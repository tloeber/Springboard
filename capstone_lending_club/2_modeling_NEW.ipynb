{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Predictive-models\" data-toc-modified-id=\"Predictive-models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Predictive models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forests\" data-toc-modified-id=\"Random-Forests-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Random Forests</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-data-set\" data-toc-modified-id=\"With-smaller-data-set-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>With smaller data set</a></span></li><li><span><a href=\"#With-all-data\" data-toc-modified-id=\"With-all-data-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>With all data</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Support Vector Machine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-SVM\" data-toc-modified-id=\"Linear-SVM-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Linear SVM</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-data-set\" data-toc-modified-id=\"With-smaller-data-set-2.3.1.1\"><span class=\"toc-item-num\">2.3.1.1&nbsp;&nbsp;</span>With smaller data set</a></span></li><li><span><a href=\"#With-whole-data-set\" data-toc-modified-id=\"With-whole-data-set-2.3.1.2\"><span class=\"toc-item-num\">2.3.1.2&nbsp;&nbsp;</span>With whole data set</a></span></li></ul></li><li><span><a href=\"#SVM-with-RBF-Kernel\" data-toc-modified-id=\"SVM-with-RBF-Kernel-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>SVM with RBF-Kernel</a></span></li><li><span><a href=\"#SVM-with-polynomial-kernel\" data-toc-modified-id=\"SVM-with-polynomial-kernel-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>SVM with polynomial kernel</a></span></li></ul></li></ul></li><li><span><a href=\"#Performance-comparison\" data-toc-modified-id=\"Performance-comparison-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Performance comparison</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    " \n",
    "import missingno  # for visualizing missing data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    GridSearchCV, ShuffleSplit\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, \\\n",
    "    LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    precision_recall_curve, average_precision_score, f1_score, \\\n",
    "    roc_curve, auc, roc_auc_score, make_scorer,\\\n",
    "    accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "\n",
    "# Set up pandas table display\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Set plotting options\n",
    "sns.set() # Use seaborn defaults for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# Adjust number of CPU cores to use\n",
    "n_jobs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-21-e60910363dbf>(31)split_preprocess()\n",
      "-> numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
      "(Pdb) X_train.shape\n",
      "(20000, 86)\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e60910363dbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;31m# Create smaller training and test data to start out with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m \u001b[0mX_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names_small\u001b[0m\u001b[1;33m=\u001b[0m     \u001b[0msplit_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-e60910363dbf>\u001b[0m in \u001b[0;36msplit_preprocess\u001b[1;34m(X, y, train_size, test_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# =============\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Imputation and standardization for numeric features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mnumeric_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     numeric_transformer = Pipeline(steps =[\n\u001b[0;32m     33\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'imputer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-e60910363dbf>\u001b[0m in \u001b[0;36msplit_preprocess\u001b[1;34m(X, y, train_size, test_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# =============\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Imputation and standardization for numeric features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mnumeric_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     numeric_transformer = Pipeline(steps =[\n\u001b[0;32m     33\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'imputer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load original data\n",
    "with open('data_processed/all_data.pickle', 'rb') as pickled_file: \n",
    "    all_data = pickle.load(pickled_file) \n",
    "    \n",
    "    \n",
    "# Find categorical variables with more than 50 unique values and drop them\n",
    "unique_values_cat = all_data.select_dtypes(include='object') \\\n",
    "                        .nunique() \\\n",
    "                        .sort_values(ascending=False) \n",
    "# Drop categorical variables with more than 50 categories\n",
    "all_data = all_data.drop(unique_values_cat[unique_values_cat > 50].index,\n",
    "                 axis='columns')\n",
    "\n",
    "\n",
    "def split_preprocess(X=all_data.drop('default', axis='columns'),\n",
    "                     y=all_data.default,\n",
    "                     train_size=.8, test_size=.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test set of specified size, \n",
    "    then applies preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train-test split \n",
    "    # ================\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y,\n",
    "                         train_size=train_size, test_size=test_size,\n",
    "                         random_state=1, shuffle=True, stratify=y) \n",
    "\n",
    "    pdb.set_trace()\n",
    "    # Preprocessing\n",
    "    # =============\n",
    "    # Imputation and standardization for numeric features\n",
    "    numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "    numeric_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())]) \n",
    "\n",
    "    # Imputation and one-hot encoding for categorical features\n",
    "    categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "    categorical_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Combining preprocessing for both kinds of features\n",
    "    # (Features of other dtypes – in our case, boolean – will be\n",
    "    # appended at the end without transformation.)\n",
    "    # (Use only 1 core to avoid joblib error)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric_transformer', \n",
    "                 numeric_transformer, numeric_features),\n",
    "            ('categorical_transformer', \n",
    "                 categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough', n_jobs=1) \n",
    "    \n",
    "    # Print dtypes of untransformed data\n",
    "    print('data types of columns that were not transformed:\\n {}'\n",
    "            .format(X_train.select_dtypes(exclude=[np.number, object]) \\\n",
    "                    .dtypes.unique()))\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_p = preprocessor.fit_transform(X_train)\n",
    "    X_test_p = preprocessor.transform(X_test)\n",
    "   \n",
    "\n",
    "    # Get feature names\n",
    "    # =================\n",
    "    # Names of categorical variables after one-hot encoding\n",
    "    categorical_names = preprocessor \\\n",
    "        .named_transformers_['categorical_transformer'] \\\n",
    "        .named_steps['onehot'] \\\n",
    "        .get_feature_names()\n",
    "    # Names of columns with other dtype (should only be Boolean)\n",
    "    other_names = X_train \\\n",
    "        .select_dtypes(exclude=[np.number, object]) \\\n",
    "        .columns\n",
    "    # Concatenate feature names (Note that list with names of \n",
    "    # numeric features was already created above)\n",
    "    feature_names = list(numeric_features) + \\\n",
    "        list(categorical_names) + list(other_names) \n",
    "\n",
    "    \n",
    "    # Return results\n",
    "    # ==============\n",
    "    return(X_train_p, X_test_p, y_train, y_test, feature_names)\n",
    "  \n",
    "    \n",
    "# Create smaller training and test data to start out with\n",
    "X_train_small, X_test_small, y_train_small, y_test_small, feature_names_small= \\\n",
    "    split_preprocess(train_size=20000, test_size=10000)\n",
    "\n",
    "# Create full training and test set\n",
    "X_train, X_test, y_train, y_test, feature_names = \\\n",
    "    split_preprocess(train_size=.8, test_size=.2)\n",
    "\n",
    "\n",
    "# Save preprocessed training and test sets\n",
    "filenames_whole = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "filenames_small = [filename + '_small' for filename in filenames]\n",
    "filenames = filenames_whole + filenames_small\n",
    "files = [X_train, X_test, y_train, y_test,\n",
    "         X_train_small, X_test_small, y_train_small, y_test_small]\n",
    "\n",
    "for file, filename in zip(files, filenames):\n",
    "    joblib.dump(file,\n",
    "                'data_processed/{}.joblib'.format(filename))\n",
    "# Delete temporary list to conserve memory\n",
    "del files\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(feature_names, 'data_procesesd/feature_names')\n",
    "joblib.dump(feature_names_small, 'data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training and test set, incl. feature names \n",
    "X_train = joblib.load('data_processed/X_train.joblib')\n",
    "X_test = joblib.load('data_processed/X_test.joblib')\n",
    "y_train = joblib.load('data_processed/y_train.joblib')\n",
    "y_test = joblib.load('data_processed/y_test.joblib')\n",
    "X_train_small = joblib.load('data_processed/X_train_small.joblib')\n",
    "X_test_small = joblib.load('data_processed/X_test_small.joblib')\n",
    "y_train_small = joblib.load('data_processed/y_train_small.joblib')\n",
    "y_test_small = joblib.load('data_processed/y_test_small.joblib')\n",
    "feature_names = joblib.load('data_processed/feature_names')\n",
    "feature_names_small = joblib.load('data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store results for SMALL data set\n",
    "average_precision_1 = {}\n",
    "classification_reports_1 = {}\n",
    "most_important_features_1 = {} \n",
    "# Note that models with small data were estimated on a different subset\n",
    "# of the observations, though the size stayed constant.  So don't use future \n",
    "# importance on these data, unless re-estimating models!\n",
    "\n",
    "# Dictionaries to store results for WHOLE data set\n",
    "average_precision_2 = {}\n",
    "classification_reports_2 = {}\n",
    "most_important_features_2 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "        oob_score=False, n_jobs=n_jobs, random_state=1,\n",
    "        class_weight='balanced_subsample')\n",
    "rf.fit(X_train_p, y_train)\n",
    "\n",
    "# Predictions of class and probability\n",
    "y_pred_rf = rf.predict(X_test_p) \n",
    "y_pred_proba_rf = rf.predict_proba(X_test_p)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision['random forests'] = \\\n",
    "    average_precision_score(y_test, y_pred_proba_rf)\n",
    "classification_reports['random forests'] = \\\n",
    "    classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Compute feature importance and sort\n",
    "most_important_features['random forests'] = \\\n",
    "    pd.Series(rf.feature_importances_, index=feature_names) \\\n",
    "            .sort_values(ascending=False) \\\n",
    "            .iloc[: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "#### With smaller data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/lr_gs_1.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression (Elastic Net) \n",
    "# --------------------------------\n",
    "lr_1 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 1, 8)}\n",
    "# Grid search\n",
    "lr_gs_1 = GridSearchCV(lr_1, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=n_jobs, cv=3)\n",
    "lr_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_gs_1, 'saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_1 = joblib.load('saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0.01\n",
       "                      0.2\n",
       "mean_fit_time       0.337\n",
       "std_fit_time        0.067\n",
       "mean_score_time     0.006\n",
       "std_score_time      0.001\n",
       "param_alpha         0.010\n",
       "param_l1_ratio      0.200\n",
       "split0_test_score   0.380\n",
       "split1_test_score   0.394\n",
       "split2_test_score   0.378\n",
       "mean_test_score     0.384\n",
       "std_test_score      0.007\n",
       "rank_test_score     1.000\n",
       "split0_train_score  0.394\n",
       "split1_train_score  0.386\n",
       "split2_train_score  0.390\n",
       "mean_train_score    0.390\n",
       "std_train_score     0.003"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search results for iid = True for best parameters\n",
    "def gs_best_result(gridsearchcv, decimals=3):\n",
    "    \"\"\"Returns details for best results from grid search.\"\"\"\n",
    "\n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(gridsearchcv.cv_results_) \\\n",
    "                .drop('params', axis='columns')\n",
    "    \n",
    "    # Get values for hyperparameters \n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    \n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], axis=1)\n",
    "    # Set hyperparameters as index\n",
    "    scores_w_params = scores_w_params \\\n",
    "                        .set_index(params.columns.tolist())\n",
    "    \n",
    "    # Get tuple with best hyperparameters values, making sure it \n",
    "    # has the same order as the multi-index.\n",
    "    best_param_tuple = (\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[0]],\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[1]])\n",
    "    \n",
    "    # Filter results for best hyperparameters \n",
    "    best_result = pd.to_numeric(\n",
    "                    scores_w_params.loc[best_param_tuple, :])\n",
    "    \n",
    "    # Return rounded result (convert to dataframe for pretty  printing)\n",
    "    return(pd.DataFrame(best_result) \\\n",
    "               .round(decimals))\n",
    "\n",
    "gs_best_result(lr_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.384, best hyperparameters:  {'alpha': 0.01, 'l1_ratio': 0.2}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEXCAYAAAC+mHPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xu81VWd//HXAUFQQ1IxQS0s4lN2kZRkupDOhNOo5CXRCs3REnSGaXIa50e/IDXLJisdmjQzyMFE0sLUFEzzVl7yggXqz/GdlqQg5qSQiqJyzv79sb7H2W4256zN2d/N4fB+Ph77wfmu7/e71toH2J+9Lt+12iqVCmZmZt3pt6krYGZmmwcHDDMzy+KAYWZmWRwwzMwsiwOGmZllccAwM7MsDhjWYxFxc0R8oU76v0bEVd3cOzciTil+XhIRQ+tcc0pEzM2ox+yI2Kf4eU5ETMh+E2bWra02dQWsT/gucCbw9Zr0KcA/52YiaUwP63EAcEGR1wk9zMvMajhgWDNcAcyKiPGSbgWIiP2ANuAXEdEP+A/gr4DXFeknSLq9OpOIqADDgL8A/0kKAE8BfyrSiIi/Ar4BbA0MB34h6TMRcSYwArgkIo4FzgLOlbQgIg4DTiO1qJ8DPi/p7og4HRhZ5PMmYAVwjKSVNfV6AykQvQHYBfgjcJSkpyJidHFuZ6AD+Kqky7pIXwZMkrS4yHsZMAn4M3Ar8N9FnfYDjgcOBQYD2wKnSLoiIrYqfgcTgXXAHcA04D7gnyT9osh7DnC/pG93/ddnlsddUtZjktYBs4HPVCVPBb4rqQKMI32Yv0/SnsBFwHpdWFX+ERgN7EkKGm+sOvc54FRJ44rzh0TEPpJmAE8AR0u6q/PiiHgb8D3gCEl7AacCV0XEkOKS8cCRkt4GrAFOqlOfTwC/lvQ+4M3AC8CninOXAj+R9A7gIOBrRd4bSu/KbsBXJI0GBgITgP0lvRuYAZxR9fvZB9gLeCcpCB8FnE9q1RERrwMOIf2uzZrCLQxrlu8DDxYfVAOAj5A+2JD064iYCZwYEW8B9id909+QCcB8SS8DL0fEJcC7i3N/DxwUEV8E3kb69r1dF3n9DXCjpD8UdbkpIp4ifeAC3CLp2eLn3wI71GYg6dsRMT4iPg+8lfQhfVdE7ED60J5TXPc48JYNpQNERBdVZR3w6+KePxYtpaMjYhSpddb5PicAF0t6sTj+eJH3UOC0iBhGarVcI2l1VwWaNcItDGsKSU8AvyB9Gz8WWCCpsxvpYGBhcelVpG/8bd1kWX1+XdXPvyJ9Y3+I9I17RTd59QdqF0zrRwpqAC9WpVfq5RURZxVl/Q8pMF5fXLeu6r7OawNor5ceEYPrlDGw6ueXitYaEbE3KXgMKco7q+q+dTV5vyEihhfB4SfAMcCnSb9ns6ZxwLBmOg84mtQKOK8q/QDgaknnA4uBw0gf5BtyLXBsRAyKiEG89hv0e4Hpkn5K6sIZVZXXOv43EHS6EfhIRLy5yONvgN2Bu8j3EWCWpItJYyoHAP2Llsm9xfslInYHbie1euqlb08KOmOL9P1J4yf1fAhYLOkc4Je89nd2AzA5IrYuxofOBz5ZnDuPNNGgn6S7G3iPZt1ywLCmkXQLsCPwrKT7q059D9g/Iu4HfgP8Htij+LCr5wJSYHmA9GH5aJH/auDfgd9ExAOkcZDbSUED4KfAvIj426o6PUjqGvtpcc/XgY92tn4ynQF8KyLuA34G3FZV5mTgqIhYClxNGsx/sov06cDnImIJaRzk3g2U+SNgp4j4b+BB4Hlgh6LL74LivnuB+4GVpEkCSFoKrMKtCytBm5c3N+s7ijGiW4CQ9MImro71MW5hmPUREXEGqcX1WQcLK4NbGGZmlsUtDDMzy+KAYWZmWRwwzMwsyxb9pPddIz5W6gDO0+0Du7+oB9a2lRvvB6z3vFvz7cArpeb/0FaDSs3/reteKjV/gFu3Lvff0V/aOkrNf+eOrh65aY5jRi4vvYxdfnVLdw+bdumVP/8h+z/UgJ3e3KOyyrJFBwwzs5bpaO/+ml7OAcPMrBUq5bbkWsEBw8ysFTocMMzMLEPFLQwzM8vSvq77a3o5Bwwzs1bwoLeZmWVxl5SZmWXxoLeZmeXwoHcDImIIcAcwUdKyiKgAS2suWyhpRp17JwDnkHYyu0zSzCI9SJvJvB54EviEpFUlvg0zs43jFkaeiBgHzAZGV6dLGpNx72DgQmA/4HFgYUQcCPyctPvZ5yT9PCK+TtqBbXqTq29m1nPt5S6D0wqtamFMAaYBF2/EvfsCD0t6FCAi5gFHkvZWXiPp58V1XwOGNqGuZmbN5y6pPJJOAEg9SP+r2Ne42nRJ19WkjSDtWdxpJbAbaU/lJyPiB8B7gP8GPtvEapuZNY+7pHomp0uKtAR79SqPbUAHqe77Ax+StDgivkIa5ziuydU0M+s5tzCaLyLGAnOKw8WkbqzhVZfsAjxBGuR+WNLiIv1HwIJW1dPMrCFuYTRfEQBebXlExKD0R4wCHgUmkwbB7wCGRcRekpYCHwXu3QRVNjPrVqXDg949UmcM4xFJk6oTJK2NiOOAy4FBwCJggaRKRBwOzI6IbYHlwKdaUG0zs8a5hdEYSSOrfs7eUUrSjcBeddLvIs2iMjPr3TyGYWZmWbz4oJmZZXELw8zMsngMw8zMsngDJTMzy+IWhpmZ5ahUPOhtZmY53MIwM7MsJc2SiojJwExgADBL0nk15w8Hvgz0B+4Bpkp6OSKGk5ZhGgG8ABwtaVlXZW3RAeOpjq1LzX/kNs+Xmv+Da4eUmn872c9WbrQ7BwwqNf/dXql0f1EPvFDpX2r+AKvayv1mOu6lfqXmv00Lnj+46g+7lV7GiT3NoIQWRkTsCpwJ7AO8BNwRETdLerA4vy1wLrC3pD9FxKWkBVq/T1qnb4Gk70XEScBZwMe7Km+LDhhmZi3TwCypiBhK/f19VktaXXU8AbhJ0jPFfQuAScAZAJLWRMRISa9ExDbAzsCqiNiJtHrGAUU+/wXc2F29yv1qYWZmSaUj/wUnkxZbrX2dXJPrhvYLelURLA4k7Vi6E3A98BbgMeDsiLiHtNL3y929BQcMM7NW6OjIf8EsYI86r1k1uW5ov6DXkHStpB2Ba4DzSb1L7yG1Tt4LXAVc1N1bcJeUmVkrNDCGUXQ7re72wrRK9/iq4879ggCIiB2AsZKuL5IuAS4j7Sf0nKRrivT5wH92V5hbGGZmrdBYl1SuG4APR8SwYoziCODnVefbgHkR8cbi+EjgNkm/B5YXXVWQuZ+QA4aZWSu0r8t/ZZK0ApgB3AwsAeZLujsiFkXEWElPA1OBayJiKRDA9OL2jwHTI+IB4HPAp7srz11SZmatUNKDe5Lmk7qUqtMOqvr5SuDKOvcJ2L+RshwwzMxawcubm5lZFi8Nki8ihgB3ABMlLYuICrC05rKFkmbUuXcCcA4wGLhM0swi/TRSv9uq4tLZtY/Fm5n1Cg4YeSJiHDAbGF2dLmlMxr2DgQuB/UgPniyMiAMlXQuMBT4h6dfNr7WZWRNVyl2mphVa1cKYAkwjrV3SqH2BhyU9ChAR80hTwzoDxhcj4k3Ar4BTJK1tTpXNzJponTdQyiLpBICIeE16RCypuXS6pOtq0uo++h4R2wG/Bf4NeASYC3yJNMXMzKx38aB3z+R0SbGBR98lPQ+8OnUsIs4mdV05YJhZ7+MxjOaLiLGkNdoBFpO6sYZXXbIL8ETx5OIESRcW6W3AKy2rqJlZIzyG0XySFgOvtjwiYlD6I0aRVmucTGpJvAh8IyJuBpaRxkiuaHmFzcxyuIXRM3XGMB6RNKk6QdLaiDgOuBwYBCwibfpRiYgTgauBgcBtwNnl19rMbCM4YDRG0siqn7O3c5N0I2mzj9r0y0mBxMysV6u0l7/zYNl6XZeUmVmf5BaGmZll8bRaMzPL0uFZUmZmlsNdUmZmlsWD3mZmlsUtDDMzy+IxDDMzy+JZUpu3/Y96rtT8+7/1jaXm/5YBA0rNvxXattuu3AJe2fyXFxv/yKOl5t/+5OpS8x/w8cNLzR+g8sBvSy+jx9zCMDOzHBWPYZiZWRbPkjIzsyzukjIzsyzukjIzsyxuYZiZWRZPqzUzsyxuYZiZWY7KunJmSUXEZGAmMACYJem8mvOHA18G+gP3AFMlvRwR44FZpB1LHwX+XtKqrsrqV0L9zcysVkcl/5UpInYFzgQ+CIwBpkbEnlXntwXOBQ6Q9A7SNtfHFaf/C/iUpHcBDwL/1l15LWthRMQQ4A5goqRlEVEBltZctlDSjDr3TgDOAQYDl0maWXP+YOBcSXuUU3szsx4qZwxjAnCTpGcAImIBMAk4A0DSmogYKemViNgG2BnobEW8vUgfAOwK3NddYS0JGBExDpgNjK5OlzQm497BwIXAfsDjwMKIOFDStcX5NwDfArL3CDcza7nGWg5DgaF1Tq2WVL2WywhgZdXxSmDf6huKoHAgMA9YAVxflf4u4AbgFeCL3dWrVV1SU4BpwBMbce++wMOSHpW0jvSmj6w6P4fUP2dm1mtVOirZL+Bk0rhC7evkmmz7AdWRqA1Yrykj6VpJOwLXAOdXpd8v6Q3AV4DLunsPLWlhSDoBICJekx4RS2ounS7pupq0ehF0t+L+fwZ+A9zZzPqamTVdY4Pes4C5ddJrV4pcDoyvOt6Fqi/mEbEDMFbS9UXSJcBlETEI+DtJVxbp84Czu6vUJp0lldMlxQYiaES8EzgC+DBFADEz67Ua6JIqup1ylhG+ATg9IoYBa0ifiVOrzrcB8yJirKTHSL0zt5G6oM6LiMcl3QscVaR3qddNq42IsaRuJoDFwMXA8KpLOiPokUX6YtK0sBERcauk6mhrZtY7lPAchqQVETEDuJn0OThH0t0RsQg4VdLiiJgKXFNMNHoQOElSe0R8HPh+RPQnjW2c0F15vS5gSFpMmh4GQNF0iogYRerDmwxcKOknwGnFNSOBWxwszKy3qlTKeXBP0nxgfk3aQVU/XwlcWee+24B9GilrkwaMOmMYj0iaVJ0gaW1EHAdcTppDvAhY0Joampk1iZ/0boykkVU/Z0+DlXQjsFcX55cBIzd03sxsk3PAMDOzHJV1XnzQzMxybP7xwgHDzKwVKu6SMjOzLA4YZmaWxV1SZmaWw11SZmaWpbLOAcPMzHK4S2rzNvAfu91gqmfWvVxq9pUXny01f/r1Lzd/gK0Glpp921Zbl5p/5aU1peYP0P89Hyo1/6223aHU/CurV3Z/UQ/1/0Ttqt+9Tzn7J7XWFh0wzMxaxgHDzMxyuIVhZmZZKus2dQ16zgHDzKwF3MIwM7MsDhhmZpankr2jQ6/lgGFm1gJuYZiZWZZKh1sYZmaWoaPdASNbRAwB7gAmSloWERVgac1lCyXNqHPvBOAcYDBwmaSZRfrhwJeB/sA9wFRJ5T5ebWa2EdwllSkixgGzgdHV6ZLGZNw7GLgQ2A94HFgYEQcCvwLOBfaW9KeIuBQ4Dvh+c2tvZtZzfaFLql+LypkCTAOe2Ih79wUelvSopHXAPOBISWuAkUWw2AbYGVjVtBqbmTVRpZL/6q1a0sKQdAJARLwmPSKW1Fw6XdJ1NWkjgOrVy1YCuxX5vlK0NuYBK4Drm1htM7Om6QstjE066J3TJUVqBVXH3DaqlvGSdC2wY0R8DTgfmNzUSpqZNYEHvUsQEWOBOcXhYuBiYHjVJbsAT0TEDsBYSZ2tikuAy1pWUTOzBmxRLYyIeA+wHekbfn9glKTZza6QpMXAqy2PiBiU/ohRwKOkFsSFRT3mRcRYSY8BRwK3Nbs+ZmbNUNlSnvSOiNnAocAg0sD1KNKHc48CRp0xjEckTapOkLQ2Io4DLi/KXwQskFSJiKnANcUU3QeBk3pSHzOzspQ1rTYiJgMzgQHALEnn1Zyv+/hBRLyRNP67MyDgaEnPd1VWbgvjAGAP4LvAGcDuwP/JfkcFSSOrfs4Ot5JuBPaqk34lcGWj9TAza7WOEloYEbErcCawD/AScEdE3CzpweL8tmz48YPvAt+VdGlEfAn4EjC9q/Jyp9WuLKaxPgS8S9ItFDOVzMyse5VKW/arAROAmyQ9U3xGLwBe7aXZ0OMHETEA+FBxPcBcUrd+l3JbGC9HxIdI3T4HRsTNpPEMMzPL0MgsqYgYCgytc2q1pNVVx/UeO9i3+oYNPH6wE/Bs8Wxb533dNgJyWxjTgRNJ4wdjgD8XhZuZWYZKR1v2CziZNMmn9nVyTbZdPnbQSdK1knYEriE9flB7H/Xuq5XVwpB0J3BncfhXEbG9pL/k3GtmZg2PYcwidRPVWl1zvBwYX3W8C1UranTx+MFTwPYR0V9SO+nRhW5X4sidJRXAKaT+r7YiDUmH5NxvZrala2Rsouh2qg0O9dwAnB4Rw4A1wBHA1KrzdR8/KLqpbgU+DswHjgWu7a6w3DGM+cCtwBWs34wxM7NulLFGlKQVETEDuBkYCMyRdHdELAJOlbS4i8cP/hG4KCJmAo8Bn+yuvLZKxruIiPskvXvj3lLv9dJDvyw3+K0rd6X1yovPlpo//fqXmz/AVgNLzb5tq61Lzb/y0ppS8wegX7lrhLZtu0Op+VdWr+z+oh7qt+vbSi9j4Ih39Ghe7JI3HZL9eTPmjz/rlU/55f5LfCwi9ii1JmZmfVhHR1v2q7fqsksqIq4mdUHtAiyOiLuBVzrPb+5jGP1ev0up+Vfa13V/UQ/0G/iWUvOno73c/IHKSy+UXkaZ2jpeX34hJe+8U3ml3JZw23bltmAAKqueLL0MRryjR7eX8eBeq3U3hrGgm/NmZpahz68lJemizp8jYkfSk4HtwC89rdbMLF9faGFkjWEUi1c9Qnpo5P8Aj0TEX5dZMTOzvqTSwKu3yp1WeybwIUn3A0TE3qQ9K/Yuq2JmZn1Je0erdsQuT+47eKEzWABI+g29OxCamfUqHQ28eqvcFsa1ETGdtExuO+mpwAci4vVAm6RnyqqgmVlfUGHzH8PIDRhfIG2+8e816Z8itTRa8ISXmdnmq6MP9MnkLj44oOyKmJn1ZR19vYUREZ/v6rykc5pbHTOzvmlL6JJ6V9XPtWuub/7v3sysRdr7wEdmdw/uHQ8QEe8njWNsS5pZ1R8Y2UhBETEEuAOYKGlZsXLi0prLFkqaUefeCcA5wGDgMkkzi/RDSZubt5E2Fzle0qpG6mVm1gq9efZTrtxB79nAD0l7xX4POAy4PLeQiBhX5DG6Ol3SmIx7BwMXAvsBjwMLi+0GbyftHPXeYonfM4DTgc/l1svMrFX6QsDIfQ6jIuks4BbgIeAo4G8bKGcKMI2MHZ3q2Bd4WNKjxf6z80ibgAwApklaUVx3H/DGjcjfzKx0FdqyX71VbgvjueLP3wPvlHR7RGQvZSrpBEi79FWLiCU1l06XdF1NWr1NzneT9DRpQ6fOVsgXgO/k1snMrJV68arl2XIDxl0RcRnwJVKX0Gigx2t353RJ0c0m5xGxPSlwLK1eLNHMrDfp89Nqq/wLME7S7yLiZGACGdv5bYyIGEtapwpgMXAxaYPyTq9uch4Rw4HrgJuKOpqZ9Url7y5TvtwH9yrAncXPC4GFZVVI0mLg1ZZHRAxKf8Qo0kyoycCFEdEfuBr4saSvllUfM7Nm6GjbcloYpagzhvGIpEnVCZLWRsRxpFlZg4BFpI2dDiOtlrtVRHTes7hzvMTMrDfpAyuDtDZgSBpZ9XN2uJV0I7BXTfIV5M/yMjPbpPrCtNpN2sIwM9tSbEmzpMzMrAf6/NIgZmbWHG5hmJlZFo9hmJlZFs+SMjOzLO6SMjOzLO6S2tx1lPtXWHn2z6Xm3/7Uo6Xmz1PLy80fqPzpyVLzb3/4j+Xmv/L5UvMHWHLLTqXmf+/WW5ea/7lr7i81f4DHnyv3/xrAupdXdH9RF9pLamFExGRgJmkF71mSzqs5v96+QcW111ddtj0wTNJ2XZXlB9/MzFqgo4FXrojYFTgT+CBpSaWpEbFn1fkhpH2DDpa0F2kbiNMlPSVpTLEA7N7AMmBqd+Vt2S0MM7MWaTAQDAWG1jm1WtLqquMJwE2SninuW0Da6O6M4ny9fYOOrsnzeOAFSfO7q5cDhplZCzQ4S+pk4LQ66V8m7Szaqd5+Qft2HnS3b1CxiOsM4NCcSjlgmJm1QIOzpGYBc+ukr6457nK/oE5d7Bv0d6QdTbMGmhwwzMxaoJEuqaLbqTY41LMcGF91/Op+QZ262TfoMODS3Ho5YJiZtUBJGyjdAJweEcOANcARVA1eZ+wb9D7grNzCHDDMzFqgjAf3JK2IiBnAzcBAYI6kuyNiEXAqsDtd7xv0ZlIrJYsDhplZC5T11Fcxu2l+TdpBxY+L6eLxCUnbNFKWA4aZWQt4LSkzM8vS0QdCRssCRvHE4R3AREnLIqICLK25bKGkGXXunQCcAwwGLpM0s+b8D0kPr8wtpfJmZj1U0qB3S7UkYETEOGA2MLo6vXgsvbt7BwMXAvsBjwMLI+JASddGxAjgAuDDpCljZma9Ul9YfLBVa0lNAaZRMz84076kB0selbQOmAccWZw7GrgK+HFTamlmVpKOtvxXb9WSFkbnFK6IeE16RCypuXS6pOtq0uo9+r5bke83i3w+2Mz6mpk1m8cweiinS4rMR9/NzHqzzT9c9MJZUhExFphTHC4GLgaGV12y3qPvZma9XV/4ltvrAoakxaR13QGIiEHpjxhF2vxjMmkQ3Mxss9HeB9oYmzRg1BnDeETSpOoESWsj4jjgcmAQsAhY0Joampk1h1sYDZI0surn7LkAkm4E9uri/HE9qpiZWck86G1mZlk2/3DhgGFm1hLukjIzsywe9DYzsywewzAzsyybf7hwwDAzawm3MMzMLIsHvTdz7Y8/UGr+233w5FLzty3F7zZ1BawJKm5hmJlZDs+SMjOzLO6SMjOzLB0VtzDMzCzD5h8uHDDMzFrC02rNzCyLZ0mZmVmWdQ4YZmaWwy0MMzPLUta02oiYDMwEBgCzJJ1Xc/5Q4MtAG2mb6+Mlrao6/x7gTklbd1dWv2ZW3MzM6qtUKtmvXBGxK3Am8EFgDDA1IvasOj8EOB84WNJewH3A6VXntwG+AwzMKa/UFkZR2TuAiZKWRUQFWFpz2UJJM7rIow34JjCRFKSnSLq9OPevwBRS4PuCpJ+W8DbMzHqspFlSE4CbJD0DEBELgEnAGcX5AcA0SSuK4/uAo6vuPxuYBXwgp7DSAkZEjANmA6Or0yWNaTCrI4C3A3sCo4CFEfF24D3AMaSoOgT4dUTc0vmLMzPrTRpZGiQihgJD65xaLWl11fEIYGXV8Upg384DSU8DVxR5Dga+QGpREBGHANtIWhARWfUqs0tqCjANeKKRmyJiWU3SwcClkjok/Q54DHg/cBDwU0lrJT0F3EJqhZiZ9TodVLJfwMmk8YbaV+2Kpv147TOBbdQZLomI7YGFwFJJF0XELqRxj8828h5Ka2FIOgGgNnJFxJKaS6dLuq6LrOpF0N2K9HvqpJuZ9TqNjE2Quonm1klfXXO8HBhfdbwLNV/SI2I4cB1wE/AvRfJEYEfgV52f0cVn83hJz22oUi2fJVWvSyoi+gP3FocjqoLKR9lwBM2KrGZmvUEjH05Ft1NtcKjnBuD0iBgGrCF14U/tPFl8tl4N/FjSV6vynwPMqbqukjNc0Cum1UpqJ41FEBHLqiseEcuB4VWXd0bQeukqv7ZmZo0r4zkMSSsiYgZwM2mm0xxJd0fEIuBUYHdgb2CriJhU3La4sweoUb0iYHRjEfDpiPgRsAdpEP0eYC1wQUScA2wLfJj0CzIz63XKWktK0nxgfk3aQcWPi8kYq5bUllNWywNGnTGMRyR1Rj4kjaw5vwAYR5oOBvAZSS8Cd0fEPFLw2Ar4UtXUMTOzXqW9svn3mLc1OBDTp6y9+yelvnlv0WrWd6x7eUXWt/AN2X+3CdmfN7csv6FHZZVlc+iSMjPb7HkDJTMzy7L5hwsHDDOzlvAGSmZmlsUBw8zMsvSFWVIOGGZmLeANlMzMLEtfeITBAcPMrAU8hrGZq9x/16augpltIdzCMDOzLO19YDFtBwwzsxbwk95mZpbFs6TMzCyLWxhmZpbFLQwzM8viFoaZmWXx0iBmZpbFXVJmZpal4hZG1yJiCHAHMFHSsoioAEtrLlsoaUYXebQB3wQmAh3AFEm3V53fFVgsaXjT34CZWZN4aZAuRMQ4YDYwujpd0pgGszoCeDuwJzAKWBgRb5e0LiIOAmYBuzShymZmpekLS4P0KzHvKcA04IlGboqIZTVJBwOXSuqQ9DvgMeD9xbnPAB/rWTXNzMrXQSX71VuV1sKQdAJARLwmPSKW1Fw6XdJ1XWQ1AlhZdbwS2K0o44h6ZZiZ9TbtHR7DaFi9LqmI6A/cWxyOqAoqHyW1gqpDbhv0gVW8zGyL4llSTSKpHRgDqUuqOqhExHKgekB7Fxrs5jIz29T6whhGrwgY3VgEfDoifgTsQRpEv2fTVsnMrDG9eWwiV8sDRp0xjEckTeo8kDSy5vwCYBxwX3H8GUkvlldDM7PmK6uFERGTgZnAAGCWpPNqzh8KfJnUnf8ocLykVVXnvwK0Szq9u7La+kIzaWO9+INTSn3zr/uHH5WZvZm10LqXV7T15P7Xbzcq+/Nm1fOPZJVVPId2G7AP8BLpubdPSnqwOD8EeAh4r6QVEXEGsL2kz0XE9sA5wCeBb+QEjDKn1ZqZWaGkabUTgJskPSNpDalHZlLV+QHANEkriuP7gDcWPx8KPAycnVvY5jCGYWa22WukNycihgJD65xaLWl11XG9xw727TyQ9DRwRZHnYOALwHeKcz8s0k/PrZdbGGZmLdBRqWS/gJNJ4w21r5Nrss167KDofloILJV00ca+B7cwzMxaoMHnMGYBc+ukr645Xg6Mrzpe77GDiBgOXAfcBPxLI5Wo5YBhZtYCjWygVHQ71QaHem4ATo+IYcAa0tp7UztPFg9FXw38WNJXG6pwHQ4YZmYt0FHC8ubFzKcZwM3AQGCOpLsjYhFwKrA7sDewVUR0DoYv7ly6qVGeVlsiT6s16zt6Oq124Na7ZX/evPzS8h6VVRa3MMzMWqAvfDlTIbXUAAAGh0lEQVTfolsYZmaWz9NqzcwsiwOGmZllccAwM7MsDhhmZpbFAcPMzLI4YJiZWRYHDDMzy+KAYWZmWRwwzMwsi5cGqSNjj9wxwBxgCPAr4CRJ65qVf9V1PyTtpjW3yfXvco/fJpVxeFFGf+AeYKqkl5uVf9V1BwPnStqjyfU/Dfg00Pl7mb2hOvSgjAAuAF4PPAl8opG/h67yL/6Nzq26fBiwStI7m1j/vYv6DwQeB46p2dynGWUcCJxVHN4PnCjp+QbLGELaunSipGU153r0f3lL4xZGjWKP3DOBDwJjgKkRsWfNZfOAf5I0mvShO6WZ+UfEiIi4mtdutdiU/Iv/POcDB0vai7Rl4+lNLmNb4FzgAEnvAAYBxzUr/6rr3gB8i/R30LT6F8aSPsDHFK9Gg0V3v6M24GfA14u/h9+SdkNrSv6SlnTWHXg/KfCd1Kz8C98GTi3qL+CU3Pxzyih2nbuI9PfwbmAp8LUGyxhH2vN69AYu2ej/y1siB4z1dblHbkS8CRgs6c4iaS5wZLPyLxwNXAX8uNn1p+s9fptSRpE2UtKfImIbYGf+95t6M95DpzmkVkyjcvIfC3wxIu6LiHMjYlCTy9gbWCPp58Xx14BGglLu7wjg/wK/lHRbk/PvT/pmDrAN8GID+eeU8Vbgj5IeLI6vAQ5rsIwpwDRqNhWCpvxf3uI4YKyv3h65uzVwvqf5I+mbkuY0kGd2/pKellS7x++VzSyjKOeVojvhcWAn4Ppm5h8R/wz8BriTxnWZf0RsR/rG/2+kD/ahwJeaWQYwCngyIn4QEb8htfoa6WrJ+ndYbM05lcYDa07+nwdmR8RK4ADge00u42Fg94jYqzg+irSjXDZJJ0i6dSPLtxoOGOvrbo/crD10e5B/T7Vij9+sMiRdK2lH0jfD85uVf0S8k7Sz2FcayDM7f0nPSzpI0kNFf/bZwEHNLIM0frg/cL6kvYE/AOc0Mf9OxwBXSnqqgby7zb/4svEDYIKk4cB3gR82s4xiPORY4PsRcQ+plZA9DtbT8m19DhjrWw4Mrzqu3SO3u/M9zb+nus2/2OP3VlJ31MbsvNVlGRGxQ0T8bdX5S4B3Nyt/UrfBcGAxsAgYEREb+hbZcP4R8caI+HTV+TbglQby77YM0iD3w5IWF8c/AvZtYv6dDgMubSDf3PzfCbwo6e7i+AJSAGxaGcX2ossljZP0XlKr7/cNlrHR5dv6HDDWdwPw4YgYVvS/HwF09jMj6Y/A2oj4QJH0KeDaZuXfBF3mX7PH78mSNmZDlO7eQxswLyI6x0aOJA08NiV/SadJGl0M6B4EPCFpfBPr/yLwjYjYoxicngZc0UD+OWXcAQyr6m75KHBvE/PvHFjfB/h1g3XPyf8RUndRFMeHkmbDNbOMCnB9ROxavJfPA5dtxHupqwn/l7c4Dhg1isHgzj1ylwDzO/fIjYixxWVHA/8REQ8B2wH/2eT8y6z/IaR++UkRsaR4NTRe0l0Zkp4m9ZtfExFLgQCmN/E99EhG/f8HOJEUWEUKgGc3uYwXgcNJYwD/D/gb4F+blX9x2TDgZUlrG6l7Zv1XkWa+/Tgi7iNNQT6+yWV0kP4efk76e1gFfLPR91KrWf+Xt0Tecc/MzLK4hWFmZlkcMMzMLIsDhpmZZXHAMDOzLA4YZmaWxQHDzMyyOGBYnxAR+0fEA1XHu0fEiojYqcnlHBwRZxQ/HxIRnrdvWwzvh2F9TkQcS1psb0QJ2b8X2AFA0s9IS5SbbREcMKxPiYgRpPWTPkJ6OjjnnuOAzwDbAn8BJpIWS3wrsCPwHDCZtGrtSUD/iPgLaTXVSZImRsRuxT0jSU+GXySpx08lm/Um7pKyPkXSE5I+Jul3Dd76DmB/SX8NHAislvS+YmOde0ib7NxFWsL7Mkkzau6/BLhZ0ruADwDHRMQnevZuzHoXBwyz5D5JzwJIWgDMjYjPRsS3SauwbrehG4sdBj9AsQGSpL+QNuM5sOQ6m7WUA4ZZ8urmRRHxD6S9Hl4A5pOWHu9qG9h+dc73I+1uaNZnOGCYre8jwFxJPyCNg3yUtB0pwDpqAoGk50g7/02DVzenOhb4RasqbNYKDhhm6/sWcGKxbPetpK1gRxXnbgI+EhHfqbnnaNLeDvcDdwM/JXVLmfUZXt7czMyyeFqtbRGKLVxft4HT44tuJTPrglsYZmaWxWMYZmaWxQHDzMyyOGCYmVkWBwwzM8vigGFmZln+P4DWbSniGBDuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_lr_1= lr_gs_1.predict(X_test_small)    \n",
    "y_pred_proba_lr_1= lr_gs_1.predict_proba(X_test_small)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision_1['logistic regression'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_proba_lr_1)\n",
    "classification_reports_1['logistic regression'] = \\\n",
    "    classification_report(y_test_small, y_pred_lr_1)\n",
    "\n",
    "# Compute feature importance and sort\n",
    "most_important_features_1['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_1.best_estimator_.coef_[0], \n",
    "          index=feature_names_small) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] \n",
    "\n",
    "# Visualize grid search results\n",
    "def gs_heatmap(gridsearchcv, x_digits=0, y_digits=0,\n",
    "               x_scientific_notation=True, y_scientific_notation=True):\n",
    "    \"\"\"Visualizes validation accuracy from grid search over two hyperparameters.\"\"\"\n",
    "    \n",
    "    # Print test score and  hyperparameters\n",
    "    print('Best score: {:.3f}, best hyperparameters: '\n",
    "                .format(gridsearchcv.best_score_), \n",
    "          gridsearchcv.best_params_)\n",
    "      \n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['mean_test_score'])\n",
    "    # Get values for hyperparameters\n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], \n",
    "                                  axis=1)\n",
    "    # Set first two columns, which correspond to parameters, as index.\n",
    "    # Then unstack.\n",
    "    index_cols = list(scores_w_params.columns)[:2]\n",
    "    scores_2d = scores_w_params.set_index(index_cols) \\\n",
    "                    .squeeze() \\\n",
    "                    .unstack()\n",
    "    \n",
    "    # Create desired formatting string for axes (scientific notation and digits)\n",
    "    if x_scientific_notation == True:\n",
    "        x_notation = 'E' \n",
    "    else: \n",
    "        x_notation = 'F'\n",
    "    x_formatting = '{:.' + str(x_digits) + x_notation + '}'\n",
    "\n",
    "    if y_scientific_notation == True:\n",
    "        y_notation = 'E' \n",
    "    else: \n",
    "        y_notation = 'F'\n",
    "    y_formatting = '{:.' + str(y_digits) + y_notation + '}'\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(scores_2d, ax=ax,\n",
    "                xticklabels=[x_formatting.format(x) for  x in scores_2d.columns],\n",
    "                yticklabels=[y_formatting.format(y) for y in scores_2d.index])\n",
    "    ax.set_title('Validation accuracy')\n",
    "    \n",
    "\n",
    "gs_heatmap(lr_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/lr_gs_2.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression (Elastic Net) \n",
    "# --------------------------------\n",
    "lr_2 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "# param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "#               'alpha': np.logspace(-6, 0, 13)}\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 1),\n",
    "              'alpha': np.logspace(-6, 0, 1)}\n",
    "\n",
    "# Grid search\n",
    "lr_gs_2 = GridSearchCV(lr_2, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=n_jobs, cv=5)\n",
    "lr_gs_2.fit(X_train, y_train) \n",
    "\n",
    "# Save model\n",
    "\n",
    "joblib.dump(lr_gs_2, 'saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_2 = joblib.load('saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_lr_2 = lr_gs_2.predict(X_test)\n",
    "y_pred_proba_lr_2 = lr_gs_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision_2['logistic regression'] = \\\n",
    "    average_precision_score(y_test, y_pred_proba_lr_2)\n",
    "classification_reports_2['logistic regression'] = \\\n",
    "    classification_report(y_test, y_pred_lr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature importance and sort\n",
    "most_important_features_2['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_2.best_estimator_.coef_[0], \n",
    "          index=feature_names) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.335, best hyperparameters:  {'alpha': 1e-06, 'l1_ratio': 0.0}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'unstack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-307929ad9205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize grid search results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgs_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_gs_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_digits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_scientific_notation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-3960aacf9a2b>\u001b[0m in \u001b[0;36mgs_heatmap\u001b[1;34m(gridsearchcv, x_digits, y_digits, x_scientific_notation, y_scientific_notation)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Then unstack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mindex_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_w_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mscores_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores_w_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_cols\u001b[0m\u001b[1;33m)\u001b[0m                     \u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                     \u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# Create desired formatting string for axes (scientific notation and digits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'unstack'"
     ]
    }
   ],
   "source": [
    "# Visualize grid search results    \n",
    "gs_heatmap(lr_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_1 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-5, 1, 11)}\n",
    "svm_lin_gs_1 = GridSearchCV(svm_lin_1, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=n_jobs, cv=2)\n",
    "svm_lin_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_1, 'saved_models/svm_lin_gs.joblib')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model\n",
    "svm_lin_gs_1 = joblib.load('saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_1 = svm_lin_gs_1.predict(X_test_small)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_1 = svm_lin_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_1)\n",
    "classification_reports_1['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_1)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_2 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-5, 1, 11)}\n",
    "svm_lin_gs_2 = GridSearchCV(svm_lin_2, param_grid=param_grid,\n",
    "                            scoring='average_precision',\n",
    "                            return_train_score=True,       \n",
    "                            n_jobs=n_jobs, cv=2)\n",
    "svm_lin_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_2, 'saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model\n",
    "svm_lin_gs_2 = joblib.load('saved_model/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm = svm_lin_gs.predict(X_test_small)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm = svm_lin_gs.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm)\n",
    "classification_reports['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with RBF-Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'gamma': np.logspace(-5, 1, 8)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_rbf_gs = GridSearchCV(svm_rbf, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs.fit(X_train_p, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs, 'saved_models/svm_rbf_gs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs = joblib.load('svm_rbf_gs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm = svm_rbf_gs.predict(X_test_small)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm = svm_rbf_gs.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm)\n",
    "\n",
    "classification_reports['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs.cv_results_) \\\n",
    "    .set_index('params') \\\n",
    "    .loc[:,['mean_test_score', 'mean_train_score',\n",
    "           'split0_test_score', 'split1_test_score','split2_test_score',\n",
    "           'split0_train_score', 'split1_train_score','split2_train_score']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_gs.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with polynomial kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel='poly', probability=False, gamma='auto',\n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'degree': [2,3,4]}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_poly_gs = GridSearchCV(svm_poly, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_poly_gs.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_poly = svm_poly_gs.predict(X_test_p)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_poly = svm_poly_gs.decision_function(X_test_p)\n",
    "\n",
    "# Save results\n",
    "average_precision['SVM (Polynomial Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_poly)\n",
    "\n",
    "classification_reports['SVM (Polynomial Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_poly_gs, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(svm_poly_gs, 'svm_poly_gs.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = \n",
    "plt.title('Impact of Dropping Columns on Classifier Performance')\n",
    "plt.ylabel('Average Precision');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.724px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
