{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Club Loan Default Predictions 1\n",
    "**Author: Thomas Loeber**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-data-and-saved-models\" data-toc-modified-id=\"Load-data-and-saved-models-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load data and saved models</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>PCA</a></span></li><li><span><a href=\"#Random-forests\" data-toc-modified-id=\"Random-forests-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Random forests</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ridge/Lasso-+-LogisticRegressionCV\" data-toc-modified-id=\"Ridge/Lasso-+-LogisticRegressionCV-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Ridge/Lasso + LogisticRegressionCV</a></span></li><li><span><a href=\"#SGDClassifier-(elastic-net)-+-GridSearchCV\" data-toc-modified-id=\"SGDClassifier-(elastic-net)-+-GridSearchCV-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>SGDClassifier (elastic net) + GridSearchCV</a></span></li></ul></li><li><span><a href=\"#Load-pickled-data\" data-toc-modified-id=\"Load-pickled-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Load pickled data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import missingno  # for visualizing missing data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set up pandas table display\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Set plotting options\n",
    "sns.set() # Use seaborn defaults for plotting\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "with open('data_processed/all_data.pickle', 'rb') as pickled_file: \n",
    "    all_data = pickle.load(pickled_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data and models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (for now only select 1% for training)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(all_data.drop('default', axis='columns'),\n",
    "                     all_data.default,\n",
    "                     test_size=0.99, random_state=1,\n",
    "                     shuffle=True, stratify=all_data.default) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller test set\n",
    "X_test_small, y_test_small = resample(\n",
    "    X_test, y_test, replace=False, \n",
    "    n_samples= 10000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation and standardization for numeric features\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "numeric_transformer = Pipeline(steps =[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Imputation and one-hot encoding for categorical features\n",
    "categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "categorical_transformer = Pipeline(steps =[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "# Combining preprocessing for both kinds of features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('', categorical_transformer, categorical_features)],\n",
    "    remainder='passthrough', n_jobs=3)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_p = preprocessor.fit_transform(X_train)\n",
    "\n",
    "X_test_small_p = preprocessor.transform(X_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\n",
    "for split_data in ['X_train_p', 'X_test_small_p', 'y_train', 'y_test_small']:\n",
    "    joblib.dump(split_data,\n",
    "                'data_processed/{}.joblib'.format(split_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, 168)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8139\n",
       "1    2094\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look how imbalanced our data are\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7950\n",
       "1    2050\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_small.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use PCA to assess whether features lie in lower-\n",
    "# dimensional subspace\n",
    "pca = PCA()\n",
    "pca.fit(X_train_p)\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.step(range(1, len(explained_var)+2),\n",
    "         np.hstack([[0], np.cumsum(explained_var)]),\n",
    "         color='black', label='Cumulative')\n",
    "plt.bar(range(1, len(explained_var)+1),\n",
    "        explained_var, \n",
    "        label='per principal component')\n",
    "plt.legend('lowerright')\n",
    "plt.title('Explained variance for different numbers of principal component')\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlabel('Number of Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=3, oob_score=True, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "        oob_score=True, n_jobs=3, random_state=1,\n",
    "        class_weight='balanced_subsample')\n",
    "rf.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999413661682791"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test_small_p, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "### Ridge/Lasso + LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=4, class_weight='balanced', cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=1,\n",
       "           refit=True, scoring=None, solver='saga', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge CV, stochastic gradient descent\n",
    "lr_ridge_cv = LogisticRegressionCV(Cs = 4, solver='saga', cv=3,\n",
    "    random_state=1, penalty='l2', class_weight='balanced')\n",
    "lr_ridge_cv.fit(X_train_p, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0.85019056, 0.99794782, 0.99736148, 0.99765465],\n",
       "        [0.88155966, 1.        , 1.        , 1.        ],\n",
       "        [0.87716212, 0.99970683, 0.99970683, 0.99970683]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance during cross-validation\n",
    "lr_ridge_cv.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance on test set\n",
    "lr_ridge_cv.score(X_test_small_p, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try more iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=4, class_weight='balanced', cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=1,\n",
       "           refit=True, scoring=None, solver='saga', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try more iterations (Ridge CV, stochastic gradient descent)\n",
    "lr_ridge_cv = LogisticRegressionCV(Cs = 4, solver='saga', cv=3,\n",
    "    random_state=1, penalty='l2', class_weight='balanced', \n",
    "    max_iter=1000)\n",
    "lr_ridge_cv.fit(X_train_p, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0.85019056, 0.99824099, 0.99882732, 0.99882732],\n",
       "        [0.88155966, 1.        , 1.        , 1.        ],\n",
       "        [0.87716212, 0.99970683, 1.        , 1.        ]])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance during cross-validation\n",
    "lr_ridge_cv.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance on test set\n",
    "lr_ridge_cv.score(X_test_small_p, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=4, class_weight='balanced', cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=1,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try default solver (Ridge CV, more iterations)\n",
    "lr_ridge_cv_2 = LogisticRegressionCV(Cs = 4, cv=3,\n",
    "    random_state=1, penalty='l2', class_weight='balanced',\n",
    "    max_iter=1000)\n",
    "lr_ridge_cv_2.fit(X_train_p, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0.8507769 , 0.99853415, 1.        , 1.        ],\n",
       "        [0.88155966, 1.        , 1.        , 1.        ],\n",
       "        [0.87716212, 0.99970683, 1.        , 1.        ]])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance during cross-validation\n",
    "lr_ridge_cv_2.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance on test set\n",
    "lr_ridge_cv_2.score(X_test_small_p, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defaults solver did in fact get rid of the convergence warnings.\n",
    "\n",
    "Next, try Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(lr_ridge, 'lr_ridge.Joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=4, class_weight='balanced', cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l1', random_state=1,\n",
       "           refit=True, scoring=None, solver='saga', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso CV (Stochastic gradient descent, default number of iterations\n",
    "lr_lasso_cv = LogisticRegressionCV(Cs = 4, solver='saga', cv=3,\n",
    "    random_state=1, penalty='l1', class_weight='balanced')\n",
    "lr_lasso_cv.fit(X_train_p, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0.20463207, 0.9961888 , 0.99706831, 0.99736148],\n",
       "        [0.79536793, 0.99882732, 1.        , 1.        ],\n",
       "        [0.79536793, 0.99794782, 0.99970683, 0.99970683]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_lasso_cv.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_lasso_cv.score(X_test_small_p, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier (elastic net) + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='elasticnet',\n",
       "       power_t=0.5, random_state=1, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'l1_ratio': array([0.     , 0.33333, 0.66667, 1.     ]), 'alpha': array([1.00000e-10, 4.64159e-07, 2.15443e-03, 1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elastic net, logistic regression (Loss='log')\n",
    "lr_en = SGDClassifier(loss='log', penalty='elasticnet', random_state=1,\n",
    "                   class_weight='balanced', n_jobs=1) \n",
    "\n",
    "# Parameters to search over\n",
    "grid={'l1_ratio': np.linspace(0, 1, 4),\n",
    "      'alpha': np.logspace(-10, 1, 4)}\n",
    "\n",
    "# With iid = True\n",
    "gscv_t = GridSearchCV(lr_en, param_grid=grid, iid=True, cv=3, n_jobs=3)\n",
    "gscv_t.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation accuracy\n",
    "gscv_t.score(X_test_small_p, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(gscv_t, 'gscv_t.joblib') # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='elasticnet',\n",
       "       power_t=0.5, random_state=1, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=False, n_jobs=3,\n",
       "       param_grid={'l1_ratio': array([0.     , 0.33333, 0.66667, 1.     ]), 'alpha': array([1.00000e-10, 4.64159e-07, 2.15443e-03, 1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With iid = False\n",
    "gscv_f = GridSearchCV(lr_en, param_grid=grid, iid=False, cv=3, n_jobs=3)\n",
    "gscv_f.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_f.score(X_test_small_p, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(gscv_f, 'gscv_f.joblib') # Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the results. I'm displaying the accuracy for all folds here, because in previous iterations they sometimes widely differed. (In fact, the problems occurred when I was still trying to use all the data, so it is particularly surprising that with almost a million observations, there would be such severe overfitting).\n",
    "\n",
    "Note: the higher alpha, the *stronger* the regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.995602</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.995309</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.998974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.995798</td>\n",
       "      <td>0.997410</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.991498</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.994870</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.996677</td>\n",
       "      <td>0.998632</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.994137</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.998632</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.999414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.997752</td>\n",
       "      <td>0.997850</td>\n",
       "      <td>0.996189</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.998094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.997850</td>\n",
       "      <td>0.998290</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>0.997801</td>\n",
       "      <td>0.998681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.995407</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.995309</td>\n",
       "      <td>0.993550</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.997801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.808365</td>\n",
       "      <td>0.812274</td>\n",
       "      <td>0.823805</td>\n",
       "      <td>0.800059</td>\n",
       "      <td>0.801231</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>0.800938</td>\n",
       "      <td>0.803283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_test_score  mean_train_score  split0_test_score  \\\n",
       "params                                                                                                     \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.0}                          0.997264          0.997019           0.996775   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}           0.997264          0.997019           0.996775   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}           0.997264          0.997019           0.996775   \n",
       "{'alpha': 1e-10, 'l1_ratio': 1.0}                          0.997264          0.997019           0.996775   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}         0.996482          0.997117           0.996482   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...         0.995798          0.997410           0.996775   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...         0.996677          0.998632           0.997655   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}         0.998632          0.999316           0.998241   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}           0.999511          0.999805           0.999120   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.3...         0.997752          0.997850           0.996189   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.6...         0.997850          0.998290           0.996482   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}           0.995407          0.996775           0.995309   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.0}                           0.808365          0.812274           0.823805   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}            0.795368          0.795368           0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}            0.795368          0.795368           0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 1.0}                           0.795368          0.795368           0.795368   \n",
       "\n",
       "                                                    split1_test_score  split2_test_score  split0_train_score  \\\n",
       "params                                                                                                         \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.0}                            0.997948           0.997068            0.994283   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}             0.997948           0.997068            0.994283   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}             0.997948           0.997068            0.994283   \n",
       "{'alpha': 1e-10, 'l1_ratio': 1.0}                            0.997948           0.997068            0.994283   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}           0.995602           0.997361            0.995309   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...           0.991498           0.999120            0.997361   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...           0.994137           0.998241            0.998681   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}           0.998534           0.999120            0.999707   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}             0.999707           0.999707            0.999853   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.3...           0.998827           0.998241            0.998388   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.6...           0.999414           0.997655            0.998388   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}             0.993550           0.997361            0.997068   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.0}                             0.800059           0.801231            0.832600   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}              0.795368           0.795368            0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}              0.795368           0.795368            0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 1.0}                             0.795368           0.795368            0.795368   \n",
       "\n",
       "                                                    split1_train_score  split2_train_score  \n",
       "params                                                                                      \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.0}                             0.998827            0.997948  \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}              0.998827            0.997948  \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}              0.998827            0.997948  \n",
       "{'alpha': 1e-10, 'l1_ratio': 1.0}                             0.998827            0.997948  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}            0.997068            0.998974  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...            0.994870            1.000000  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...            0.997361            0.999853  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}            0.998827            0.999414  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}              0.999707            0.999853  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.3...            0.997068            0.998094  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.6...            0.997801            0.998681  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}              0.995456            0.997801  \n",
       "{'alpha': 10.0, 'l1_ratio': 0.0}                              0.800938            0.803283  \n",
       "{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}               0.795368            0.795368  \n",
       "{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}               0.795368            0.795368  \n",
       "{'alpha': 10.0, 'l1_ratio': 1.0}                              0.795368            0.795368  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gscv_t.cv_results_) \\\n",
    "    .set_index('params') \\\n",
    "    .loc[:,['mean_test_score', 'mean_train_score',\n",
    "           'split0_test_score', 'split1_test_score','split2_test_score',\n",
    "           'split0_train_score', 'split1_train_score','split2_train_score']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 1e-10, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.995602</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.995309</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.998974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.995798</td>\n",
       "      <td>0.997410</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.991498</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.994870</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.996677</td>\n",
       "      <td>0.998632</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.994137</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.998632</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.999414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.997752</td>\n",
       "      <td>0.997850</td>\n",
       "      <td>0.996189</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.998094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.997850</td>\n",
       "      <td>0.998290</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>0.997801</td>\n",
       "      <td>0.998681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.995407</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.995309</td>\n",
       "      <td>0.993550</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.997801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 0.0}</th>\n",
       "      <td>0.808365</td>\n",
       "      <td>0.812274</td>\n",
       "      <td>0.823805</td>\n",
       "      <td>0.800059</td>\n",
       "      <td>0.801231</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>0.800938</td>\n",
       "      <td>0.803283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}</th>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}</th>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'alpha': 10.0, 'l1_ratio': 1.0}</th>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_test_score  mean_train_score  split0_test_score  \\\n",
       "params                                                                                                     \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.0}                          0.997264          0.997019           0.996775   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}           0.997264          0.997019           0.996775   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}           0.997264          0.997019           0.996775   \n",
       "{'alpha': 1e-10, 'l1_ratio': 1.0}                          0.997264          0.997019           0.996775   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}         0.996482          0.997117           0.996482   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...         0.995798          0.997410           0.996775   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...         0.996677          0.998632           0.997655   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}         0.998632          0.999316           0.998241   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}           0.999511          0.999805           0.999120   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.3...         0.997752          0.997850           0.996189   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.6...         0.997850          0.998290           0.996482   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}           0.995407          0.996775           0.995309   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.0}                           0.808365          0.812274           0.823805   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}            0.795368          0.795368           0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}            0.795368          0.795368           0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 1.0}                           0.795368          0.795368           0.795368   \n",
       "\n",
       "                                                    split1_test_score  split2_test_score  split0_train_score  \\\n",
       "params                                                                                                         \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.0}                            0.997948           0.997068            0.994283   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}             0.997948           0.997068            0.994283   \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}             0.997948           0.997068            0.994283   \n",
       "{'alpha': 1e-10, 'l1_ratio': 1.0}                            0.997948           0.997068            0.994283   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}           0.995602           0.997361            0.995309   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...           0.991498           0.999120            0.997361   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...           0.994137           0.998241            0.998681   \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}           0.998534           0.999120            0.999707   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}             0.999707           0.999707            0.999853   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.3...           0.998827           0.998241            0.998388   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.6...           0.999414           0.997655            0.998388   \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}             0.993550           0.997361            0.997068   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.0}                             0.800059           0.801231            0.832600   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}              0.795368           0.795368            0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}              0.795368           0.795368            0.795368   \n",
       "{'alpha': 10.0, 'l1_ratio': 1.0}                             0.795368           0.795368            0.795368   \n",
       "\n",
       "                                                    split1_train_score  split2_train_score  \n",
       "params                                                                                      \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.0}                             0.998827            0.997948  \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.3333333333333333}              0.998827            0.997948  \n",
       "{'alpha': 1e-10, 'l1_ratio': 0.6666666666666666}              0.998827            0.997948  \n",
       "{'alpha': 1e-10, 'l1_ratio': 1.0}                             0.998827            0.997948  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0.0}            0.997068            0.998974  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...            0.994870            1.000000  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 0...            0.997361            0.999853  \n",
       "{'alpha': 4.6415888336127725e-07, 'l1_ratio': 1.0}            0.998827            0.999414  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.0}              0.999707            0.999853  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.3...            0.997068            0.998094  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 0.6...            0.997801            0.998681  \n",
       "{'alpha': 0.002154434690031882, 'l1_ratio': 1.0}              0.995456            0.997801  \n",
       "{'alpha': 10.0, 'l1_ratio': 0.0}                              0.800938            0.803283  \n",
       "{'alpha': 10.0, 'l1_ratio': 0.3333333333333333}               0.795368            0.795368  \n",
       "{'alpha': 10.0, 'l1_ratio': 0.6666666666666666}               0.795368            0.795368  \n",
       "{'alpha': 10.0, 'l1_ratio': 1.0}                              0.795368            0.795368  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gscv_f.cv_results_) \\\n",
    "    .set_index('params') \\\n",
    "    .loc[:,['mean_test_score', 'mean_train_score',\n",
    "            'split0_test_score', 'split1_test_score','split2_test_score',\n",
    "            'split0_train_score', 'split1_train_score','split2_train_score']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-2754bc4fafb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Raise error, because we only want to execute the next cell manually\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Raise error, because we only want to execute the next cells manually\n",
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
