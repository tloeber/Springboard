{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Estimate-or-load-models-and-make-predictions\" data-toc-modified-id=\"Estimate-or-load-models-and-make-predictions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Estimate or load models and make predictions</a></span></li><li><span><a href=\"#Voting-classifier\" data-toc-modified-id=\"Voting-classifier-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Voting classifier</a></span></li><li><span><a href=\"#Adjust-the-decision-threshold\" data-toc-modified-id=\"Adjust-the-decision-threshold-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Adjust the decision threshold</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-regression\" data-toc-modified-id=\"Linear-regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Linear regression</a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>SVM</a></span></li><li><span><a href=\"#Other\" data-toc-modified-id=\"Other-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Other</a></span></li></ul></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#HpSklearn\" data-toc-modified-id=\"HpSklearn-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>HpSklearn</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Hyperopt</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    " \n",
    "import missingno  # for visualizing missing data\n",
    " \n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    GridSearchCV, ShuffleSplit\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, \\\n",
    "    LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    precision_score, recall_score, \\\n",
    "    precision_recall_curve, average_precision_score, f1_score, \\\n",
    "    roc_curve, auc, roc_auc_score, make_scorer,\\\n",
    "    accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "\n",
    "# Set up pandas table display\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Set plotting options\n",
    "sns.set() # Use seaborn defaults for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# Adjust number of CPU cores to use\n",
    "n_jobs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training and test set, incl. feature names \n",
    "X_train_small = joblib.load('data_processed/X_train_small.joblib')\n",
    "X_test_small = joblib.load('data_processed/X_test_small.joblib')\n",
    "y_train_small = joblib.load('data_processed/y_train_small.joblib')\n",
    "y_test_small = joblib.load('data_processed/y_test_small.joblib')\n",
    "# feature_names_small = joblib.load('data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store results for SMALL data set\n",
    "average_precision_1 = {}\n",
    "classification_reports_1 = {}\n",
    "most_important_features_1 = {} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate or load models and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "        oob_score=False, n_jobs=n_jobs, random_state=1,\n",
    "        class_weight='balanced_subsample')\n",
    "rf.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "lr_gs_1 = joblib.load('saved_models/lr_gs_1.joblib')\n",
    "svm_lin_gs_1 = joblib.load('saved_models/svm_lin_gs_1.joblib')\n",
    "svm_rbf_gs_1 = joblib.load('saved_models/svm_rbf_gs_1.joblib')\n",
    "svm_poly_gs_1 = joblib.load('saved_models/svm_poly_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the test set into validation set and proper test set for stacking\n",
    "# X_val, X_t, y_val, y_t = train_test_split(\n",
    "#     X_test_small, y_test_small, train_size=0.5, test_size=0.5,\n",
    "#     stratify=y_test_small, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predicted probability or distance from separating hyperplane \n",
    "\n",
    "# For TRAINING data:\n",
    "y_proba_rf_tr = rf.predict_proba(X_train_small)[:, 1]\n",
    "y_proba_lr_tr = lr_gs_1.predict_proba(X_train_small)[:, 1]\n",
    "y_dist_svm_lin_tr = svm_lin_gs_1.decision_function(X_train_small)\n",
    "y_dist_svm_rbf_tr = svm_rbf_gs_1.decision_function(X_train_small)\n",
    "y_dist_svm_poly_tr = svm_poly_gs_1.decision_function(X_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For TEST data:\n",
    "y_proba_rf_1 = rf.predict_proba(X_test_small)[:, 1]\n",
    "y_proba_lr_1 = lr_gs_1.predict_proba(X_test_small)[:, 1]\n",
    "y_dist_svm_lin_1 = svm_lin_gs_1.decision_function(X_test_small)\n",
    "y_dist_svm_rbf_1 = svm_rbf_gs_1.decision_function(X_test_small)\n",
    "y_dist_svm_poly_1 = svm_poly_gs_1.decision_function(X_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the decision threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to make a prediction with custom threshold\n",
    "def custom_prediction(proba_or_dist, threshold):\n",
    "    \"\"\"\n",
    "    Makes predictions for binary classification from probabilities or distance\n",
    "    to separating hyperplane, given a custom threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    return (proba_or_dist > threshold).astype(int)\n",
    "\n",
    "\n",
    "# Define function to plot effect of threshold on precision and recall\n",
    "def plot_threshold(proba_or_dist, y_true, thresholds=None):\n",
    "    \"\"\"\n",
    "    Plot precision and recall as a function of decision threshold for an array of\n",
    "    probabilities or distances to separating hyperplane.\n",
    "\n",
    "    If no custom list of thresholds is supplied, it defaults to a grid of length \n",
    "    100, spanning between the minimum and maximum probability/distance. (In\n",
    "    order to avoid thresholds that assign all observations to a single class, \n",
    "    the smallest and largest thresholds are offset by 0.01 from the minimum and \n",
    "    maximum probability/distance.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    proba_or_dist: array-like\n",
    "        Probabilities or distance from separating hyperplane\n",
    "    y_true: array-like\n",
    "        True values of target variable.\n",
    "    thresholds: list-like\n",
    "        Custom thresholds. Optional.  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize dictionaries to store results\n",
    "    classes = {}\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "            \n",
    "    # If no custom thresholds were passed, make grid between minimum and maximum\n",
    "    # values for probability or distance.\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(proba_or_dist.min() + 0.01,\n",
    "                                 proba_or_dist.max() - 0.01, 100)\n",
    "\n",
    "    # Iterate over thresholds\n",
    "    for threshold in thresholds:\n",
    "        # Classify as 1 if probability/distance is greater than threshold, else 0\n",
    "        classes[threshold] = custom_prediction(proba_or_dist, threshold)\n",
    "\n",
    "        # Compute precision and recall\n",
    "        precisions[threshold] = precision_score(y_true, classes[threshold])\n",
    "        recalls[threshold] = recall_score(y_true, classes[threshold])\n",
    "\n",
    "    # Combine precision and recall into a data frame, indexed by threshold\n",
    "    pr_rec = pd.DataFrame({'precision': precisions, 'recall': recalls})\n",
    "\n",
    "    # Plot results\n",
    "    pr_rec.plot()\n",
    "    plt.title('Effect of threshold on Precision and Recall')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Precision\\nRecall')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot effect of probability threshold for linear regression\n",
    "plot_threshold(proba_or_dist=y_proba_lr_1, y_true=y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr_custom = custom_prediction(y_proba_lr_1, 0.4)\n",
    "print(classification_report(y_test_small, y_lr_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr_custom = custom_prediction(y_proba_lr_1, 0.4)\n",
    "def plot_confusion_matrix(y_test, y_pred, digits=3):\n",
    "    cf = pd.DataFrame(confusion_matrix(y_test, y_pred,\n",
    "                                      labels=[1,0]),\n",
    "                      columns=['True', 'False'])\n",
    "    cf.index=['True', 'False']\n",
    "    cf.columns.name = 'Predicted'\n",
    "    cf.index.name = 'Actual'\n",
    "    print(round(cf / len(y_test), digits))    \n",
    "\n",
    "# Plot confusion matrix \n",
    "plot_confusion_matrix(y_test_small, y_lr_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot effect of probability threshold for linear regression\n",
    "plot_threshold(proba_or_dist=y_dist_svm_lin_1, y_true=y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svm_lin_custom = custom_prediction(y_dist_svm_lin_1, -0.5)\n",
    "print(classification_report(y_test_small, y_svm_lin_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svm_lin_custom = custom_prediction(y_dist_svm_lin_1, -0.4)\n",
    "def plot_confusion_matrix(y_test, y_pred, digits=3):\n",
    "    cf = pd.DataFrame(confusion_matrix(y_test, y_pred,\n",
    "                                      labels=[1,0]),\n",
    "                      columns=['True', 'False'])\n",
    "    cf.index=['True', 'False']\n",
    "    cf.columns.name = 'Predicted'\n",
    "    cf.index.name = 'Actual'\n",
    "    print(round(cf / len(y_test), digits))    \n",
    "\n",
    "# Plot confusion matrix \n",
    "plot_confusion_matrix(y_test_small, y_svm_lin_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def plot_roc(y_test, y_pred, model_name=None):\n",
    "#         false_positive_rate, true_positive_rate, thresholds = \\\n",
    "#             roc_curve(y_test, y_pred)\n",
    "#         roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#         plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "#                  label='AUC = {0:.3f}'.format(roc_auc))\n",
    "#         plt.legend(loc='lower right')\n",
    "#         plt.plot([0, 1],[0, 1], 'r--')\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         title='ROC Curve'\n",
    "#         # Add custom title, if specified\n",
    "#         if model_name is not None:\n",
    "#             title = ', '.join([title, model_name])\n",
    "#         plt.title(title)\n",
    "#         plt.show();\n",
    "\n",
    "#     # Plot ROC curve for random forests\n",
    "#     y_proba_rf = rf.predict_proba(X_test_p)[:, 1]\n",
    "#     plot_roc(y_test, y_proba_rf, 'Random Forests')\n",
    "\n",
    "\n",
    "#     def plot_precision_recall(y_test, y_pred):\n",
    "#         \"\"\"Plots precision-recall curve.\"\"\"\n",
    "\n",
    "#         average_precision = average_precision_score(y_test, y_pred)\n",
    "#         precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "#         # pdb.set_trace()\n",
    "#         step_kwargs = ({'step': 'post'}\n",
    "#                        if 'step' in signature(plt.fill_between).parameters\n",
    "#                        else {})\n",
    "#         plt.step(recall, precision, color='b', alpha=0.2,\n",
    "#                  where='post')\n",
    "#         plt.figtext(0.2, 0.2, 'Average Precision={0:0.3f}' \\\n",
    "#                                         .format(average_precision))\n",
    "#         plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "#         plt.xlabel('Recall')\n",
    "#         plt.ylabel('Precision')\n",
    "#         plt.ylim([0.0, 1.05])\n",
    "#         plt.xlim([0.0, 1.0])\n",
    "#         plt.title('Precision-Recall curve')\n",
    "#         plt.show();\n",
    "\n",
    "#     # Plot precision recall curve for random forests classifier\n",
    "#     plot_precision_recall(y_test, y_proba_rf)\n",
    "\n",
    "#     # Get a list of feature names\n",
    "#     cat_names = preprocessor.named_transformers_['cat'] \\\n",
    "#                     .named_steps['onehot'].get_feature_names()\n",
    "#     feature_names = list(numeric_features) + list(cat_names)\n",
    "#     # Compute feature importance and sort\n",
    "#     feature_importances = pd.Series(\n",
    "#                                 rf.feature_importances_,\n",
    "#                                 index=feature_names) \\\n",
    "#                             .sort_values(ascending=False)\n",
    "#     print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_train = xgb.DMatrix(data=X_train_small, label=y_train_small)\n",
    "# X_train_small_dmat = xgb.DMatrix(X_train_small)\n",
    "# X_test_small_dmat = xgb.DMatrix(X_test_small)\n",
    "# y_train_small_dmat = xgb.DMatrix(y_train_small[:, np.newaxis])\n",
    "# y_test_small_dmat = xgb.DMatrix(y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specify parameters via map\n",
    "# param = {'objective':'binary:logistic', 'eval_metric':'map',\n",
    "#          'scale_pos_weight':5  # Balance class weight\n",
    "#          'seed':0}\n",
    "# num_round = 2\n",
    "\n",
    "# train(param, X_train_small, num_round)\n",
    "# y_pred = xgb_.predict(X_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ = xgb.XGBClassifier(objective='binary:logistic', eval_metric='map',\n",
    "                         scale_pos_weight=5,  # Balance class weight\n",
    "                         seed=0, nthread=n_jobs)\n",
    "# xgb_.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'max_depth'= [3, 5, 7, 10],  # Control complexity\n",
    "              'min_child_weight'= , # The higher, the more regularization\n",
    "              'gamma'= , # Higher value leads to fewer splits for a given node (i.e. more regularization) if\n",
    "              'subsample'= [0.5, 0.75, 1],  # Fraction of observations per tree \n",
    "              'colsample_bytree': [0.5, 0.75, 1]} # Fraction of features per tree\n",
    "# Grid search\n",
    "xgb_gs_1 = GridSearchCV(xgb_1, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=n_jobs, cv=3, verbose=5)\n",
    "xgb_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(xgb_gs_1, 'saved_models/xgb_gs_1.joblib')\n",
    "\n",
    "# Predictions\n",
    "y_proba_xgb = xgb_.predict_proba(X_test_small)[:, 1]\n",
    "average_precision_score(y_test_small, y_proba_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':'binary:logistic', 'eval_metric':'map',\n",
    "         'scale_pos_weight':5,  # Balance class weight\n",
    "         'seed':0}\n",
    "xgb_cv = xgb.cv(dtrain=data_xgb_train, params=params, nfold=3,\n",
    "                num_boost_round=50, as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb_cv = xgb_cv.predict(X_test_small)\n",
    "average_precision_score(y_test_small, y_xgb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HpSklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator, svc\n",
    "import hyperopt \n",
    "\n",
    "# svc_class_weight = 'balanced'\n",
    "svc_C = 10\n",
    "svm_rbf_1 = svc(name='svm_rbf_1', kernels=['rbf'], C=svc_C)\n",
    "#                 class_weight=svc_class_weight) #'balanced',\n",
    "#                 probability=False, cache_size=5000,\n",
    "#                 random_state=1)\n",
    "svm_rbf_hp_1 = HyperoptEstimator(classifier=svm_rbf_1,\n",
    "                                 algo=hyperopt.tpe.suggest,\n",
    "                                 max_evals=5)\n",
    "\n",
    "svm_rbf_hp_1.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Hyperopt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define hyperparameter search space\n",
    "space = {\n",
    "    'kernel': 'rbf',\n",
    "    'cache_size': 10000,\n",
    "    'class_weight': 'balanced',\n",
    "    'random_state': 1\n",
    "    'C': hp.uniform('C', 1E-10, 1E10),\n",
    "    'gamma': hp.uniform('gamma', 1E-5, 1E8),\n",
    "}\n",
    "\n",
    "# Function to minimize\n",
    "N_FOLDS=3\n",
    "N_JOBS=-2\n",
    "def objective(params, n_folds=N_FOLDS, n_jobs=N_JOBS):\n",
    "    \"\"\"Objective function to minimize\"\"\"\n",
    "    \n",
    "    # Instantiate estimator\n",
    "    clf = SVC(**params)\n",
    "    \n",
    "    # Cross-validation object\n",
    "    cv = StratifiedKFold(n_folds, random_state=1)\n",
    "    \n",
    "    # Compute average precision through CV\n",
    "    score = cross_val_score(clf, X_train_small, y_train_small, cv=cv,\n",
    "                            scoring='average_precision', n_jobs=n_jobs)\n",
    "    \n",
    "    # Return results\n",
    "    return {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "# Trials object to track progress\n",
    "trials = Trials()\n",
    "\n",
    "# Minimize objective\n",
    "MAX_EVALS=50 \n",
    "best = fmin(objective, space, algo=tpe.suggest,\n",
    "            max_evals=MAX_EVALS, trials=trials)\n",
    "\n",
    "print ('Best parameters: {}'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values of the optimal parameters\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "# Fit the model with the optimal hyperparamters\n",
    "SVC.set_params(**best_params)\n",
    "SVC.fit(X_train_small, y_train_small);\n",
    "\n",
    "# Score with the test data\n",
    "y_score = SVC.predict_proba(X_test_small)\n",
    "ap_score = average_precision_score(y_test_small, y_score[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
