{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Predictive-models\" data-toc-modified-id=\"Predictive-models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Predictive models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forests\" data-toc-modified-id=\"Random-Forests-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Random Forests</a></span></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-all-data\" data-toc-modified-id=\"With-all-data-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>With all data</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Support Vector Machine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-SVM\" data-toc-modified-id=\"Linear-SVM-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Linear SVM</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.1.1\"><span class=\"toc-item-num\">2.4.1.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-whole-data-set\" data-toc-modified-id=\"With-whole-data-set-2.4.1.2\"><span class=\"toc-item-num\">2.4.1.2&nbsp;&nbsp;</span>With whole data set</a></span></li></ul></li><li><span><a href=\"#SVM-with-RBF-Kernel\" data-toc-modified-id=\"SVM-with-RBF-Kernel-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>SVM with RBF-Kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.2.1\"><span class=\"toc-item-num\">2.4.2.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-more-data\" data-toc-modified-id=\"With-more-data-2.4.2.2\"><span class=\"toc-item-num\">2.4.2.2&nbsp;&nbsp;</span>With more data</a></span></li></ul></li><li><span><a href=\"#SVM-with-polynomial-kernel\" data-toc-modified-id=\"SVM-with-polynomial-kernel-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>SVM with polynomial kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.3.1\"><span class=\"toc-item-num\">2.4.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Performance-comparison\" data-toc-modified-id=\"Performance-comparison-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Performance comparison</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    " \n",
    "import missingno  # for visualizing missing data\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    GridSearchCV, ShuffleSplit\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, \\\n",
    "    LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    precision_recall_curve, average_precision_score, f1_score, \\\n",
    "    roc_curve, auc, roc_auc_score, make_scorer,\\\n",
    "    accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "\n",
    "# Set up pandas table display\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Set plotting options\n",
    "sns.set() # Use seaborn defaults for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# Adjust number of CPU cores to use\n",
    "n_jobs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-21-e60910363dbf>(31)split_preprocess()\n",
      "-> numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
      "(Pdb) X_train.shape\n",
      "(20000, 86)\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e60910363dbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;31m# Create smaller training and test data to start out with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m \u001b[0mX_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names_small\u001b[0m\u001b[1;33m=\u001b[0m     \u001b[0msplit_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-e60910363dbf>\u001b[0m in \u001b[0;36msplit_preprocess\u001b[1;34m(X, y, train_size, test_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# =============\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Imputation and standardization for numeric features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mnumeric_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     numeric_transformer = Pipeline(steps =[\n\u001b[0;32m     33\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'imputer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-e60910363dbf>\u001b[0m in \u001b[0;36msplit_preprocess\u001b[1;34m(X, y, train_size, test_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# =============\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Imputation and standardization for numeric features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mnumeric_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     numeric_transformer = Pipeline(steps =[\n\u001b[0;32m     33\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'imputer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load original data\n",
    "with open('data_processed/all_data.pickle', 'rb') as pickled_file: \n",
    "    all_data = pickle.load(pickled_file) \n",
    "    \n",
    "    \n",
    "# Find categorical variables with more than 50 unique values and drop them\n",
    "unique_values_cat = all_data.select_dtypes(include='object') \\\n",
    "                        .nunique() \\\n",
    "                        .sort_values(ascending=False) \n",
    "# Drop categorical variables with more than 50 categories\n",
    "all_data = all_data.drop(unique_values_cat[unique_values_cat > 50].index,\n",
    "                 axis='columns')\n",
    "\n",
    "\n",
    "def split_preprocess(X=all_data.drop('default', axis='columns'),\n",
    "                     y=all_data.default,\n",
    "                     train_size=.8, test_size=.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test set of specified size, \n",
    "    then applies preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train-test split \n",
    "    # ================\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y,\n",
    "                         train_size=train_size, test_size=test_size,\n",
    "                         random_state=1, shuffle=True, stratify=y) \n",
    "\n",
    "    pdb.set_trace()\n",
    "    # Preprocessing\n",
    "    # =============\n",
    "    # Imputation and standardization for numeric features\n",
    "    numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "    numeric_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())]) \n",
    "\n",
    "    # Imputation and one-hot encoding for categorical features\n",
    "    categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "    categorical_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Combining preprocessing for both kinds of features\n",
    "    # (Features of other dtypes – in our case, boolean – will be\n",
    "    # appended at the end without transformation.)\n",
    "    # (Use only 1 core to avoid joblib error)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric_transformer', \n",
    "                 numeric_transformer, numeric_features),\n",
    "            ('categorical_transformer', \n",
    "                 categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough', n_jobs=1) \n",
    "    \n",
    "    # Print dtypes of untransformed data\n",
    "    print('data types of columns that were not transformed:\\n {}'\n",
    "            .format(X_train.select_dtypes(exclude=[np.number, object]) \\\n",
    "                    .dtypes.unique()))\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_p = preprocessor.fit_transform(X_train)\n",
    "    X_test_p = preprocessor.transform(X_test)\n",
    "   \n",
    "\n",
    "    # Get feature names\n",
    "    # =================\n",
    "    # Names of categorical variables after one-hot encoding\n",
    "    categorical_names = preprocessor \\\n",
    "        .named_transformers_['categorical_transformer'] \\\n",
    "        .named_steps['onehot'] \\\n",
    "        .get_feature_names()\n",
    "    # Names of columns with other dtype (should only be Boolean)\n",
    "    other_names = X_train \\\n",
    "        .select_dtypes(exclude=[np.number, object]) \\\n",
    "        .columns\n",
    "    # Concatenate feature names (Note that list with names of \n",
    "    # numeric features was already created above)\n",
    "    feature_names = list(numeric_features) + \\\n",
    "        list(categorical_names) + list(other_names) \n",
    "\n",
    "    \n",
    "    # Return results\n",
    "    # ==============\n",
    "    return(X_train_p, X_test_p, y_train, y_test, feature_names)\n",
    "  \n",
    "    \n",
    "# Create smaller training and test data to start out with\n",
    "X_train_small, X_test_small, y_train_small, y_test_small, feature_names_small= \\\n",
    "    split_preprocess(train_size=20000, test_size=10000)\n",
    "\n",
    "# Create full training and test set\n",
    "X_train, X_test, y_train, y_test, feature_names = \\\n",
    "    split_preprocess(train_size=.8, test_size=.2)\n",
    "\n",
    "\n",
    "# Save preprocessed training and test sets\n",
    "filenames_whole = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "filenames_small = [filename + '_small' for filename in filenames]\n",
    "filenames = filenames_whole + filenames_small\n",
    "files = [X_train, X_test, y_train, y_test,\n",
    "         X_train_small, X_test_small, y_train_small, y_test_small]\n",
    "\n",
    "for file, filename in zip(files, filenames):\n",
    "    joblib.dump(file,\n",
    "                'data_processed/{}.joblib'.format(filename))\n",
    "# Delete temporary list to conserve memory\n",
    "del files\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(feature_names, 'data_procesesd/feature_names')\n",
    "joblib.dump(feature_names_small, 'data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training and test set, incl. feature names \n",
    "X_train = joblib.load('data_processed/X_train.joblib')\n",
    "X_test = joblib.load('data_processed/X_test.joblib')\n",
    "y_train = joblib.load('data_processed/y_train.joblib')\n",
    "y_test = joblib.load('data_processed/y_test.joblib')\n",
    "X_train_small = joblib.load('data_processed/X_train_small.joblib')\n",
    "X_test_small = joblib.load('data_processed/X_test_small.joblib')\n",
    "y_train_small = joblib.load('data_processed/y_train_small.joblib')\n",
    "y_test_small = joblib.load('data_processed/y_test_small.joblib')\n",
    "# feature_names = joblib.load('data_processed/feature_names')\n",
    "# feature_names_small = joblib.load('data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store results for SMALL data set\n",
    "average_precision_1 = {}\n",
    "classification_reports_1 = {}\n",
    "most_important_features_1 = {} \n",
    "# Note that models with small data were estimated on a different subset\n",
    "# of the observations, though the size stayed constant.  So don't use future \n",
    "# importance on these data, unless re-estimating models!\n",
    "\n",
    "# Dictionaries to store results for WHOLE data set\n",
    "average_precision_2 = {}\n",
    "classification_reports_2 = {}\n",
    "most_important_features_2 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-70f4defc76f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Save results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0maverage_precision\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random forests'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m     \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba_rf_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mclassification_reports\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random forests'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m     \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_rf_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_small' is not defined"
     ]
    }
   ],
   "source": [
    "rf_1 = RandomForestClassifier(n_estimators=100, \n",
    "        oob_score=False, n_jobs=n_jobs, random_state=1,\n",
    "        class_weight='balanced_subsample')\n",
    "rf_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Predictions of class and probability\n",
    "y_pred_rf_1 = rf_1.predict(X_test_small) \n",
    "y_pred_proba_rf_1 = rf_1.predict_proba(X_test_small)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision['random forests'] = \\\n",
    "    average_precision_score(y_small, y_pred_proba_rf_1)\n",
    "classification_reports['random forests'] = \\\n",
    "    classification_report(y_small, y_pred_rf_1)\n",
    "\n",
    "# Compute feature importance and sort\n",
    "most_important_features['random forests'] = \\\n",
    "    pd.Series(rf_1.feature_importances_, index=feature_names) \\\n",
    "            .sort_values(ascending=False) \\\n",
    "            .iloc[: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_train = xgb.DMatrix(data=X_train_small, label=y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cv() got an unexpected keyword argument 'eval_metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1c09cb7084a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                seed=0, nthread=n_jobs)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mxgb_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_small\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cv() got an unexpected keyword argument 'eval_metric'"
     ]
    }
   ],
   "source": [
    "xgb_1 = xgb.cv(objective='binary:logistic', \n",
    "               eval_metric='map',\n",
    "               scale_pos_weight=5,  # Balance class weight\n",
    "               learning_rate=0.1, n_estimators=1000,\n",
    "               max_depth=5,min_child_weight=1, gamma=0,\n",
    "               subsample=0.8, colsample_bytree=0.8,\n",
    "               seed=0, nthread=n_jobs)\n",
    "# xgb_1.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to search over\n",
    "param_grid = {'max_depth'= [3, 5, 7, 10],  # Control complexity\n",
    "              'min_child_weight'= , # The higher, the more regularization\n",
    "              'gamma'= , # Higher value leads to fewer splits for a given node (i.e. more regularization) if\n",
    "              'subsample'= [0.5, 0.75, 1],  # Fraction of observations per tree \n",
    "              'colsample_bytree': [0.5, 0.75, 1]} # Fraction of features per tree\n",
    "# Grid search\n",
    "xgb_gs_1 = GridSearchCV(xgb_1, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=n_jobs, cv=3, verbose=5)\n",
    "xgb_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(xgb_gs_1, 'saved_models/xgb_gs_1.joblib')\n",
    "\n",
    "# Predictions\n",
    "y_proba_xgb = xgb_.predict_proba(X_test_small)[:, 1]\n",
    "average_precision_score(y_test_small, y_proba_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22:01:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    }
   ],
   "source": [
    "params = {'objective':'binary:logistic', 'eval_metric':'map',\n",
    "         'scale_pos_weight':5,  # Balance class weight\n",
    "         'seed':0}\n",
    "xgb_cv = xgb.cv(dtrain=data_xgb_train, params=params, nfold=3,\n",
    "                num_boost_round=50, as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb_cv = xgb_cv.predict(X_test_small)\n",
    "average_precision_score(y_test_small, y_xgb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "#### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/lr_gs_1.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression (Elastic Net) \n",
    "# --------------------------------\n",
    "lr_1 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 1, 8)}\n",
    "# Grid search\n",
    "lr_gs_1 = GridSearchCV(lr_1, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=n_jobs, cv=3)\n",
    "lr_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_gs_1, 'saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_1 = joblib.load('saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0.01\n",
       "                      0.2\n",
       "mean_fit_time       0.337\n",
       "std_fit_time        0.067\n",
       "mean_score_time     0.006\n",
       "std_score_time      0.001\n",
       "param_alpha         0.010\n",
       "param_l1_ratio      0.200\n",
       "split0_test_score   0.380\n",
       "split1_test_score   0.394\n",
       "split2_test_score   0.378\n",
       "mean_test_score     0.384\n",
       "std_test_score      0.007\n",
       "rank_test_score     1.000\n",
       "split0_train_score  0.394\n",
       "split1_train_score  0.386\n",
       "split2_train_score  0.390\n",
       "mean_train_score    0.390\n",
       "std_train_score     0.003"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search results for iid = True for best parameters\n",
    "def gs_best_result(gridsearchcv, decimals=3):\n",
    "    \"\"\"Returns details for best results from grid search.\"\"\"\n",
    "\n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(gridsearchcv.cv_results_) \\\n",
    "                .drop('params', axis='columns')\n",
    "    \n",
    "    # Get values for hyperparameters \n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    \n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], axis=1)\n",
    "    # Set hyperparameters as index\n",
    "    scores_w_params = scores_w_params \\\n",
    "                        .set_index(params.columns.tolist())\n",
    "    \n",
    "    # Get tuple with best hyperparameters values, making sure it \n",
    "    # has the same order as the multi-index.\n",
    "    best_param_tuple = (\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[0]],\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[1]])\n",
    "    \n",
    "    # Filter results for best hyperparameters \n",
    "    best_result = pd.to_numeric(\n",
    "                    scores_w_params.loc[best_param_tuple, :])\n",
    "    \n",
    "    # Return rounded result (convert to dataframe for pretty  printing)\n",
    "    return(pd.DataFrame(best_result) \\\n",
    "               .round(decimals))\n",
    "\n",
    "gs_best_result(lr_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_lr_1= lr_gs_1.predict(X_test_small)    \n",
    "y_pred_proba_lr_1= lr_gs_1.predict_proba(X_test_small)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision_1['logistic regression'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_proba_lr_1)\n",
    "classification_reports_1['logistic regression'] = \\\n",
    "    classification_report(y_test_small, y_pred_lr_1)\n",
    "\n",
    "# Compute feature importance and sort\n",
    "most_important_features_1['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_1.best_estimator_.coef_[0], \n",
    "          index=feature_names_small) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "def gs_heatmap(gridsearchcv, x_digits=0, y_digits=0,\n",
    "               x_scientific_notation=True, y_scientific_notation=True):\n",
    "    \"\"\"Visualizes validation accuracy from grid search over two hyperparameters.\"\"\"\n",
    "    \n",
    "    # Print test score and  hyperparameters\n",
    "    print('Best score: {:.3f}, best hyperparameters: '\n",
    "                .format(gridsearchcv.best_score_), \n",
    "          gridsearchcv.best_params_)\n",
    "      \n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['mean_test_score'])\n",
    "    # Get values for hyperparameters\n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], \n",
    "                                  axis=1)\n",
    "    # Set first two columns, which correspond to parameters, as index.\n",
    "    # Then unstack.\n",
    "    index_cols = list(scores_w_params.columns)[:2]\n",
    "    scores_2d = scores_w_params.set_index(index_cols) \\\n",
    "                    .squeeze() \\\n",
    "                    .unstack()\n",
    "    \n",
    "    # Create desired formatting string for axes (scientific notation and digits)\n",
    "    if x_scientific_notation == True:\n",
    "        x_notation = 'E' \n",
    "    else: \n",
    "        x_notation = 'F'\n",
    "    x_formatting = '{:.' + str(x_digits) + x_notation + '}'\n",
    "\n",
    "    if y_scientific_notation == True:\n",
    "        y_notation = 'E' \n",
    "    else: \n",
    "        y_notation = 'F'\n",
    "    y_formatting = '{:.' + str(y_digits) + y_notation + '}'\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(scores_2d, ax=ax,\n",
    "                xticklabels=[x_formatting.format(x) for  x in scores_2d.columns],\n",
    "                yticklabels=[y_formatting.format(y) for y in scores_2d.index])\n",
    "    ax.set_title('Validation accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_gs_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-11bee19cb820>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mgs_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_gs_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_digits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_scientific_notation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_gs_1' is not defined"
     ]
    }
   ],
   "source": [
    "gs_heatmap(lr_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now estimate the model on all data. Based on the results from the smaller data set, we will adjust the parameter grade for alpha, the constant that multiplies the regularization term: We will drop all values for alpha greater than 0.1, since these did not give us good performance. \n",
    "\n",
    "Because we are now using more data, the optimal regularization term will be even smaller; thus, we leave the minimum value for alpha to search over constant, even though it did not give us great performance either on the smaller data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/lr_gs_2.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression (Elastic Net) \n",
    "# --------------------------------\n",
    "lr_2 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 0, 13)}\n",
    "\n",
    "# Grid search\n",
    "lr_gs_2 = GridSearchCV(lr_2, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=n_jobs, cv=5)\n",
    "lr_gs_2.fit(X_train, y_train) \n",
    "\n",
    "# Save model\n",
    "\n",
    "joblib.dump(lr_gs_2, 'saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_2 = joblib.load('saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_lr_2 = lr_gs_2.predict(X_test)\n",
    "y_pred_proba_lr_2 = lr_gs_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision_2['logistic regression'] = \\\n",
    "    average_precision_score(y_test, y_pred_proba_lr_2)\n",
    "classification_reports_2['logistic regression'] = \\\n",
    "    classification_report(y_test, y_pred_lr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-97f59ceb3e73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute feature importance and sort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m most_important_features_2['logistic regression'] =     pd.Series(lr_gs_2.best_estimator_.coef_[0], \n\u001b[1;32m----> 3\u001b[1;33m           index=feature_names) \\\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_names' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute feature importance and sort\n",
    "most_important_features_2['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_2.best_estimator_.coef_[0], \n",
    "          index=feature_names) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.391, best hyperparameters:  {'alpha': 0.00031622776601683794, 'l1_ratio': 0.2}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize grid search results    \n",
    "gs_heatmap(lr_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.66      0.76    162777\n",
      "           1       0.33      0.65      0.44     41888\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    204665\n",
      "   macro avg       0.61      0.66      0.60    204665\n",
      "weighted avg       0.77      0.66      0.69    204665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_reports_2['logistic regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/svm_lin_gs_1.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_1 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 3),\n",
    "              'alpha': np.logspace(-5, 1, 7)}\n",
    "svm_lin_gs_1 = GridSearchCV(svm_lin_1, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=n_jobs, cv=5)\n",
    "svm_lin_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_1, 'saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model\n",
    "svm_lin_gs_1 = joblib.load('saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.384, best hyperparameters:  {'alpha': 0.1, 'l1_ratio': 0.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_lin_1 = svm_lin_gs_1.predict(X_test_small)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_lin_1 = svm_lin_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_1)\n",
    "classification_reports_1['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_1)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat this analysis on the whole data set. Again, since more data will require less regularization, we will look at lower our maximum value for for to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/svm_lin_gs_2.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_2 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=n_jobs) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-5, -1, 9)}\n",
    "svm_lin_gs_2 = GridSearchCV(svm_lin_2, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=n_jobs, cv=5)\n",
    "svm_lin_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_2, 'saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_lin_gs_2 = joblib.load('saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.392, best hyperparameters:  {'alpha': 0.001, 'l1_ratio': 0.1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_2 = svm_lin_gs_2.predict(X_test)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_2 = svm_lin_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_2)\n",
    "classification_reports_2['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_2)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with RBF-Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_1 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'gamma': np.logspace(-5, 1, 8)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_rbf_gs_1 = GridSearchCV(svm_rbf_1, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_1, 'saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_1 = joblib.load('saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_1 = svm_rbf_gs_1.predict(X_test_small)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_1 = svm_rbf_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_rbf_1)\n",
    "\n",
    "classification_reports_1['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_rbf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.719686</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.003728</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>67.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>6.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_gamma</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.719686\n",
       "                   0.003728\n",
       "mean_fit_time        67.675\n",
       "std_fit_time          0.000\n",
       "mean_score_time       6.375\n",
       "std_score_time        0.000\n",
       "param_C               0.720\n",
       "param_gamma           0.004\n",
       "split0_test_score     0.402\n",
       "mean_test_score       0.402\n",
       "std_test_score        0.000\n",
       "rank_test_score       1.000\n",
       "split0_train_score    0.431\n",
       "mean_train_score      0.431\n",
       "std_train_score       0.000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_best_result(svm_rbf_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.402, best hyperparameters:  {'C': 0.7196856730011522, 'gamma': 0.003727593720314938}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs_heatmap(svm_rbf_gs_1) #, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.154882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.268241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>0.341731</td>\n",
       "      <td>0.341731</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.350184</td>\n",
       "      <td>0.350184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.016387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.258233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00372759</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.003727593720314938}</td>\n",
       "      <td>0.348639</td>\n",
       "      <td>0.348639</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.001978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.251251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.013894954943731374}</td>\n",
       "      <td>0.356746</td>\n",
       "      <td>0.356746</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.367547</td>\n",
       "      <td>0.367547</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.042341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.232261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.0517947467923121}</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>23</td>\n",
       "      <td>0.411679</td>\n",
       "      <td>0.411679</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.438465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.242256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.19306977288832497}</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>33</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85.304924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.361191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.7196856730011514}</td>\n",
       "      <td>0.237501</td>\n",
       "      <td>0.237501</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>81.086336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.398164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.6827</td>\n",
       "      <td>{'C': 0.001, 'gamma': 2.6826957952797246}</td>\n",
       "      <td>0.199725</td>\n",
       "      <td>0.199725</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>64</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>97.282040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.465988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.001, 'gamma': 10.0}</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79.237423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.243268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 0.001}</td>\n",
       "      <td>0.341731</td>\n",
       "      <td>0.341731</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.350184</td>\n",
       "      <td>0.350184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78.609828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.153308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>0.00372759</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 0.0037275...</td>\n",
       "      <td>0.354187</td>\n",
       "      <td>0.354187</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>20</td>\n",
       "      <td>0.362184</td>\n",
       "      <td>0.362184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>78.087059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.004405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 0.0138949...</td>\n",
       "      <td>0.361344</td>\n",
       "      <td>0.361344</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.374866</td>\n",
       "      <td>0.374866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>80.252871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.230263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 0.0517947...</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>23</td>\n",
       "      <td>0.411679</td>\n",
       "      <td>0.411679</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>78.666267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.236242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 0.1930697...</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>33</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>84.898140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.456134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 0.7196856...</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>80.555249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.367184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>2.6827</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 2.6826957...</td>\n",
       "      <td>0.200020</td>\n",
       "      <td>0.200020</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>55</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>97.197102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.435978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00517947</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.005179474679231213, 'gamma': 10.0}</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75.846332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.820500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 0.001}</td>\n",
       "      <td>0.366223</td>\n",
       "      <td>0.366223</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>14</td>\n",
       "      <td>0.372918</td>\n",
       "      <td>0.372918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>72.153486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.263808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.00372759</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 0.00372759...</td>\n",
       "      <td>0.385489</td>\n",
       "      <td>0.385489</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73.291342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.137896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 0.01389495...</td>\n",
       "      <td>0.381935</td>\n",
       "      <td>0.381935</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>12</td>\n",
       "      <td>0.402176</td>\n",
       "      <td>0.402176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>78.787670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.952427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 0.05179474...</td>\n",
       "      <td>0.353227</td>\n",
       "      <td>0.353227</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>21</td>\n",
       "      <td>0.445773</td>\n",
       "      <td>0.445773</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>80.252903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.443129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 0.19306977...</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>33</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>85.082069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.250264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 0.71968567...</td>\n",
       "      <td>0.237707</td>\n",
       "      <td>0.237707</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>80.693567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.376183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>2.6827</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 2.68269579...</td>\n",
       "      <td>0.201531</td>\n",
       "      <td>0.201531</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>54</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>96.829273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.469992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.02682695795279726, 'gamma': 10.0}</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>70.096375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.981982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13895</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.13894954943731375, 'gamma': 0.001}</td>\n",
       "      <td>0.386651</td>\n",
       "      <td>0.386651</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.393888</td>\n",
       "      <td>0.393888</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>69.519989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.729128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13895</td>\n",
       "      <td>0.00372759</td>\n",
       "      <td>{'C': 0.13894954943731375, 'gamma': 0.00372759...</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.407573</td>\n",
       "      <td>0.407573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>72.295816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.596205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13895</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 0.13894954943731375, 'gamma': 0.01389495...</td>\n",
       "      <td>0.391965</td>\n",
       "      <td>0.391965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.441185</td>\n",
       "      <td>0.441185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>79.059095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.360751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13895</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 0.13894954943731375, 'gamma': 0.05179474...</td>\n",
       "      <td>0.360162</td>\n",
       "      <td>0.360162</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>17</td>\n",
       "      <td>0.593280</td>\n",
       "      <td>0.593280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78.691706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.211264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13895</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 0.13894954943731375, 'gamma': 0.19306977...</td>\n",
       "      <td>0.310242</td>\n",
       "      <td>0.310242</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32</td>\n",
       "      <td>0.993320</td>\n",
       "      <td>0.993320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>84.713780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.253248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13895</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 0.13894954943731375, 'gamma': 0.71968567...</td>\n",
       "      <td>0.237875</td>\n",
       "      <td>0.237875</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>41</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>74.172312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.379329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 0.7196856730011522, 'gamma': 0.013894954...</td>\n",
       "      <td>0.385868</td>\n",
       "      <td>0.385868</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.536340</td>\n",
       "      <td>0.536340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>103.154717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.020974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 0.7196856730011522, 'gamma': 0.051794746...</td>\n",
       "      <td>0.358263</td>\n",
       "      <td>0.358263</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>18</td>\n",
       "      <td>0.911192</td>\n",
       "      <td>0.911192</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>145.349441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.187302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 0.7196856730011522, 'gamma': 0.193069772...</td>\n",
       "      <td>0.296582</td>\n",
       "      <td>0.296582</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>36</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>199.228421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.242254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 0.7196856730011522, 'gamma': 0.719685673...</td>\n",
       "      <td>0.237086</td>\n",
       "      <td>0.237086</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>200.671153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.372193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>2.6827</td>\n",
       "      <td>{'C': 0.7196856730011522, 'gamma': 2.682695795...</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>49</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>241.365124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.425017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.7196856730011522, 'gamma': 10.0}</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>68.493108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.346360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 0.001}</td>\n",
       "      <td>0.399073</td>\n",
       "      <td>0.399073</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.418351</td>\n",
       "      <td>0.418351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>75.707429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.212444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.00372759</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 0.003727593...</td>\n",
       "      <td>0.396748</td>\n",
       "      <td>0.396748</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.476278</td>\n",
       "      <td>0.476278</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>135.061250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.109498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 0.013894954...</td>\n",
       "      <td>0.362323</td>\n",
       "      <td>0.362323</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>15</td>\n",
       "      <td>0.743766</td>\n",
       "      <td>0.743766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>176.988186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.729115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 0.051794746...</td>\n",
       "      <td>0.321804</td>\n",
       "      <td>0.321804</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>28</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>174.923998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.201269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 0.193069772...</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>267.693008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.223281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 0.719685673...</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>275.641367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.372176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>2.6827</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 2.682695795...</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>331.588186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.407023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72759</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 3.7275937203149416, 'gamma': 10.0}</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>79.074485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.238397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 0.001}</td>\n",
       "      <td>0.396470</td>\n",
       "      <td>0.396470</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444309</td>\n",
       "      <td>0.444309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>155.866326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.994537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>0.00372759</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 0.003727593...</td>\n",
       "      <td>0.371180</td>\n",
       "      <td>0.371180</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.568742</td>\n",
       "      <td>0.568742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>465.227419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.536814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 0.013894954...</td>\n",
       "      <td>0.320351</td>\n",
       "      <td>0.320351</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>29</td>\n",
       "      <td>0.935186</td>\n",
       "      <td>0.935186</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>196.571897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.669167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 0.051794746...</td>\n",
       "      <td>0.315052</td>\n",
       "      <td>0.315052</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>175.352079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.175296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 0.193069772...</td>\n",
       "      <td>0.291062</td>\n",
       "      <td>0.291062</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>268.450593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.354180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 0.719685673...</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>277.723287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.376168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>2.6827</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 2.682695795...</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>332.177395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.416017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.307</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 19.306977288832496, 'gamma': 10.0}</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>192.774043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.037543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.001}</td>\n",
       "      <td>0.384603</td>\n",
       "      <td>0.384603</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>11</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>713.729332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.589770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00372759</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.003727593720314938}</td>\n",
       "      <td>0.339439</td>\n",
       "      <td>0.339439</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>27</td>\n",
       "      <td>0.721131</td>\n",
       "      <td>0.721131</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>913.606002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.008105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.013894954943731374}</td>\n",
       "      <td>0.291693</td>\n",
       "      <td>0.291693</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>37</td>\n",
       "      <td>0.997230</td>\n",
       "      <td>0.997230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>198.812699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.660154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0517947</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.0517947467923121}</td>\n",
       "      <td>0.314697</td>\n",
       "      <td>0.314697</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>175.197201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.193303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.19307</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.19306977288832497}</td>\n",
       "      <td>0.291062</td>\n",
       "      <td>0.291062</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>268.212637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.284232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.719686</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.7196856730011514}</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>275.491449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.469141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2.6827</td>\n",
       "      <td>{'C': 100.0, 'gamma': 2.6826957952797246}</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>331.545183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.419990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 100.0, 'gamma': 10.0}</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time     param_C param_gamma  \\\n",
       "0       80.154882           0.0         8.268241             0.0       0.001       0.001   \n",
       "1       81.016387           0.0         8.258233             0.0       0.001  0.00372759   \n",
       "2       80.001978           0.0         8.251251             0.0       0.001    0.013895   \n",
       "3       81.042341           0.0         8.232261             0.0       0.001   0.0517947   \n",
       "4       79.438465           0.0         8.242256             0.0       0.001     0.19307   \n",
       "5       85.304924           0.0         8.361191             0.0       0.001    0.719686   \n",
       "6       81.086336           0.0         8.398164             0.0       0.001      2.6827   \n",
       "7       97.282040           0.0        10.465988             0.0       0.001          10   \n",
       "8       79.237423           0.0         8.243268             0.0  0.00517947       0.001   \n",
       "9       78.609828           0.0         8.153308             0.0  0.00517947  0.00372759   \n",
       "10      78.087059           0.0         8.004405             0.0  0.00517947    0.013895   \n",
       "11      80.252871           0.0         8.230263             0.0  0.00517947   0.0517947   \n",
       "12      78.666267           0.0         8.236242             0.0  0.00517947     0.19307   \n",
       "13      84.898140           0.0         8.456134             0.0  0.00517947    0.719686   \n",
       "14      80.555249           0.0         8.367184             0.0  0.00517947      2.6827   \n",
       "15      97.197102           0.0        10.435978             0.0  0.00517947          10   \n",
       "16      75.846332           0.0         7.820500             0.0    0.026827       0.001   \n",
       "17      72.153486           0.0         7.263808             0.0    0.026827  0.00372759   \n",
       "18      73.291342           0.0         7.137896             0.0    0.026827    0.013895   \n",
       "19      78.787670           0.0         7.952427             0.0    0.026827   0.0517947   \n",
       "20      80.252903           0.0         8.443129             0.0    0.026827     0.19307   \n",
       "21      85.082069           0.0         8.250264             0.0    0.026827    0.719686   \n",
       "22      80.693567           0.0         8.376183             0.0    0.026827      2.6827   \n",
       "23      96.829273           0.0        10.469992             0.0    0.026827          10   \n",
       "24      70.096375           0.0         6.981982             0.0     0.13895       0.001   \n",
       "25      69.519989           0.0         6.729128             0.0     0.13895  0.00372759   \n",
       "26      72.295816           0.0         6.596205             0.0     0.13895    0.013895   \n",
       "27      79.059095           0.0         7.360751             0.0     0.13895   0.0517947   \n",
       "28      78.691706           0.0         8.211264             0.0     0.13895     0.19307   \n",
       "29      84.713780           0.0         8.253248             0.0     0.13895    0.719686   \n",
       "..            ...           ...              ...             ...         ...         ...   \n",
       "34      74.172312           0.0         6.379329             0.0    0.719686    0.013895   \n",
       "35     103.154717           0.0         7.020974             0.0    0.719686   0.0517947   \n",
       "36     145.349441           0.0         8.187302             0.0    0.719686     0.19307   \n",
       "37     199.228421           0.0         8.242254             0.0    0.719686    0.719686   \n",
       "38     200.671153           0.0         8.372193             0.0    0.719686      2.6827   \n",
       "39     241.365124           0.0        10.425017             0.0    0.719686          10   \n",
       "40      68.493108           0.0         6.346360             0.0     3.72759       0.001   \n",
       "41      75.707429           0.0         6.212444             0.0     3.72759  0.00372759   \n",
       "42     135.061250           0.0         6.109498             0.0     3.72759    0.013895   \n",
       "43     176.988186           0.0         6.729115             0.0     3.72759   0.0517947   \n",
       "44     174.923998           0.0         8.201269             0.0     3.72759     0.19307   \n",
       "45     267.693008           0.0         8.223281             0.0     3.72759    0.719686   \n",
       "46     275.641367           0.0         8.372176             0.0     3.72759      2.6827   \n",
       "47     331.588186           0.0        10.407023             0.0     3.72759          10   \n",
       "48      79.074485           0.0         6.238397             0.0      19.307       0.001   \n",
       "49     155.866326           0.0         5.994537             0.0      19.307  0.00372759   \n",
       "50     465.227419           0.0         5.536814             0.0      19.307    0.013895   \n",
       "51     196.571897           0.0         6.669167             0.0      19.307   0.0517947   \n",
       "52     175.352079           0.0         8.175296             0.0      19.307     0.19307   \n",
       "53     268.450593           0.0         8.354180             0.0      19.307    0.719686   \n",
       "54     277.723287           0.0         8.376168             0.0      19.307      2.6827   \n",
       "55     332.177395           0.0        10.416017             0.0      19.307          10   \n",
       "56     192.774043           0.0         6.037543             0.0         100       0.001   \n",
       "57     713.729332           0.0         5.589770             0.0         100  0.00372759   \n",
       "58     913.606002           0.0         5.008105             0.0         100    0.013895   \n",
       "59     198.812699           0.0         6.660154             0.0         100   0.0517947   \n",
       "60     175.197201           0.0         8.193303             0.0         100     0.19307   \n",
       "61     268.212637           0.0         8.284232             0.0         100    0.719686   \n",
       "62     275.491449           0.0         8.469141             0.0         100      2.6827   \n",
       "63     331.545183           0.0        10.419990             0.0         100          10   \n",
       "\n",
       "                                               params  split0_test_score  mean_test_score  std_test_score  \\\n",
       "0                        {'C': 0.001, 'gamma': 0.001}           0.341731         0.341731    0.000000e+00   \n",
       "1         {'C': 0.001, 'gamma': 0.003727593720314938}           0.348639         0.348639    0.000000e+00   \n",
       "2         {'C': 0.001, 'gamma': 0.013894954943731374}           0.356746         0.356746    0.000000e+00   \n",
       "3           {'C': 0.001, 'gamma': 0.0517947467923121}           0.347594         0.347594    0.000000e+00   \n",
       "4          {'C': 0.001, 'gamma': 0.19306977288832497}           0.310183         0.310183    0.000000e+00   \n",
       "5           {'C': 0.001, 'gamma': 0.7196856730011514}           0.237501         0.237501    0.000000e+00   \n",
       "6           {'C': 0.001, 'gamma': 2.6826957952797246}           0.199725         0.199725    0.000000e+00   \n",
       "7                         {'C': 0.001, 'gamma': 10.0}           0.199950         0.199950    0.000000e+00   \n",
       "8         {'C': 0.005179474679231213, 'gamma': 0.001}           0.341731         0.341731    0.000000e+00   \n",
       "9   {'C': 0.005179474679231213, 'gamma': 0.0037275...           0.354187         0.354187    0.000000e+00   \n",
       "10  {'C': 0.005179474679231213, 'gamma': 0.0138949...           0.361344         0.361344    0.000000e+00   \n",
       "11  {'C': 0.005179474679231213, 'gamma': 0.0517947...           0.347594         0.347594    0.000000e+00   \n",
       "12  {'C': 0.005179474679231213, 'gamma': 0.1930697...           0.310183         0.310183    0.000000e+00   \n",
       "13  {'C': 0.005179474679231213, 'gamma': 0.7196856...           0.237569         0.237569    0.000000e+00   \n",
       "14  {'C': 0.005179474679231213, 'gamma': 2.6826957...           0.200020         0.200020    0.000000e+00   \n",
       "15         {'C': 0.005179474679231213, 'gamma': 10.0}           0.199950         0.199950    0.000000e+00   \n",
       "16         {'C': 0.02682695795279726, 'gamma': 0.001}           0.366223         0.366223    0.000000e+00   \n",
       "17  {'C': 0.02682695795279726, 'gamma': 0.00372759...           0.385489         0.385489    0.000000e+00   \n",
       "18  {'C': 0.02682695795279726, 'gamma': 0.01389495...           0.381935         0.381935    0.000000e+00   \n",
       "19  {'C': 0.02682695795279726, 'gamma': 0.05179474...           0.353227         0.353227    0.000000e+00   \n",
       "20  {'C': 0.02682695795279726, 'gamma': 0.19306977...           0.310183         0.310183    0.000000e+00   \n",
       "21  {'C': 0.02682695795279726, 'gamma': 0.71968567...           0.237707         0.237707    0.000000e+00   \n",
       "22  {'C': 0.02682695795279726, 'gamma': 2.68269579...           0.201531         0.201531    0.000000e+00   \n",
       "23          {'C': 0.02682695795279726, 'gamma': 10.0}           0.199950         0.199950    0.000000e+00   \n",
       "24         {'C': 0.13894954943731375, 'gamma': 0.001}           0.386651         0.386651    0.000000e+00   \n",
       "25  {'C': 0.13894954943731375, 'gamma': 0.00372759...           0.396335         0.396335    0.000000e+00   \n",
       "26  {'C': 0.13894954943731375, 'gamma': 0.01389495...           0.391965         0.391965    0.000000e+00   \n",
       "27  {'C': 0.13894954943731375, 'gamma': 0.05179474...           0.360162         0.360162    0.000000e+00   \n",
       "28  {'C': 0.13894954943731375, 'gamma': 0.19306977...           0.310242         0.310242    0.000000e+00   \n",
       "29  {'C': 0.13894954943731375, 'gamma': 0.71968567...           0.237875         0.237875    0.000000e+00   \n",
       "..                                                ...                ...              ...             ...   \n",
       "34  {'C': 0.7196856730011522, 'gamma': 0.013894954...           0.385868         0.385868    5.551115e-17   \n",
       "35  {'C': 0.7196856730011522, 'gamma': 0.051794746...           0.358263         0.358263    0.000000e+00   \n",
       "36  {'C': 0.7196856730011522, 'gamma': 0.193069772...           0.296582         0.296582    0.000000e+00   \n",
       "37  {'C': 0.7196856730011522, 'gamma': 0.719685673...           0.237086         0.237086    0.000000e+00   \n",
       "38  {'C': 0.7196856730011522, 'gamma': 2.682695795...           0.203100         0.203100    0.000000e+00   \n",
       "39           {'C': 0.7196856730011522, 'gamma': 10.0}           0.199950         0.199950    0.000000e+00   \n",
       "40          {'C': 3.7275937203149416, 'gamma': 0.001}           0.399073         0.399073    0.000000e+00   \n",
       "41  {'C': 3.7275937203149416, 'gamma': 0.003727593...           0.396748         0.396748    0.000000e+00   \n",
       "42  {'C': 3.7275937203149416, 'gamma': 0.013894954...           0.362323         0.362323    0.000000e+00   \n",
       "43  {'C': 3.7275937203149416, 'gamma': 0.051794746...           0.321804         0.321804    0.000000e+00   \n",
       "44  {'C': 3.7275937203149416, 'gamma': 0.193069772...           0.291100         0.291100    0.000000e+00   \n",
       "45  {'C': 3.7275937203149416, 'gamma': 0.719685673...           0.236273         0.236273    0.000000e+00   \n",
       "46  {'C': 3.7275937203149416, 'gamma': 2.682695795...           0.203100         0.203100    0.000000e+00   \n",
       "47           {'C': 3.7275937203149416, 'gamma': 10.0}           0.199950         0.199950    0.000000e+00   \n",
       "48          {'C': 19.306977288832496, 'gamma': 0.001}           0.396470         0.396470    0.000000e+00   \n",
       "49  {'C': 19.306977288832496, 'gamma': 0.003727593...           0.371180         0.371180    0.000000e+00   \n",
       "50  {'C': 19.306977288832496, 'gamma': 0.013894954...           0.320351         0.320351    0.000000e+00   \n",
       "51  {'C': 19.306977288832496, 'gamma': 0.051794746...           0.315052         0.315052    0.000000e+00   \n",
       "52  {'C': 19.306977288832496, 'gamma': 0.193069772...           0.291062         0.291062    0.000000e+00   \n",
       "53  {'C': 19.306977288832496, 'gamma': 0.719685673...           0.236273         0.236273    0.000000e+00   \n",
       "54  {'C': 19.306977288832496, 'gamma': 2.682695795...           0.203100         0.203100    0.000000e+00   \n",
       "55           {'C': 19.306977288832496, 'gamma': 10.0}           0.199950         0.199950    0.000000e+00   \n",
       "56                       {'C': 100.0, 'gamma': 0.001}           0.384603         0.384603    0.000000e+00   \n",
       "57        {'C': 100.0, 'gamma': 0.003727593720314938}           0.339439         0.339439    0.000000e+00   \n",
       "58        {'C': 100.0, 'gamma': 0.013894954943731374}           0.291693         0.291693    0.000000e+00   \n",
       "59          {'C': 100.0, 'gamma': 0.0517947467923121}           0.314697         0.314697    0.000000e+00   \n",
       "60         {'C': 100.0, 'gamma': 0.19306977288832497}           0.291062         0.291062    0.000000e+00   \n",
       "61          {'C': 100.0, 'gamma': 0.7196856730011514}           0.236273         0.236273    0.000000e+00   \n",
       "62          {'C': 100.0, 'gamma': 2.6826957952797246}           0.203100         0.203100    0.000000e+00   \n",
       "63                        {'C': 100.0, 'gamma': 10.0}           0.199950         0.199950    0.000000e+00   \n",
       "\n",
       "    rank_test_score  split0_train_score  mean_train_score  std_train_score  \n",
       "0                25            0.350184          0.350184              0.0  \n",
       "1                22            0.356863          0.356863              0.0  \n",
       "2                19            0.367547          0.367547              0.0  \n",
       "3                23            0.411679          0.411679              0.0  \n",
       "4                33            0.992965          0.992965              0.0  \n",
       "5                44            1.000000          1.000000              0.0  \n",
       "6                64            1.000000          1.000000              0.0  \n",
       "7                56            1.000000          1.000000              0.0  \n",
       "8                25            0.350184          0.350184              0.0  \n",
       "9                20            0.362184          0.362184              0.0  \n",
       "10               16            0.374866          0.374866              0.0  \n",
       "11               23            0.411679          0.411679              0.0  \n",
       "12               33            0.992965          0.992965              0.0  \n",
       "13               43            1.000000          1.000000              0.0  \n",
       "14               55            1.000000          1.000000              0.0  \n",
       "15               56            1.000000          1.000000              0.0  \n",
       "16               14            0.372918          0.372918              0.0  \n",
       "17               10            0.391691          0.391691              0.0  \n",
       "18               12            0.402176          0.402176              0.0  \n",
       "19               21            0.445773          0.445773              0.0  \n",
       "20               33            0.992965          0.992965              0.0  \n",
       "21               42            1.000000          1.000000              0.0  \n",
       "22               54            1.000000          1.000000              0.0  \n",
       "23               56            1.000000          1.000000              0.0  \n",
       "24                8            0.393888          0.393888              0.0  \n",
       "25                5            0.407573          0.407573              0.0  \n",
       "26                7            0.441185          0.441185              0.0  \n",
       "27               17            0.593280          0.593280              0.0  \n",
       "28               32            0.993320          0.993320              0.0  \n",
       "29               41            1.000000          1.000000              0.0  \n",
       "..              ...                 ...               ...              ...  \n",
       "34                9            0.536340          0.536340              0.0  \n",
       "35               18            0.911192          0.911192              0.0  \n",
       "36               36            0.999997          0.999997              0.0  \n",
       "37               45            1.000000          1.000000              0.0  \n",
       "38               49            1.000000          1.000000              0.0  \n",
       "39               56            1.000000          1.000000              0.0  \n",
       "40                2            0.418351          0.418351              0.0  \n",
       "41                3            0.476278          0.476278              0.0  \n",
       "42               15            0.743766          0.743766              0.0  \n",
       "43               28            0.998004          0.998004              0.0  \n",
       "44               38            1.000000          1.000000              0.0  \n",
       "45               46            1.000000          1.000000              0.0  \n",
       "46               50            1.000000          1.000000              0.0  \n",
       "47               56            1.000000          1.000000              0.0  \n",
       "48                4            0.444309          0.444309              0.0  \n",
       "49               13            0.568742          0.568742              0.0  \n",
       "50               29            0.935186          0.935186              0.0  \n",
       "51               30            1.000000          1.000000              0.0  \n",
       "52               39            1.000000          1.000000              0.0  \n",
       "53               46            1.000000          1.000000              0.0  \n",
       "54               50            1.000000          1.000000              0.0  \n",
       "55               56            1.000000          1.000000              0.0  \n",
       "56               11            0.487928          0.487928              0.0  \n",
       "57               27            0.721131          0.721131              0.0  \n",
       "58               37            0.997230          0.997230              0.0  \n",
       "59               31            1.000000          1.000000              0.0  \n",
       "60               39            1.000000          1.000000              0.0  \n",
       "61               46            1.000000          1.000000              0.0  \n",
       "62               50            1.000000          1.000000              0.0  \n",
       "63               56            1.000000          1.000000              0.0  \n",
       "\n",
       "[64 rows x 14 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svm_rbf_gs_1.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_2 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=10000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-2, 3, 6),\n",
    "              'gamma': np.logspace(-5, -1, 4)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, random_state=1,\n",
    "                             train_size=50000, test_size=1000)\n",
    "\n",
    "svm_rbf_gs_2 = GridSearchCV(svm_rbf_2, param_grid=param_grid,\n",
    "                          return_train_score=True, n_jobs=3,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_2, 'saved_models/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_2 = joblib.load('saved_model/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'average_precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9fe7b8eba27c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Save results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0maverage_precision\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SVM (RBF Kernel)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m     \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_distance_svm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclassification_reports\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SVM (RBF Kernel)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m     \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'average_precision' is not defined"
     ]
    }
   ],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_2 = svm_rbf_gs_2.predict(X_test)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_2 = svm_rbf_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_rbf_2)\n",
    "\n",
    "classification_reports_2['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_rbf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_best_result(svm_rbf_gs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs_2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with polynomial kernel \n",
    "\n",
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel='poly', probability=False, gamma='auto',\n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'degree': [2,3,4]}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_poly_gs = GridSearchCV(svm_poly, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_poly_gs.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_poly = svm_poly_gs.predict(X_test_p)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_poly = svm_poly_gs.decision_function(X_test_p)\n",
    "\n",
    "# Save results\n",
    "average_precision['SVM (Polynomial Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_poly)\n",
    "\n",
    "classification_reports['SVM (Polynomial Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_poly_gs, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(svm_poly_gs, 'svm_poly_gs.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = \n",
    "plt.title('Impact of Dropping Columns on Classifier Performance')\n",
    "plt.ylabel('Average Precision');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "503.636px",
    "left": "518px",
    "top": "682.909px",
    "width": "230.716px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
