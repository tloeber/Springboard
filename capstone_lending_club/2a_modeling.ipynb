{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Predictive-models\" data-toc-modified-id=\"Predictive-models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Predictive models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Forests-of-Randomized-Trees\" data-toc-modified-id=\"Forests-of-Randomized-Trees-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Forests of Randomized Trees</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forests\" data-toc-modified-id=\"Random-Forests-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Random Forests</a></span></li><li><span><a href=\"#Extremely-Randomized-Trees\" data-toc-modified-id=\"Extremely-Randomized-Trees-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Extremely Randomized Trees</a></span></li></ul></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2.3.1.1\"><span class=\"toc-item-num\">2.3.1.1&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2.3.1.2\"><span class=\"toc-item-num\">2.3.1.2&nbsp;&nbsp;</span>Hyperopt</a></span></li></ul></li><li><span><a href=\"#With-all-data\" data-toc-modified-id=\"With-all-data-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>With all data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2.3.2.1\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2.3.2.2\"><span class=\"toc-item-num\">2.3.2.2&nbsp;&nbsp;</span>Hyperopt</a></span></li></ul></li></ul></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Support Vector Machine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-SVM\" data-toc-modified-id=\"Linear-SVM-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Linear SVM</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.1.1\"><span class=\"toc-item-num\">2.4.1.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-whole-data-set\" data-toc-modified-id=\"With-whole-data-set-2.4.1.2\"><span class=\"toc-item-num\">2.4.1.2&nbsp;&nbsp;</span>With whole data set</a></span></li></ul></li><li><span><a href=\"#SVM-with-RBF-Kernel\" data-toc-modified-id=\"SVM-with-RBF-Kernel-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>SVM with RBF-Kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.2.1\"><span class=\"toc-item-num\">2.4.2.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-more-data\" data-toc-modified-id=\"With-more-data-2.4.2.2\"><span class=\"toc-item-num\">2.4.2.2&nbsp;&nbsp;</span>With more data</a></span></li></ul></li><li><span><a href=\"#SVM-with-polynomial-kernel\" data-toc-modified-id=\"SVM-with-polynomial-kernel-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>SVM with polynomial kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.3.1\"><span class=\"toc-item-num\">2.4.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Performance-comparison\" data-toc-modified-id=\"Performance-comparison-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Performance comparison</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "import pdb \n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    " \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    StratifiedShuffleSplit, cross_val_score, StratifiedKFold, \\\n",
    "    GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, \\\n",
    "    LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, \\\n",
    "    ExtraTreesClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    precision_recall_curve, average_precision_score, f1_score, \\\n",
    "    roc_curve, auc, roc_auc_score, make_scorer,\\\n",
    "    accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "import missingno  # for visualizing missing data\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval, pyll\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Set up pandas table display\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Set plotting options\n",
    "sns.set() # Use seaborn defaults for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# Load line profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "# Adjust number of CPU cores to use\n",
    "# n_jobs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training and test set, incl. feature names \n",
    "X_train = joblib.load('data_processed/X_train.joblib')\n",
    "X_test = joblib.load('data_processed/X_test.joblib')\n",
    "y_train = joblib.load('data_processed/y_train.joblib')\n",
    "y_test = joblib.load('data_processed/y_test.joblib')\n",
    "X_train_small = joblib.load('data_processed/X_train_small.joblib')\n",
    "X_test_small = joblib.load('data_processed/X_test_small.joblib')\n",
    "y_train_small = joblib.load('data_processed/y_train_small.joblib')\n",
    "y_test_small = joblib.load('data_processed/y_test_small.joblib')\n",
    "feature_names = joblib.load('data_processed/feature_names')\n",
    "feature_names_small = joblib.load('data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "with open('data_processed/all_data.pickle', 'rb') as pickled_file: \n",
    "    all_data = pickle.load(pickled_file)  \n",
    "\n",
    "    \n",
    "# Find categorical variables with more than 50 unique values and drop them\n",
    "unique_values_cat = all_data.select_dtypes(include='object') \\\n",
    "                        .nunique() \\\n",
    "                        .sort_values(ascending=False) \n",
    "# Drop categorical variables with more than 50 categories\n",
    "all_data = all_data.drop(unique_values_cat[unique_values_cat > 50].index,\n",
    "                 axis='columns')\n",
    "\n",
    "\n",
    "def split_preprocess(X=all_data.drop('default', axis='columns'),\n",
    "                     y=all_data.default,\n",
    "                     train_size=.8, test_size=.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test set of specified size, \n",
    "    then applies preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train-test split \n",
    "    # ================\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y,\n",
    "                         train_size=train_size, test_size=test_size,\n",
    "                         random_state=1, shuffle=True, stratify=y) \n",
    "\n",
    "    # Preprocessing\n",
    "    # =============\n",
    "    # Imputation and standardization for numeric features\n",
    "    numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "    numeric_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())]) \n",
    "\n",
    "    # Imputation and one-hot encoding for categorical features\n",
    "    categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "    categorical_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Combining preprocessing for both kinds of features\n",
    "    # (Features of other dtypes – in our case, boolean – will be\n",
    "    # appended at the end without transformation.)\n",
    "    # (Use only 1 core to avoid joblib error)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric_transformer', \n",
    "                 numeric_transformer, numeric_features),\n",
    "            ('categorical_transformer', \n",
    "                 categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough', n_jobs=1) \n",
    "    \n",
    "    # Print dtypes of untransformed data\n",
    "    print('data types of columns that were not transformed:\\n {}'\n",
    "            .format(X_train.select_dtypes(exclude=[np.number, object]) \\\n",
    "                    .dtypes.unique()))\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_p = preprocessor.fit_transform(X_train)\n",
    "    X_test_p = preprocessor.transform(X_test)\n",
    "   \n",
    "\n",
    "    # Get feature names\n",
    "    # =================\n",
    "    # Names of categorical variables after one-hot encoding\n",
    "    categorical_names = preprocessor \\\n",
    "        .named_transformers_['categorical_transformer'] \\\n",
    "        .named_steps['onehot'] \\\n",
    "        .get_feature_names()\n",
    "    # Names of columns with other dtype (should only be Boolean)\n",
    "    other_names = X_train \\\n",
    "        .select_dtypes(exclude=[np.number, object]) \\\n",
    "        .columns\n",
    "    # Concatenate feature names (Note that list with names of \n",
    "    # numeric features was already created above)\n",
    "    feature_names = list(numeric_features) + \\\n",
    "        list(categorical_names) + list(other_names) \n",
    "\n",
    "    \n",
    "    # Return results\n",
    "    # ==============\n",
    "    return(X_train_p, X_test_p, y_train, y_test, feature_names)\n",
    "  \n",
    "    \n",
    "# Create smaller training and test data to start out with\n",
    "X_train_small, X_test_small, y_train_small, y_test_small, feature_names_small= \\\n",
    "    split_preprocess(train_size=20000, test_size=10000)\n",
    "\n",
    "# Create full training and test set\n",
    "X_train, X_test, y_train, y_test, feature_names = \\\n",
    "    split_preprocess(train_size=.8, test_size=.2)\n",
    "\n",
    "\n",
    "# Save preprocessed training and test sets\n",
    "filenames_whole = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "filenames_small = [filename + '_small' for filename in filenames_whole]\n",
    "filenames = filenames_whole + filenames_small\n",
    "files = [X_train, X_test, y_train, y_test,\n",
    "         X_train_small, X_test_small, y_train_small, y_test_small]\n",
    "\n",
    "for file, filename in zip(files, filenames):\n",
    "    joblib.dump(file,\n",
    "                'data_processed/{}.joblib'.format(filename))\n",
    "# Delete temporary list to conserve memory\n",
    "del files\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(feature_names, 'data_processed/feature_names')\n",
    "joblib.dump(feature_names_small, 'data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store results for SMALL data set\n",
    "# average_precision_1 = {}\n",
    "classification_reports_1 = {}\n",
    "most_important_features_1 = {} \n",
    "# Note that models with small data were estimated on a different subset\n",
    "# of the observations, though the size stayed constant.  So don't use future \n",
    "# importance on these data, unless re-estimating models!\n",
    "\n",
    "# Dictionaries to store results for WHOLE data set\n",
    "# average_precision_2 = {}\n",
    "classification_reports_2 = {}\n",
    "most_important_features_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average precision\n",
    "def print_save_ap(clf, model_name, X_test, y_test, \n",
    "                  X_train, y_train, validation_plot=False):\n",
    "    \"\"\"\n",
    "    Calculates and prints average precision score on train and test set; \n",
    "    saves score from test set. Optionally plot how average precision \n",
    "    changed over iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Score classifier with the test data\n",
    "    # Try if classifier supports probability\n",
    "    try:\n",
    "        y_score = clf.predict_proba(X_test)[:,1]\n",
    "    # If it doesn't, use its decision function\n",
    "    except AttributeError:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "   \n",
    "    # Calculate average precision\n",
    "    ap_score = average_precision_score(y_test, y_score)\n",
    "    ap_score_train = average_precision_score(y_test_train, y_score_train)\n",
    "    \n",
    "    # Save AP\n",
    "    try:\n",
    "        average_precision_hp[model_name] = ap_score\n",
    "    # If dictionary to save AP doesn't exist yet, create it first\n",
    "    except NameError:\n",
    "        average_precision = {}\n",
    "        average_precision[model_name] = ap_score\n",
    "    \n",
    "    # Print AP\n",
    "    print('Best average precision score on *test* set: {}'.format(ap_score))\n",
    "    print('Best average precision score on *training* set: {}'.format(ap_score))\n",
    "    \n",
    "    \n",
    "    # Plot AP, if specified\n",
    "    if validation_plot:\n",
    "        # Load progress file with validation performance\n",
    "        progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "        progress_file = pd.read_csv(progress_file_path)\n",
    "\n",
    "        # Extract AP for each iteration\n",
    "        ap = - progress_file.loss\n",
    "        ap.plot()\n",
    "        plt.title('Performance on *Validation* Set')\n",
    "        plt.ylabel('Average Precision')\n",
    "        plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to carry out hyperparameter optimization\n",
    "def find_best_hp(CLF, space, model_name, \n",
    "                 X_train, y_train, \n",
    "                 adjust_params=None,n_folds=5, n_jobs=-1, max_evals=20):\n",
    "    \"\"\"Find best hyperparameters for a given classifier and search space.\"\"\"\n",
    "    \n",
    "    # Trials object to track progress\n",
    "    trials = Trials()\n",
    "\n",
    "    # CSV file to track progress\n",
    "    progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "    with open(progress_file_path, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write header to the file\n",
    "        writer.writerow(['loss', 'params'])\n",
    "\n",
    "    # Objective function to minimize\n",
    "    def objective(params, CLF=CLF, \n",
    "                  progress_file_path=progress_file_path,\n",
    "                  n_folds=n_folds, n_jobs=n_jobs):\n",
    "        \"\"\"Objective function to minimize\"\"\"\n",
    "        \n",
    "        # Adjust parameters, if specified\n",
    "        if adjust_params is not None:\n",
    "            params = adjust_params(params)\n",
    "    \n",
    "        # Instantiate CLF\n",
    "        clf = CLF(**params)\n",
    "        \n",
    "        ## Generate indices for cross-validation\n",
    "        # If only one \"fold\" is desired, split into train and validation set\n",
    "        if n_folds == 1: \n",
    "            cv = StratifiedShuffleSplit(n_splits=1, test_size=.2, \n",
    "                                        random_state=1)\n",
    "        # Otherwise, generate indices for proper cross-validation split\n",
    "        else:  \n",
    "            cv = StratifiedKFold(n_folds, random_state=1)\n",
    "\n",
    "        # Compute average precision through CV / validation set\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=cv,\n",
    "                                scoring='average_precision', n_jobs=n_jobs)\n",
    "        # Compute loss as the negative mean of the average precision scores\n",
    "        # (since hyperopt can only minimize a function)\n",
    "        loss = -score.mean()\n",
    "        \n",
    "        # Save results to csv file\n",
    "        with open(progress_file_path, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([loss, params])\n",
    "        \n",
    "        # Return results\n",
    "        return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "    \n",
    "    # Minimize objective\n",
    "    best = fmin(objective, space, algo=tpe.suggest,\n",
    "                max_evals=max_evals, trials=trials)\n",
    "\n",
    "    # Get the values of the optimal parameters\n",
    "    best_params = space_eval(space, best)\n",
    "    # Adjust best parameters\n",
    "    best_params = adjust_params(best_params)\n",
    "\n",
    "    # Fit the model with the optimal hyperparamters\n",
    "    clf = CLF(**best_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Save model to disk\n",
    "    joblib.dump(clf, 'saved_models/' + model_name + '.joblib')\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forests of Randomized Trees\n",
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute sqrt of number of features for baseline max_features\n",
    "sqrt_n_ft = np.sqrt(X_train.shape[1])\n",
    "sqrt_n_ft\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "space = {'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "         'max_depth': hp.uniform('max_depth', 5, 100),\n",
    "         'max_features': hp.normal('max_features',\n",
    "                                    sqrt_n_ft, 0.25*sqrt_n_ft),\n",
    "         'min_samples_leaf': hp.uniform('min n_samples_leaf', 1, 200),\n",
    "         'class_weight': 'balanced',\n",
    "         'n_estimators': 100, \n",
    "         'random_state': 1}\n",
    "\n",
    "# Function to convert sampled parameters to integer or make positive, etc., \n",
    "# where necessary\n",
    "def adjust_params_rf(params):\n",
    "    \"\"\" \n",
    "    Adjust parameters where hyperopt did not allow sampling from optimal \n",
    "    distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert sampled parameters to integer, where  applicable\n",
    "    params['max_depth'] = round(params['max_depth'])\n",
    "    params['max_features'] = round(params['max_features'])\n",
    "    params['min_samples_leaf'] = round(params['min_samples_leaf'])\n",
    "    \n",
    "    # Set upper or lower bunds for parameters, where applicable\n",
    "    if params['max_features'] < 1:\n",
    "        params['max_features'] = 1\n",
    "        \n",
    "    # Return modified parameters\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 64, 'max_features': 29, 'min_samples_leaf': 34, 'n_estimators': 100, 'random_state': 1}\n"
     ]
    }
   ],
   "source": [
    "MAX_EVALS = 50\n",
    "N_JOBS = 3\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(RandomForestClassifier, space, \n",
    "             model_name='rf_hp_2', \n",
    "             X_train=X_train, y_train=y_train, \n",
    "             adjust_params=adjust_params_rf, \n",
    "             max_evals=MAX_EVALS, n_jobs=N_JOBS, \n",
    "             n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d46066a1f59c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m print_save_ap(rf_2, 'rf_hp_2', X_test, y_test, \n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m              validation_plot=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_2' is not defined"
     ]
    }
   ],
   "source": [
    "print_save_ap(rf_2, 'rf_hp_2', X_test, y_test, \n",
    "              X_train=X_train, y_train=y_train,\n",
    "             validation_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf_rs_2, 'rf_rs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for hyperparameters\n",
    "space = {'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "         'max_depth': hp.uniform('max_depth', 5, 100),\n",
    "         'max_features': hp.normal('max_features',\n",
    "                                    sqrt_n_ft, 0.25*sqrt_n_ft),\n",
    "         'min_samples_leaf': hp.uniform('min n_samples_leaf', 1, 200),\n",
    "         'class_weight': 'balanced',\n",
    "         'n_estimators': 500,  # Only difference to random forests\n",
    "         'random_state': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 528, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 333, in fit\n    for i, t in enumerate(trees))\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 920, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 182, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 549, in __init__\n    self.results = batch()\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 121, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 801, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 152, in fit\n    return_inverse=True)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 233, in unique\n    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n  File \"C:\\Users\\t\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 273, in _unique1d\n    ar = np.asanyarray(ar).flatten()\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0837ac010145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m               \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m               \u001b[0madjust_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madjust_params_rf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Reuse from RF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m               max_evals=MAX_EVALS, n_jobs=N_JOBS, n_folds=3)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-af5092c375ea>\u001b[0m in \u001b[0;36mfind_best_hp\u001b[1;34m(CLF, space, model_name, X_train, y_train, adjust_params, n_folds, n_jobs, max_evals)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Minimize objective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     best = fmin(objective, space, algo=tpe.suggest,\n\u001b[1;32m---> 56\u001b[1;33m                 max_evals=max_evals, trials=trials)\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# Get the values of the optimal parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         )\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[0;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-af5092c375ea>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(params, CLF, progress_file_path, n_folds, n_jobs)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# Compute average precision through CV / validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         score = cross_val_score(clf, X_train, y_train, cv=cv,\n\u001b[1;32m---> 41\u001b[1;33m                                 scoring='average_precision', n_jobs=n_jobs)\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m# Compute loss as the negative mean of the average precision scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# (since hyperopt can only minimize a function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAX_EVALS = 50\n",
    "N_JOBS = 3\n",
    "\n",
    "# Find best hyperparameters \n",
    "find_best_hp(ExtraTreesClassifier, space, model_name='et_hp_2',\n",
    "              X_train=X_train, y_train=y_train,\n",
    "              adjust_params=adjust_params_rf,  # Reuse from RF\n",
    "              max_evals=MAX_EVALS, n_jobs=N_JOBS, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf, 'rf', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of parameters to tune, we need a smart way of searching over the different parameters that avoids the combinatorial explosion that would result from a simultaneous grid search over all parameters.  \n",
    "\n",
    "In the following, I will follow the suggestions from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ for plausible ranges for the hyperparameters.  However, since I will use Bayesian optimization rather than brute force, I am able to avoid having to repeatedly optimize a small number of parameters at a time. Instead, I will optimize all tree-specific parameters at once, using a relatively higher learning rate to speed up training. Subsequently, I will reestimate the model on the training set with the parameters identified in the previous step, but use a smaller learning rate for increased accuracy. \n",
    "\n",
    "During both of the steps, I will use early stopping to determine the optimal number of trees.  To that end, I split off a quarter of the original training set to use as the validation set for early stopping. Since the original training set has about 200,000 observations, we will still have around 150,000 observations left as the new test set for the final XGBoost classifier. This is more than enough to measure performance with very high accuracy.\n",
    "\n",
    "I will be using XGBoost's native API rather than the Scikit-learn API. This has several benefits, such as being able to use SGBoost's native data format, which increases performance.  Thus, let's start by converting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"<\" from feature names, since this causes problems for xgboost\n",
    "feature_names_xgb = [x.replace('<', '_less_than_') for x in feature_names]\n",
    "\n",
    "\n",
    "# Split original test set into validation set (for early stopping) and new test set\n",
    "X_val_xgb, X_test_xgb, y_val_xgb, y_test_xgb = \\\n",
    "    train_test_split(X_test, y_test,\n",
    "                     train_size=0.25, test_size=0.75,\n",
    "                     random_state=1, shuffle=True, stratify=y_test) \n",
    "\n",
    "# Convert data to DMatrix \n",
    "data_xgb_train = xgb.DMatrix(data=X_train, label=y_train,\n",
    "                             feature_names=feature_names_xgb, nthread=-1)\n",
    "data_xgb_test = xgb.DMatrix(data=X_test_xgb, label=y_test_xgb,\n",
    "                            feature_names=feature_names_xgb)\n",
    "data_xgb_val = xgb.DMatrix(data=X_val_xgb, label=y_val_xgb,\n",
    "                            feature_names=feature_names_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not using the sklearn API, we won't be able to reuse the function defined above for Bayesian hyperparameters optimization. Instead, let's adapt the code for XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most parameters, we will use a normal distribution to define their prior distributions to sample from.  Thus, setting the mean and standard deviation for these distributions is pretty straightforward.  However, for the regularization term alpha, we will use a lognormal distribution (analogous to using a logarithmic grid for a brute force search). Since the relationship between its parameters and the scale of the distribution is less intuitive, let's draw a few samples first to inspect if it yields a plausible distribution for the regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect prior distribution for reg_alpha\n",
    "from hyperopt import pyll\n",
    "reg_alpha_distr = hp.loguniform('n_estimators', -6, 4)\n",
    "samples = [pyll.stochastic.sample(reg_alpha_distr) for i in range(100)]\n",
    "\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist', bins=100)\n",
    "plt.xlabel('reg_alpha')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the minimum, maximum, and median, these values look good, so let's go with these parameters.\n",
    "\n",
    "How let's decide on an appropriate prior distribution for gamma, the minimum loss reduction that we require to further partition a node. I will use a lognormal distribution bounded between 0 and 0.5.  The challenge is to define this in hyperopt, because it bounds the distribution by the exponential function of the upper and lower bounds supplied as the parameters. Thus, in order to get a lower bound of 0, we would have to pass log(0) or -$\\infty$ as the parameter. I solved this problem by passing the log of a small number as the lower bound, and then subtract the small number from the final distribution when adjusting the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect prior distribution for gamma\n",
    "from hyperopt import pyll\n",
    "small_number = 0.01\n",
    "\n",
    "gamma_distr = hp.loguniform('n_estimators', \n",
    "                            np.log(small_number), \n",
    "                            np.log(0.5 + small_number))\n",
    "\n",
    "samples = [pyll.stochastic.sample(gamma_distr) - small_number\n",
    "               for i in range(1000)]\n",
    "\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist')\n",
    "plt.xlabel('gamma')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_number = 0.01 # To adjust lower bound for Gamma\n",
    "space = {\n",
    "    # Parameters that we are going to tune (Note that these may be modified\n",
    "    # in objective function to convert to integer or to set min or max.)\n",
    "    'eta':.3,  # Start with a higher learning rate for speed\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'map',\n",
    "    'scale_pos_weight': 5,  # Balance classes\n",
    "    'max_depth': hp.normal('max_depth', 6, 2),\n",
    "    'min_child_weight': hp.normal('min_child_weight', 4, 2), \n",
    "    'gamma': hp.loguniform('gamma', # small number will be subtracted later\n",
    "                            np.log(small_number), \n",
    "                            np.log(0.5 + small_number)),\n",
    "    'subsample': hp.normal('subsample', 0.75, 0.2), \n",
    "    'colsample_bytree':  hp.normal('colsample_bytree', 0.75, 0.2),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -6, 4),\n",
    "    'verbose_eval': False,\n",
    "    'nthread': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options\n",
    "N_JOBS=3\n",
    "MAX_EVALS = 100\n",
    "\n",
    "# CSV file to track progress\n",
    "progress_file_path = 'hp_progress/progress_xgb.csv'\n",
    "with open(progress_file_path, 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header to the file\n",
    "    writer.writerow(['loss', 'params', 'n_trees'])\n",
    "\n",
    "    \n",
    "# Function to convert sampled parameters to integer or make positive, etc., \n",
    "# where necessary\n",
    "def adjust_params_xgb(params):\n",
    "    \"\"\" \n",
    "    Adjust parameters where hyperopt did not allow sampling from optimal \n",
    "    distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert sampled parameters to integer, where  applicable\n",
    "    params['max_depth'] = round(params['max_depth'])\n",
    "    \n",
    "    # Make sure min_child_weight is positive\n",
    "    if params['min_child_weight'] <= 0:\n",
    "        params['min_child_weight'] = 0 # Set to lower bound\n",
    "   \n",
    "    # Subtract the small number from gamma to set 0 as lower bound\n",
    "    params['gamma'] = params['gamma'] - small_number\n",
    "\n",
    "    # Set upper or lower bunds for parameters, where applicable\n",
    "    if params['max_depth'] <= 2:\n",
    "        params['max_depth'] = 2\n",
    "    if params['subsample'] < 0.05:\n",
    "        params['subsample'] = 0.05\n",
    "    if params['subsample'] > 1:\n",
    "        params['subsample'] = 1\n",
    "    if params['colsample_bytree'] < 0.05: \n",
    "        params['colsample_bytree'] = 0.05\n",
    "    if params['colsample_bytree'] > 1:\n",
    "        params['colsample_bytree'] = 0.75\n",
    "    \n",
    "    # Return modified parameters\n",
    "    return params\n",
    "\n",
    "\n",
    "# Objective function to minimize\n",
    "def objective(params, progress_file_path=progress_file_path,\n",
    "              n_jobs=N_JOBS):\n",
    "    \"\"\"Objective function to minimize\"\"\"\n",
    "    \n",
    "    # Adjust parameters\n",
    "    params = adjust_params_xgb(params)\n",
    "    \n",
    "    # Train model\n",
    "    xgb_ = xgb.train(params, dtrain=data_xgb_train, \n",
    "                num_boost_round=1000,\n",
    "                evals=[(data_xgb_val, \"val\")], \n",
    "                early_stopping_rounds=50)\n",
    "    \n",
    "    # Compute loss as the negative mean of the average precision scores\n",
    "    # (since hyperopt can only minimize a function)\n",
    "    loss = - xgb_.best_score\n",
    "    \n",
    "    # Save results to csv file\n",
    "    with open(progress_file_path, 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([loss, params, xgb_.best_ntree_limit])\n",
    "\n",
    "    # Return results\n",
    "    return {'loss': loss, 'params': params, 'n_trees': xgb_.best_ntree_limit, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to carry out the hyperparameters optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize objective\n",
    "best = fmin(objective, space, algo=tpe.suggest,\n",
    "            max_evals=MAX_EVALS)\n",
    "\n",
    "# Get the values of the optimal parameters\n",
    "best_params = space_eval(space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full results from progress file\n",
    "xgb_results = pd.read_csv('hp_progress/progress_xgb.csv')\n",
    "\n",
    "# Get validation score\n",
    "# Extract AP for each iteration\n",
    "ap_xgb = - xgb_results.loss\n",
    "\n",
    "print(f'Best average precision on validation set: {ap_xgb.max()}')\n",
    "\n",
    "# Plot AP per iteration\n",
    "ap_xgb.plot()\n",
    "plt.title('Performance on validation set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the best parameters, let's re-estimate the model with a lower learning rate to get another boost in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease learning rate\n",
    "best_params['eta'] = 0.005\n",
    "\n",
    "# Adjust parameters (e.g., convert to integer)\n",
    "best_params = adjust_params_xgb(best_params)\n",
    "\n",
    "# Fit the model with the optimal hyperparamters and lower learning rate\n",
    "xgb_best = xgb.train(best_params,\n",
    "                    dtrain=data_xgb_train, \n",
    "                    num_boost_round=10000,\n",
    "                    evals=[(data_xgb_val, \"val\")], \n",
    "                    early_stopping_rounds=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best.best_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute test score of final model\n",
    "# Make predicition\n",
    "y_xgb = xgb_best.predict(data_xgb_test)\n",
    "y_xgb\n",
    "\n",
    "# Save and print AP\n",
    "ap_xgb = average_precision_score(y_test_xgb, y_xgb)\n",
    "print(f'Average precision on test set: {ap_xgb}')\n",
    "# average_precision['xgb'] = ap_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add optimum number of trees to best parameters\n",
    "best_params['num_boost_round'] = xgb_best.best_ntree_limit\n",
    "# Remove early stopping, because now we don't need it anymore\n",
    "best_params['early_stopping_rounds'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature importances\n",
    "fi_xgb = pd.Series(xgb_best.get_fscore()) \\\n",
    "            .sort_values(ascending=False)\n",
    "feature_importances = {}\n",
    "feature_importances['xgb'] = fi_xgb\n",
    "fi_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "#### With smaller subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_1 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 1, 8)}\n",
    "# Grid search\n",
    "lr_gs_1 = GridSearchCV(lr_1, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=N_JOBS, cv=3)\n",
    "lr_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_gs_1, 'saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_1 = joblib.load('saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_best_result(gridsearchcv, decimals=3):\n",
    "    \"\"\"Returns details for best results from grid search.\"\"\"\n",
    "\n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(gridsearchcv.cv_results_) \\\n",
    "                .drop('params', axis='columns')\n",
    "    \n",
    "    # Get values for hyperparameters \n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    \n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], axis=1)\n",
    "    # Set hyperparameters as index\n",
    "    scores_w_params = scores_w_params \\\n",
    "                        .set_index(params.columns.tolist())\n",
    "    \n",
    "    # Get tuple with best hyperparameters values, making sure it \n",
    "    # has the same order as the multi-index.\n",
    "    best_param_tuple = (\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[0]],\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[1]])\n",
    "    \n",
    "    # Filter results for best hyperparameters \n",
    "    best_result = pd.to_numeric(\n",
    "                    scores_w_params.loc[best_param_tuple, :])\n",
    "    \n",
    "    # Return rounded result (convert to dataframe for pretty  printing)\n",
    "    return(pd.DataFrame(best_result) \\\n",
    "               .round(decimals))\n",
    "\n",
    "gs_best_result(lr_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_lr_1= lr_gs_1.predict(X_test_small)    \n",
    "y_pred_proba_lr_1= lr_gs_1.predict_proba(X_test_small)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision_1['logistic regression'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_proba_lr_1)\n",
    "classification_reports_1['logistic regression'] = \\\n",
    "    classification_report(y_test_small, y_pred_lr_1)\n",
    "\n",
    "# Compute feature importance and sort\n",
    "most_important_features_1['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_1.best_estimator_.coef_[0], \n",
    "          index=feature_names_small) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "def gs_heatmap(gridsearchcv, x_digits=0, y_digits=0,\n",
    "               x_scientific_notation=True, y_scientific_notation=True):\n",
    "    \"\"\"Visualizes validation accuracy from grid search over two hyperparameters.\"\"\"\n",
    "    \n",
    "    # Print test score and  hyperparameters\n",
    "    print('Best score: {:.3f}, best hyperparameters: '\n",
    "                .format(gridsearchcv.best_score_), \n",
    "          gridsearchcv.best_params_)\n",
    "      \n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['mean_test_score'])\n",
    "    # Get values for hyperparameters\n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], \n",
    "                                  axis=1)\n",
    "    # Set first two columns, which correspond to parameters, as index.\n",
    "    # Then unstack.\n",
    "    index_cols = list(scores_w_params.columns)[:2]\n",
    "    scores_2d = scores_w_params.set_index(index_cols) \\\n",
    "                    .squeeze() \\\n",
    "                    .unstack()\n",
    "    \n",
    "    # Create desired formatting string for axes (scientific notation and digits)\n",
    "    if x_scientific_notation == True:\n",
    "        x_notation = 'E' \n",
    "    else: \n",
    "        x_notation = 'F'\n",
    "    x_formatting = '{:.' + str(x_digits) + x_notation + '}'\n",
    "\n",
    "    if y_scientific_notation == True:\n",
    "        y_notation = 'E' \n",
    "    else: \n",
    "        y_notation = 'F'\n",
    "    y_formatting = '{:.' + str(y_digits) + y_notation + '}'\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(scores_2d, ax=ax,\n",
    "                xticklabels=[x_formatting.format(x) for  x in scores_2d.columns],\n",
    "                yticklabels=[y_formatting.format(y) for y in scores_2d.index])\n",
    "    ax.set_title('Validation accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(lr_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SGDClassifier, space, model_name='lr_hp_1',\n",
    "              X_train=X_train_small, y_train=y_train_small,\n",
    "              max_evals=8*11, n_jobs=3, n_folds=3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance: 0.37503654872776293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_hp_1 = joblib.load('saved_models/lr_hp_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_lr = pd.read_csv('hp_progress/progress_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best average precision score on validation set\n",
    "-progress_lr.loss.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best performance on the test set, 0.378, is slightly higher than what we found with a grid search, .375. Though this difference is only small, but note that this was achieved with the same number of iterations. Thus, let's take a look at how the performance changed with the number of iterations, to see if we already reached a plateau earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = - progress_lr.loss\n",
    "ap.plot()\n",
    "plt.title('Performance on Validation Set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows nicely how the Bayesian search algorithm has an intelligent approach towards the exploration-exploitation dilemma: For the first 20 or so iterations, it focuses on *exploration*: It searches the hyperparameter space seemingly randomly, resulting in both very high and very low performance. Later, it shifts to *exploitation*: Having identified values for the hyperparameters that work well, it shifts to predominantly searching around these values, resulting in more consistent high performance.  Nevertheless, it occasionally shifts back to exploring values further away, in order to avoid getting stuck in a local maximum.\n",
    "\n",
    "We also see that there does not seem to be much payoff from further optimization once reasonably good values have been found: The best values found during the first 10 iterations are not far off from the overall maximum. Thus, when we ran the hyperparameters optimization on the full data set, we will only let the algorithm run for 40 iteration, since the performance reaches a plateau starting at around 20 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now estimate the model on all data. Based on the results from the smaller data set, we will adjust the parameter grade for alpha, the constant that multiplies the regularization term: We will drop all values for alpha greater than 0.1, since these did not give us good performance. \n",
    "\n",
    "Because we are now using more data, the optimal regularization term will be even smaller; thus, we leave the minimum value for alpha to search over constant, even though it did not give us great performance either on the smaller data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (Elastic Net) \n",
    "# ---------------------------------\n",
    "n_jobs=2\n",
    "lr_2 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 0, 13)}\n",
    "\n",
    "# Grid search\n",
    "lr_gs_2 = GridSearchCV(lr_2, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=N_JOBS, cv=5)\n",
    "lr_gs_2.fit(X_train, y_train) \n",
    "\n",
    "# Save model\n",
    "\n",
    "joblib.dump(lr_gs_2, 'saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_2 = joblib.load('saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_gs_2, 'lr_gs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predictions\n",
    "# y_pred_lr_2 = lr_gs_2.predict(X_test)\n",
    "# y_pred_proba_lr_2 = lr_gs_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Save results\n",
    "# average_precision_2['logistic regression'] = \\\n",
    "#     average_precision_score(y_test, y_pred_proba_lr_2)\n",
    "# classification_reports_2['logistic regression'] = \\\n",
    "#     classification_report(y_test, y_pred_lr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_gs_2, 'lr_gs_2', X_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute feature importance and sort\n",
    "most_important_features_2['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_2.best_estimator_.coef_[0], \n",
    "          index=feature_names) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results    \n",
    "gs_heatmap(lr_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_reports_2['logistic regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 0),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SGDClassifier, space, model_name='lr_hp_2',\n",
    "              X_train=X_train, y_train=y_train,\n",
    "              max_evals=40, n_jobs=3, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8bc161152453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m find_best_hp(SGDClassifier, space, model_name='lr_hp_2',\n\u001b[0;32m     15\u001b[0m               \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_small\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m               max_evals=40, n_jobs=3, n_folds=1)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-af5092c375ea>\u001b[0m in \u001b[0;36mfind_best_hp\u001b[1;34m(CLF, space, model_name, X_train, y_train, adjust_params, n_folds, n_jobs, max_evals)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# Adjust best parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjust_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;31m# Fit the model with the optimal hyperparamters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 0),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SGDClassifier, space, model_name='lr_hp_2',\n",
    "              X_train=X_train_small, y_train=y_train_small,\n",
    "              max_evals=40, n_jobs=3, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_hp_2 = joblib.load('saved_models/lr_hp_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_hp_2, 'lr_hp_2', X_test, y_test, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_1 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 3),\n",
    "              'alpha': np.logspace(-5, 1, 7)}\n",
    "svm_lin_gs_1 = GridSearchCV(svm_lin_1, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=N_JOBS, cv=5)\n",
    "svm_lin_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_1, 'saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model\n",
    "svm_lin_gs_1 = joblib.load('saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_lin_1 = svm_lin_gs_1.predict(X_test_small)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_lin_1 = svm_lin_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_lin_1)\n",
    "classification_reports_1['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_lin_1)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(\n",
    "      SGDClassifier, space, model_name='svm_lin_hp_1',\n",
    "      X_train=X_train_small, y_train=y_train_small,\n",
    "      max_evals=8*11, n_jobs=3, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_lr = pd.read_csv('progress_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best average precision score on validation set\n",
    "-progress_lr.loss.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = - progress_lr.loss\n",
    "ap.plot()\n",
    "plt.title('Performance on Validation Set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### With whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat this analysis on the whole data set. Again, since more data will require less regularization, we will look at lower our maximum value for alpha to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_2 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-5, -1, 9)}\n",
    "svm_lin_gs_2 = GridSearchCV(svm_lin_2, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=N_JOBS, cv=5)\n",
    "svm_lin_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_2, 'saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_lin_gs_2 = joblib.load('saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_2 = svm_lin_gs_2.predict(X_test)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_2 = svm_lin_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_2)\n",
    "classification_reports_2['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_2)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AP score\n",
    "print_save_ap(svm_lin_gs_2, 'svm_lin_gs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -5, -1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(\n",
    "      SGDClassifier, space, model_name='svm_lin_hp_2',\n",
    "      X_train=X_train, y_train=y_train,\n",
    "      max_evals=40, n_jobs=3, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_lin_hp_2 = joblib.load('saved_models/svm_lin_hp_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(svm_lin_hp_2, 'svm_lin_hp_2', X_test, y_test, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with RBF-Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller subsets \n",
    "X_train_s, y_train_s = resample(\n",
    "    X_train, y_train, \n",
    "    replace=False, n_samples=500, random_state=1)\n",
    "    \n",
    "X_test_s, y_test_s = resample(\n",
    "    X_test, y_test, \n",
    "    replace=False, n_samples=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=30)\n",
    "X_train_pc = pca.fit_transform(X_train_s) \n",
    "X_test_pc = pca.transform(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect prior distribution for reg_alpha\n",
    "from hyperopt import pyll\n",
    "c_distr = hp.lognormal('C', 0, 5)\n",
    "samples = [pyll.stochastic.sample(c_distr) for i in range(1000)]\n",
    "# \n",
    "samples = list(filter(lambda x: x<100, samples))\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist', bins=50)\n",
    "# plt.xlim([0,1000])\n",
    "plt.xlabel('c_distr')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect prior distribution for reg_alpha\n",
    "from hyperopt import pyll\n",
    "gamma_distrdistr = hp.lognormal('C', np.log(1/30), 6)\n",
    "samples = [pyll.stochastic.sample(gamma_distrdistr) for i in range(1000)]\n",
    "# \n",
    "samples = list(filter(lambda x: x<100, samples))\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist', bins=50)\n",
    "# plt.xlim([0,1000])\n",
    "plt.xlabel('gamma_distrdistr')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_params_svm_rbf(params):\n",
    "    \"\"\" \n",
    "    Adjust parameters where hyperopt did not allow sampling from optimal \n",
    "    distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set min or max thresholds for parameters, where applicable\n",
    "    if params['C'] >= 10:\n",
    "        params['C'] = 10\n",
    "        \n",
    "    # Return modified parameters\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "# from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to carry out hyperparameter optimization\n",
    "def find_best_hp(CLF, space, model_name, \n",
    "                 X_train, y_train, \n",
    "                 adjust_params=None,n_folds=5, n_jobs=-1, max_evals=20):\n",
    "    \"\"\"Find best hyperparameters for a given classifier and search space.\"\"\"\n",
    "    \n",
    "    # Trials object to track progress\n",
    "    trials = Trials()\n",
    "\n",
    "    # CSV file to track progress\n",
    "    progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "    with open(progress_file_path, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write header to the file\n",
    "        writer.writerow(['loss', 'params'])\n",
    "\n",
    "    # Objective function to minimize\n",
    "    def objective(params, CLF=CLF, \n",
    "                  progress_file_path=progress_file_path,\n",
    "                  n_folds=n_folds, n_jobs=n_jobs):\n",
    "        \"\"\"Objective function to minimize\"\"\"\n",
    "\n",
    "        # Adjust parameters, if specified\n",
    "        if adjust_params is not None:\n",
    "            params = adjust_params(params)\n",
    "    \n",
    "        # Instantiate CLF\n",
    "        clf = CLF(**params)\n",
    "        \n",
    "        ## Generate indices for cross-validation\n",
    "        # If only one \"fold\" is desired, split into train and validation set\n",
    "        if n_folds == 1: \n",
    "            cv = StratifiedShuffleSplit(n_splits=1, test_size=.2, \n",
    "                                        random_state=1)\n",
    "        # Otherwise, generate indices for proper cross-validation split\n",
    "        else:  \n",
    "            cv = StratifiedKFold(n_folds, random_state=1)\n",
    "\n",
    "        # Compute average precision through CV / validation set\n",
    "        score = cross_val_score(clf, X_train_pc, y_train, cv=cv,\n",
    "                                scoring='average_precision', n_jobs=n_jobs)\n",
    "        # Compute loss as the negative mean of the average precision scores\n",
    "        # (since hyperopt can only minimize a function)\n",
    "        loss = -score.mean()\n",
    "        \n",
    "        # Save results to csv file\n",
    "        with open(progress_file_path, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([loss, params])\n",
    "        \n",
    "        # Return results\n",
    "        return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "    \n",
    "    # Minimize objective\n",
    "    best = fmin(objective, space, algo=tpe.suggest,\n",
    "                max_evals=max_evals, trials=trials)\n",
    "\n",
    "    # Get the values of the optimal parameters\n",
    "    best_params = space_eval(space, best)\n",
    "\n",
    "    # Fit the model with the optimal hyperparamters\n",
    "    clf = CLF(**best_params)\n",
    "    clf.fit(X_train_pc, y_train)\n",
    "    \n",
    "    # Save model to disk\n",
    "    joblib.dump(clf, 'saved_models/' + model_name + '.joblib')\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MAX_EVALS=40\n",
    "N_JOBS=3\n",
    "\n",
    "# Define search space\n",
    "space = {\n",
    "    'kernel': 'rbf',\n",
    "    'cache_size': 1500000,\n",
    "    'class_weight': 'balanced',\n",
    "    'random_state': 1,\n",
    "    'C': hp.lognormal('C', -3, 3),\n",
    "    'gamma': hp.lognormal('gamma', -3, 3)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SVC, space, model_name='svm_rbf_hp',\n",
    "              X_train=X_train_pc, y_train=y_train_s, \n",
    "              adjust_params=adjust_params_svm_rbf,\n",
    "              max_evals=MAX_EVALS,n_folds=1, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_hp = joblib.load('saved_models/svm_rbf_hp.joblib')\n",
    "\n",
    "# Calculate average precision\n",
    "def print_save_ap(clf, model_name, X_test_pc, y_test, validation_plot=False):\n",
    "    \"\"\"\n",
    "    Calculates, saves, and prints average precision score on test set; \n",
    "    optionally plot how average precision changed over iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Score classifier with the test data\n",
    "    # Try if classifier supports probability\n",
    "    try:\n",
    "        y_score = clf.predict_proba(X_test_pc)[:,1]\n",
    "    # If it doesn't, use its decision function\n",
    "    except AttributeError:\n",
    "        y_score = clf.decision_function(X_test_pc)\n",
    "   \n",
    "    # Calculate average precision\n",
    "    ap_score = average_precision_score(y_test, y_score)\n",
    "    \n",
    "    # Save AP\n",
    "    try:\n",
    "        average_precision_hp[model_name] = ap_score\n",
    "    # If dictionary to save AP doesn't exist yet, create it first\n",
    "    except NameError:\n",
    "        average_precision = {}\n",
    "        average_precision[model_name] = ap_score\n",
    "    \n",
    "    # Print AP\n",
    "    print('Best average precision score on *test* set: {}'.format(ap_score))\n",
    "    \n",
    "    \n",
    "    # Plot AP, if specified\n",
    "    if validation_plot:\n",
    "        # Load progress file with validation performance\n",
    "        progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "        progress_file = pd.read_csv(progress_file_path)\n",
    "\n",
    "        # Extract AP for each iteration\n",
    "        ap = - progress_file.loss\n",
    "        ap.plot()\n",
    "        plt.title('Performance on *Validation* Set')\n",
    "        plt.ylabel('Average Precision')\n",
    "        plt.xlabel('Iteration');\n",
    "\n",
    "print_save_ap(svm_rbf_hp, 'svm_rbf_hp', X_test_pc, y_test_s, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_1 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'gamma': np.logspace(-5, 1, 8)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_rbf_gs_1 = GridSearchCV(svm_rbf_1, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_1, 'saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_1 = joblib.load('saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_1 = svm_rbf_gs_1.predict(X_test_small)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_1 = svm_rbf_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_rbf_1)\n",
    "\n",
    "classification_reports_1['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_rbf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_best_result(svm_rbf_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs_1) #, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs_1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_2 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=10000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-2, 3, 6),\n",
    "              'gamma': np.logspace(-5, -1, 4)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, random_state=1,\n",
    "                             train_size=50000, test_size=1000)\n",
    "\n",
    "svm_rbf_gs_2 = GridSearchCV(svm_rbf_2, param_grid=param_grid,\n",
    "                          return_train_score=True, n_jobs=3,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_2, 'saved_models/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_2 = joblib.load('saved_model/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_2 = svm_rbf_gs_2.predict(X_test)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_2 = svm_rbf_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_rbf_2)\n",
    "\n",
    "classification_reports_2['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_rbf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_best_result(svm_rbf_gs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs_2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with polynomial kernel \n",
    "\n",
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel='poly', probability=False, gamma='auto',\n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'degree': [2,3,4]}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_poly_gs = GridSearchCV(svm_poly, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_poly_gs.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_poly = svm_poly_gs.predict(X_test_p)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_poly = svm_poly_gs.decision_function(X_test_p)\n",
    "\n",
    "# Save results\n",
    "average_precision['SVM (Polynomial Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_poly)\n",
    "\n",
    "classification_reports['SVM (Polynomial Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_poly_gs, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(svm_poly_gs, 'svm_poly_gs.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = \n",
    "plt.title('Impact of Dropping Columns on Classifier Performance')\n",
    "plt.ylabel('Average Precision');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "47.2px",
    "left": "591.8px",
    "top": "95.6px",
    "width": "211.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
