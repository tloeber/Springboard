{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Predictive-models\" data-toc-modified-id=\"Predictive-models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Predictive models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forests\" data-toc-modified-id=\"Random-Forests-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Random Forests</a></span></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2.3.1.1\"><span class=\"toc-item-num\">2.3.1.1&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2.3.1.2\"><span class=\"toc-item-num\">2.3.1.2&nbsp;&nbsp;</span>Hyperopt</a></span></li></ul></li><li><span><a href=\"#With-all-data\" data-toc-modified-id=\"With-all-data-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>With all data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2.3.2.1\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2.3.2.2\"><span class=\"toc-item-num\">2.3.2.2&nbsp;&nbsp;</span>Hyperopt</a></span></li></ul></li></ul></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Support Vector Machine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-SVM\" data-toc-modified-id=\"Linear-SVM-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Linear SVM</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.1.1\"><span class=\"toc-item-num\">2.4.1.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2.4.1.2\"><span class=\"toc-item-num\">2.4.1.2&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2.4.1.3\"><span class=\"toc-item-num\">2.4.1.3&nbsp;&nbsp;</span>Hyperopt</a></span></li><li><span><a href=\"#With-whole-data-set\" data-toc-modified-id=\"With-whole-data-set-2.4.1.4\"><span class=\"toc-item-num\">2.4.1.4&nbsp;&nbsp;</span>With whole data set</a></span></li></ul></li><li><span><a href=\"#SVM-with-RBF-Kernel\" data-toc-modified-id=\"SVM-with-RBF-Kernel-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>SVM with RBF-Kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.2.1\"><span class=\"toc-item-num\">2.4.2.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-more-data\" data-toc-modified-id=\"With-more-data-2.4.2.2\"><span class=\"toc-item-num\">2.4.2.2&nbsp;&nbsp;</span>With more data</a></span></li></ul></li><li><span><a href=\"#SVM-with-polynomial-kernel\" data-toc-modified-id=\"SVM-with-polynomial-kernel-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>SVM with polynomial kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.3.1\"><span class=\"toc-item-num\">2.4.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Performance-comparison\" data-toc-modified-id=\"Performance-comparison-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Performance comparison</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    " \n",
    "import missingno  # for visualizing missing data\n",
    "\n",
    "from hyperopt import hp\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, \\\n",
    "    LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    precision_recall_curve, average_precision_score, f1_score, \\\n",
    "    roc_curve, auc, roc_auc_score, make_scorer,\\\n",
    "    accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "\n",
    "# Set up pandas table display\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Set plotting options\n",
    "sns.set() # Use seaborn defaults for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# Adjust number of CPU cores to use\n",
    "n_jobs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training and test set, incl. feature names \n",
    "X_train = joblib.load('data_processed/X_train.joblib')\n",
    "X_test = joblib.load('data_processed/X_test.joblib')\n",
    "y_train = joblib.load('data_processed/y_train.joblib')\n",
    "y_test = joblib.load('data_processed/y_test.joblib')\n",
    "X_train_small = joblib.load('data_processed/X_train_small.joblib')\n",
    "X_test_small = joblib.load('data_processed/X_test_small.joblib')\n",
    "y_train_small = joblib.load('data_processed/y_train_small.joblib')\n",
    "y_test_small = joblib.load('data_processed/y_test_small.joblib')\n",
    "feature_names = joblib.load('data_processed/feature_names')\n",
    "feature_names_small = joblib.load('data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "with open('data_processed/all_data.pickle', 'rb') as pickled_file: \n",
    "    all_data = pickle.load(pickled_file) \n",
    "    \n",
    "    \n",
    "# Find categorical variables with more than 50 unique values and drop them\n",
    "unique_values_cat = all_data.select_dtypes(include='object') \\\n",
    "                        .nunique() \\\n",
    "                        .sort_values(ascending=False) \n",
    "# Drop categorical variables with more than 50 categories\n",
    "all_data = all_data.drop(unique_values_cat[unique_values_cat > 50].index,\n",
    "                 axis='columns')\n",
    "\n",
    "\n",
    "def split_preprocess(X=all_data.drop('default', axis='columns'),\n",
    "                     y=all_data.default,\n",
    "                     train_size=.8, test_size=.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test set of specified size, \n",
    "    then applies preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train-test split \n",
    "    # ================\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y,\n",
    "                         train_size=train_size, test_size=test_size,\n",
    "                         random_state=1, shuffle=True, stratify=y) \n",
    "\n",
    "    # Preprocessing\n",
    "    # =============\n",
    "    # Imputation and standardization for numeric features\n",
    "    numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "    numeric_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())]) \n",
    "\n",
    "    # Imputation and one-hot encoding for categorical features\n",
    "    categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "    categorical_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Combining preprocessing for both kinds of features\n",
    "    # (Features of other dtypes – in our case, boolean – will be\n",
    "    # appended at the end without transformation.)\n",
    "    # (Use only 1 core to avoid joblib error)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric_transformer', \n",
    "                 numeric_transformer, numeric_features),\n",
    "            ('categorical_transformer', \n",
    "                 categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough', n_jobs=1) \n",
    "    \n",
    "    # Print dtypes of untransformed data\n",
    "    print('data types of columns that were not transformed:\\n {}'\n",
    "            .format(X_train.select_dtypes(exclude=[np.number, object]) \\\n",
    "                    .dtypes.unique()))\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_p = preprocessor.fit_transform(X_train)\n",
    "    X_test_p = preprocessor.transform(X_test)\n",
    "   \n",
    "\n",
    "    # Get feature names\n",
    "    # =================\n",
    "    # Names of categorical variables after one-hot encoding\n",
    "    categorical_names = preprocessor \\\n",
    "        .named_transformers_['categorical_transformer'] \\\n",
    "        .named_steps['onehot'] \\\n",
    "        .get_feature_names()\n",
    "    # Names of columns with other dtype (should only be Boolean)\n",
    "    other_names = X_train \\\n",
    "        .select_dtypes(exclude=[np.number, object]) \\\n",
    "        .columns\n",
    "    # Concatenate feature names (Note that list with names of \n",
    "    # numeric features was already created above)\n",
    "    feature_names = list(numeric_features) + \\\n",
    "        list(categorical_names) + list(other_names) \n",
    "\n",
    "    \n",
    "    # Return results\n",
    "    # ==============\n",
    "    return(X_train_p, X_test_p, y_train, y_test, feature_names)\n",
    "  \n",
    "    \n",
    "# Create smaller training and test data to start out with\n",
    "X_train_small, X_test_small, y_train_small, y_test_small, feature_names_small= \\\n",
    "    split_preprocess(train_size=20000, test_size=10000)\n",
    "\n",
    "# Create full training and test set\n",
    "X_train, X_test, y_train, y_test, feature_names = \\\n",
    "    split_preprocess(train_size=.8, test_size=.2)\n",
    "\n",
    "\n",
    "# Save preprocessed training and test sets\n",
    "filenames_whole = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "filenames_small = [filename + '_small' for filename in filenames_whole]\n",
    "filenames = filenames_whole + filenames_small\n",
    "files = [X_train, X_test, y_train, y_test,\n",
    "         X_train_small, X_test_small, y_train_small, y_test_small]\n",
    "\n",
    "for file, filename in zip(files, filenames):\n",
    "    joblib.dump(file,\n",
    "                'data_processed/{}.joblib'.format(filename))\n",
    "# Delete temporary list to conserve memory\n",
    "del files\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(feature_names, 'data_processed/feature_names')\n",
    "joblib.dump(feature_names_small, 'data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store results for SMALL data set\n",
    "# average_precision_1 = {}\n",
    "classification_reports_1 = {}\n",
    "most_important_features_1 = {} \n",
    "# Note that models with small data were estimated on a different subset\n",
    "# of the observations, though the size stayed constant.  So don't use future \n",
    "# importance on these data, unless re-estimating models!\n",
    "\n",
    "# Dictionaries to store results for WHOLE data set\n",
    "# average_precision_2 = {}\n",
    "classification_reports_2 = {}\n",
    "most_important_features_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average precision\n",
    "def print_save_ap(clf, model_name, X_test, y_test, validation_plot=False):\n",
    "    \"\"\"\n",
    "    Calculates, saves, and prints average precision score on test set; \n",
    "    optionally plot how average precision changed over iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Score classifier with the test data\n",
    "    # Try if classifier supports probability\n",
    "    try:\n",
    "        y_score = clf.predict_proba(X_test)[:,1]\n",
    "    # If it doesn't, use its decision function\n",
    "    except AttributeError:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "   \n",
    "    # Calculate average precision\n",
    "    ap_score = average_precision_score(y_test, y_score)\n",
    "    \n",
    "    # Save AP\n",
    "    try:\n",
    "        average_precision_hp[model_name] = ap_score\n",
    "    # If dictionary to save AP doesn't exist yet, create it first\n",
    "    except NameError:\n",
    "        average_precision = {}\n",
    "        average_precision[model_name] = ap_score\n",
    "    \n",
    "    # Print AP\n",
    "    print('Best average precision score on *test* set: {}'.format(ap_score))\n",
    "    \n",
    "    \n",
    "    # Plot AP, if specified\n",
    "    if validation_plot:\n",
    "        # Load progress file with validation performance\n",
    "        progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "        progress_file = pd.read_csv(progress_file_path)\n",
    "\n",
    "        # Extract AP for each iteration\n",
    "        ap = - progress_file.loss\n",
    "        ap.plot()\n",
    "        plt.title('Performance on *Validation* Set')\n",
    "        plt.ylabel('Average Precision')\n",
    "        plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Function to carry out hyperparameter optimization\n",
    "def find_best_hp(CLF, space, model_name,\n",
    "                 X_train, y_train, \n",
    "                 n_folds=5, n_jobs=-1, max_evals=20):\n",
    "    \"\"\"Find best hyperparameters for a given classifier and search space.\"\"\"\n",
    "    \n",
    "    # Trials object to track progress\n",
    "    trials = Trials()\n",
    "\n",
    "    # CSV file to track progress\n",
    "    progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "    with open(progress_file_path, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write header to the file\n",
    "        writer.writerow(['loss', 'params'])\n",
    "\n",
    "    # Objective function to minimize\n",
    "    def objective(params, CLF=CLF, progress_file_path=progress_file_path,\n",
    "                  n_folds=n_folds, n_jobs=N_JOBS):\n",
    "        \"\"\"Objective function to minimize\"\"\"\n",
    "\n",
    "        # Instantiate CLF\n",
    "        clf = CLF(**params)\n",
    "        \n",
    "        ## Generate indices is for cross-validation\n",
    "        # If only one \"fold\" is desired, split into train and validation set\n",
    "        if n_folds == 1: \n",
    "            cv = StratifiedShuffleSplit(n_splits=1, test_size=.2, \n",
    "                                        random_state=1)\n",
    "        # Otherwise, generate indices for proper cross-validation split\n",
    "        else:  \n",
    "            cv = StratifiedKFold(n_folds, random_state=1)\n",
    "\n",
    "        # Compute average precision through CV / validation set\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=cv,\n",
    "                                scoring='average_precision', n_jobs=N_JOBS)\n",
    "        # Compute loss as the negative mean of the average precision scores\n",
    "        # (since hyperopt can only minimize a function)\n",
    "        loss = -score.mean()\n",
    "        \n",
    "        # Save results to csv file\n",
    "        with open(progress_file_path, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([loss, params])\n",
    "        \n",
    "        # Return results\n",
    "        return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "    \n",
    "    # Minimize objective\n",
    "    best = fmin(objective, space, algo=tpe.suggest,\n",
    "                max_evals=max_evals, trials=trials)\n",
    "\n",
    "    # Get the values of the optimal parameters\n",
    "    best_params = space_eval(space, best)\n",
    "\n",
    "    # Fit the model with the optimal hyperparamters\n",
    "    clf = CLF(**best_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Save model to disk\n",
    "    joblib.dump(clf, 'saved_models/' + model_name + '.joblib')\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fit random forest with default parameters\n",
    "rf_2 = RandomForestClassifier(n_estimators=100, \n",
    "        oob_score=False, n_jobs=N_JOBS, random_state=1,\n",
    "        class_weight='balanced_subsample')\n",
    "rf_2.fit(X_train, y_train)\n",
    "\n",
    "# Predictions of class and probability\n",
    "y_pred_rf_2 = rf_2.predict(X_test) \n",
    "y_pred_proba_rf_2 = rf_2.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf_2, 'rf_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 3\n",
    "# Compute sqrt of number of features for baseline max_features\n",
    "sqrt_n_ft = np.sqrt(X_train.shape[1])\n",
    "sqrt_n_ft\n",
    "\n",
    "# Parameters to search over (uniform distributions)\n",
    "param_distributions = {'n_estimators': np.arange(50, 750),\n",
    "                      'max_depth': np.arange(20, 100),\n",
    "                      'max_features': np.arange(\n",
    "                          int(0.25 * sqrt_n_ft), int(1.5 * sqrt_n_ft)),\n",
    "                      'min_samples_leaf': np.arange(1, 200)}\n",
    "# Randomized  search\n",
    "rf = RandomForestClassifier()\n",
    "rf_rs_2 = RandomizedSearchCV(rf, param_distributions=param_distributions, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=False, random_state=1,\n",
    "                       n_jobs=N_JOBS, cv=5, n_iter=100)\n",
    "rf_rs_2.fit(X_train, y_train) \n",
    "\n",
    "# Save model to disk\n",
    "joblib.dump(rf_rs_2, 'saved_models/rf_rs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "rf_rs_1 = joblib.load('saved_models/rf_rs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf_rs_2, 'rf_rs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf, 'rf', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of parameters to tune, we need a smart way of searching over the different parameters that avoids the combinatorial explosion that would result from a simultaneous grid search over all parameters.  In the following, I will follow the suggestions from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/.\n",
    "\n",
    "We will start with a high learning rate to speed up computation, and then determine the ideal number of estimators for this learning rate.  Later, we will tune tree-specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_train = xgb.DMatrix(data=X_train_small, label=y_train_small)\n",
    "data_xgb_test = xgb.DMatrix(data=X_test_small, label=y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # params = {'objective':'binary:logistic', 'eval_metric':'map',\n",
    "#          'scale_pos_weight':5,  # Balance class weight\n",
    "#          'seed':0, 'learning_rate':0.1, 'n_estimators':1000,\n",
    "#          'max_depth':5, 'min_child_weight':1, 'gamma':0,\n",
    "#          'subsample':0.8, 'colsample_bytree':0.8,\n",
    "#          'nthread':4}\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'map'\n",
    "}\n",
    "\n",
    "N_THREAD = 3\n",
    "space = {\n",
    "    'objective':'binary:logistic', \n",
    "    'eval_metric':'map',\n",
    "    'scale_pos_weight':5,  # Balance class weight\n",
    "    'seed':0, \n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 1000, 1),\n",
    "    'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "    # A problem with max_depth casted to float instead of int with\n",
    "    # the hp.quniform method.\n",
    "    'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "    'eval_metric': 'auc',\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': N_THREAD,\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'exact',\n",
    "    'silent': 1,\n",
    "    'seed': random_state\n",
    "    }\n",
    "xgb_cv = xgb.train(params=params, dtrain=data_xgb_train, \n",
    "                num_boost_round=1000,\n",
    "                evals=[(data_xgb_test, \"test\")],\n",
    "                early_stopping_rounds=50) \n",
    "#                 stratified=True, num_boost_round=1000, \n",
    "#                 early_stopping_rounds=50, verbose_eval=False,\n",
    "#                 as_pandas=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to search over\n",
    "param_grid = {'max_depth'= [3, 5, 7, 10],  # Control complexity\n",
    "              'min_child_weight'= , # The higher, the more regularization\n",
    "              'gamma'= 0, # Higher value leads to fewer splits for a given node (i.e. more regularization) if\n",
    "              'subsample'= [0.5, 0.75, 1],  # Fraction of observations per tree \n",
    "              'colsample_bytree': [0.5, 0.75, 1]} # Fraction of features per tree\n",
    "# Grid search\n",
    "xgb_gs_1 = GridSearchCV(xgb_1, param_grid=param_grid, \n",
    "                        num_boo\n",
    "                        scoring='average_precision',\n",
    "                        return_train_score=True,\n",
    "                        n_jobs=N_JOBS, cv=3, verbose=5)\n",
    "xgb_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(xgb_gs_1, 'saved_models/xgb_gs_1.joblib')\n",
    "\n",
    "# Predictions\n",
    "y_proba_xgb = xgb_.predict_proba(X_test_small)[:, 1]\n",
    "average_precision_score(y_test_small, y_proba_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_1 = XGBClassifier(objective='binary:logistic', learning_rate=0.1,\n",
    "               n_estimators=1000,\n",
    "               max_depth=5,min_child_weight=1, gamma=0,\n",
    "               subsample=0.8, colsample_bytree=0.8,\n",
    "               seed=0, nthread=N_JOBS)\n",
    "xgb_1.fit(X_train_small, y_train_small,\n",
    "          early_stopping_rounds=50,\n",
    "          eval_set=[(X_test_small, y_test_small)],\n",
    "          eval_metric='map'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# joblib.dump(xgb_gs_1, 'saved_models/xgb_gs_1.joblib')\n",
    "\n",
    "# Predictions\n",
    "y_proba_xgb = xgb_1.predict_proba(X_test_small)[:, 1]\n",
    "average_precision_score(y_test_small, y_proba_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':'binary:logistic', 'eval_metric':'map',\n",
    "         'scale_pos_weight':5,  # Balance class weight\n",
    "         'seed':0}\n",
    "xgb_cv = xgb.cv(dtrain=data_xgb_train, params=params, nfold=3,\n",
    "                num_boost_round=50, as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb_cv = xgb_cv.predict(X_test_small)\n",
    "average_precision_score(y_test_small, y_xgb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "#### With smaller subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_1 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 1, 8)}\n",
    "# Grid search\n",
    "lr_gs_1 = GridSearchCV(lr_1, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=N_JOBS, cv=3)\n",
    "lr_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_gs_1, 'saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_1 = joblib.load('saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_best_result(gridsearchcv, decimals=3):\n",
    "    \"\"\"Returns details for best results from grid search.\"\"\"\n",
    "\n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(gridsearchcv.cv_results_) \\\n",
    "                .drop('params', axis='columns')\n",
    "    \n",
    "    # Get values for hyperparameters \n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    \n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], axis=1)\n",
    "    # Set hyperparameters as index\n",
    "    scores_w_params = scores_w_params \\\n",
    "                        .set_index(params.columns.tolist())\n",
    "    \n",
    "    # Get tuple with best hyperparameters values, making sure it \n",
    "    # has the same order as the multi-index.\n",
    "    best_param_tuple = (\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[0]],\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[1]])\n",
    "    \n",
    "    # Filter results for best hyperparameters \n",
    "    best_result = pd.to_numeric(\n",
    "                    scores_w_params.loc[best_param_tuple, :])\n",
    "    \n",
    "    # Return rounded result (convert to dataframe for pretty  printing)\n",
    "    return(pd.DataFrame(best_result) \\\n",
    "               .round(decimals))\n",
    "\n",
    "gs_best_result(lr_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_lr_1= lr_gs_1.predict(X_test_small)    \n",
    "y_pred_proba_lr_1= lr_gs_1.predict_proba(X_test_small)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision_1['logistic regression'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_proba_lr_1)\n",
    "classification_reports_1['logistic regression'] = \\\n",
    "    classification_report(y_test_small, y_pred_lr_1)\n",
    "\n",
    "# Compute feature importance and sort\n",
    "most_important_features_1['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_1.best_estimator_.coef_[0], \n",
    "          index=feature_names_small) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "def gs_heatmap(gridsearchcv, x_digits=0, y_digits=0,\n",
    "               x_scientific_notation=True, y_scientific_notation=True):\n",
    "    \"\"\"Visualizes validation accuracy from grid search over two hyperparameters.\"\"\"\n",
    "    \n",
    "    # Print test score and  hyperparameters\n",
    "    print('Best score: {:.3f}, best hyperparameters: '\n",
    "                .format(gridsearchcv.best_score_), \n",
    "          gridsearchcv.best_params_)\n",
    "      \n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['mean_test_score'])\n",
    "    # Get values for hyperparameters\n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], \n",
    "                                  axis=1)\n",
    "    # Set first two columns, which correspond to parameters, as index.\n",
    "    # Then unstack.\n",
    "    index_cols = list(scores_w_params.columns)[:2]\n",
    "    scores_2d = scores_w_params.set_index(index_cols) \\\n",
    "                    .squeeze() \\\n",
    "                    .unstack()\n",
    "    \n",
    "    # Create desired formatting string for axes (scientific notation and digits)\n",
    "    if x_scientific_notation == True:\n",
    "        x_notation = 'E' \n",
    "    else: \n",
    "        x_notation = 'F'\n",
    "    x_formatting = '{:.' + str(x_digits) + x_notation + '}'\n",
    "\n",
    "    if y_scientific_notation == True:\n",
    "        y_notation = 'E' \n",
    "    else: \n",
    "        y_notation = 'F'\n",
    "    y_formatting = '{:.' + str(y_digits) + y_notation + '}'\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(scores_2d, ax=ax,\n",
    "                xticklabels=[x_formatting.format(x) for  x in scores_2d.columns],\n",
    "                yticklabels=[y_formatting.format(y) for y in scores_2d.index])\n",
    "    ax.set_title('Validation accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(lr_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SGDClassifier, space, model_name='lr_hp_1',\n",
    "              X_train=X_train_small, y_train=y_train_small,\n",
    "              X_test=X_test_small, y_test=y_test_small,\n",
    "              max_evals=8*11, n_jobs=3, n_folds=3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance: 0.37503654872776293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_hp_1 = joblib.load('saved_models/lr_hp_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_lr = pd.read_csv('progress_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best average precision score on validation set\n",
    "-progress_lr.loss.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best performance on the test set, 0.378, is slightly higher than what we found with a grid search, .375. Though this difference is only small, but note that this was achieved with the same number of iterations. Thus, let's take a look at how the performance changed with the number of iterations, to see if we already reached a plateau earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = - progress_lr.loss\n",
    "ap.plot()\n",
    "plt.title('Performance on Validation Set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows nicely how the Bayesian search algorithm has an intelligent approach towards the exploration-exploitation dilemma: For the first 20 or so iterations, it focuses on *exploration*: It searches the hyperparameter space seemingly randomly, resulting in both very high and very low performance. Later, it shifts to *exploitation*: Having identified values for the hyperparameters that work well, it shifts to predominantly searching around these values, resulting in more consistent high performance.  Nevertheless, it occasionally shifts back to exploring values further away, in order to avoid getting stuck in a local maximum.\n",
    "\n",
    "We also see that there does not seem to be much payoff from further optimization once reasonably good values have been found: The best values found during the first 10 iterations are not far off from the overall maximum. Thus, when we ran the hyperparameters optimization on the full data set, we will only let the algorithm run for 40 iteration, since the performance reaches a plateau starting at around 20 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now estimate the model on all data. Based on the results from the smaller data set, we will adjust the parameter grade for alpha, the constant that multiplies the regularization term: We will drop all values for alpha greater than 0.1, since these did not give us good performance. \n",
    "\n",
    "Because we are now using more data, the optimal regularization term will be even smaller; thus, we leave the minimum value for alpha to search over constant, even though it did not give us great performance either on the smaller data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (Elastic Net) \n",
    "# ---------------------------------\n",
    "n_jobs=2\n",
    "lr_2 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 0, 13)}\n",
    "\n",
    "# Grid search\n",
    "lr_gs_2 = GridSearchCV(lr_2, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=N_JOBS, cv=5)\n",
    "lr_gs_2.fit(X_train, y_train) \n",
    "\n",
    "# Save model\n",
    "\n",
    "joblib.dump(lr_gs_2, 'saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_2 = joblib.load('saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_gs_2, 'lr_gs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predictions\n",
    "# y_pred_lr_2 = lr_gs_2.predict(X_test)\n",
    "# y_pred_proba_lr_2 = lr_gs_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Save results\n",
    "# average_precision_2['logistic regression'] = \\\n",
    "#     average_precision_score(y_test, y_pred_proba_lr_2)\n",
    "# classification_reports_2['logistic regression'] = \\\n",
    "#     classification_report(y_test, y_pred_lr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_gs_2, 'lr_gs_2', X_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute feature importance and sort\n",
    "most_important_features_2['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_2.best_estimator_.coef_[0], \n",
    "          index=feature_names) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results    \n",
    "gs_heatmap(lr_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_reports_2['logistic regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 0),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SGDClassifier, space, model_name='lr_hp_2',\n",
    "              X_train=X_train, y_train=y_train,\n",
    "              max_evals=40, n_jobs=3, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_hp_2 = joblib.load('saved_models/lr_hp_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_hp_2, 'lr_hp_2', X_test, y_test, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_1 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 3),\n",
    "              'alpha': np.logspace(-5, 1, 7)}\n",
    "svm_lin_gs_1 = GridSearchCV(svm_lin_1, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=N_JOBS, cv=5)\n",
    "svm_lin_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_1, 'saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model\n",
    "svm_lin_gs_1 = joblib.load('saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_lin_1 = svm_lin_gs_1.predict(X_test_small)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_lin_1 = svm_lin_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_lin_1)\n",
    "classification_reports_1['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_lin_1)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(\n",
    "      SGDClassifier, space, file_name='svm_lin_hp_1'\n",
    "      X_train=X_train_small, y_train=y_train_small,\n",
    "      max_evals=8*11, n_jobs=3, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_lr = pd.read_csv('progress_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best average precision score on validation set\n",
    "-progress_lr.loss.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = - progress_lr.loss\n",
    "ap.plot()\n",
    "plt.title('Performance on Validation Set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### With whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat this analysis on the whole data set. Again, since more data will require less regularization, we will look at lower our maximum value for alpha to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_2 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-5, -1, 9)}\n",
    "svm_lin_gs_2 = GridSearchCV(svm_lin_2, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=N_JOBS, cv=5)\n",
    "svm_lin_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_2, 'saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_lin_gs_2 = joblib.load('saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_2 = svm_lin_gs_2.predict(X_test)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_2 = svm_lin_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_2)\n",
    "classification_reports_2['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_2)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AP score\n",
    "print_save_ap(svm_lin_gs_2, 'svm_lin_gs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -5, -1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(\n",
    "      SGDClassifier, space, model_name='svm_lin_hp_2',\n",
    "      X_train=X_train, y_train=y_train,\n",
    "      max_evals=40, n_jobs=3, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_lin_hp_2 = joblib.load('saved_models/svm_lin_hp_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(svm_lin_hp_2, 'svm_lin_hp_2', X_test, y_test, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with RBF-Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_1 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'gamma': np.logspace(-5, 1, 8)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_rbf_gs_1 = GridSearchCV(svm_rbf_1, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_1, 'saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_1 = joblib.load('saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_1 = svm_rbf_gs_1.predict(X_test_small)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_1 = svm_rbf_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_rbf_1)\n",
    "\n",
    "classification_reports_1['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_rbf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_best_result(svm_rbf_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs_1) #, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs_1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_2 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=10000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-2, 3, 6),\n",
    "              'gamma': np.logspace(-5, -1, 4)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, random_state=1,\n",
    "                             train_size=50000, test_size=1000)\n",
    "\n",
    "svm_rbf_gs_2 = GridSearchCV(svm_rbf_2, param_grid=param_grid,\n",
    "                          return_train_score=True, n_jobs=3,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_2, 'saved_models/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_2 = joblib.load('saved_model/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_2 = svm_rbf_gs_2.predict(X_test)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_2 = svm_rbf_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_rbf_2)\n",
    "\n",
    "classification_reports_2['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_rbf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_best_result(svm_rbf_gs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs_2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with polynomial kernel \n",
    "\n",
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel='poly', probability=False, gamma='auto',\n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'degree': [2,3,4]}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_poly_gs = GridSearchCV(svm_poly, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_poly_gs.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_poly = svm_poly_gs.predict(X_test_p)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_poly = svm_poly_gs.decision_function(X_test_p)\n",
    "\n",
    "# Save results\n",
    "average_precision['SVM (Polynomial Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_poly)\n",
    "\n",
    "classification_reports['SVM (Polynomial Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_poly_gs, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(svm_poly_gs, 'svm_poly_gs.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = \n",
    "plt.title('Impact of Dropping Columns on Classifier Performance')\n",
    "plt.ylabel('Average Precision');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "47.2px",
    "left": "591.8px",
    "top": "95.6px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
