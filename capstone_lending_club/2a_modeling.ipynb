{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Predictive-models\" data-toc-modified-id=\"Predictive-models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Predictive models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forests\" data-toc-modified-id=\"Random-Forests-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Random Forests</a></span></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2.3.1.1\"><span class=\"toc-item-num\">2.3.1.1&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2.3.1.2\"><span class=\"toc-item-num\">2.3.1.2&nbsp;&nbsp;</span>Hyperopt</a></span></li></ul></li><li><span><a href=\"#With-all-data\" data-toc-modified-id=\"With-all-data-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>With all data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2.3.2.1\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2.3.2.2\"><span class=\"toc-item-num\">2.3.2.2&nbsp;&nbsp;</span>Hyperopt</a></span></li></ul></li></ul></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Support Vector Machine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-SVM\" data-toc-modified-id=\"Linear-SVM-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Linear SVM</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.1.1\"><span class=\"toc-item-num\">2.4.1.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-whole-data-set\" data-toc-modified-id=\"With-whole-data-set-2.4.1.2\"><span class=\"toc-item-num\">2.4.1.2&nbsp;&nbsp;</span>With whole data set</a></span></li></ul></li><li><span><a href=\"#SVM-with-RBF-Kernel\" data-toc-modified-id=\"SVM-with-RBF-Kernel-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>SVM with RBF-Kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.2.1\"><span class=\"toc-item-num\">2.4.2.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li><li><span><a href=\"#With-more-data\" data-toc-modified-id=\"With-more-data-2.4.2.2\"><span class=\"toc-item-num\">2.4.2.2&nbsp;&nbsp;</span>With more data</a></span></li></ul></li><li><span><a href=\"#SVM-with-polynomial-kernel\" data-toc-modified-id=\"SVM-with-polynomial-kernel-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>SVM with polynomial kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-smaller-subset-of-data\" data-toc-modified-id=\"With-smaller-subset-of-data-2.4.3.1\"><span class=\"toc-item-num\">2.4.3.1&nbsp;&nbsp;</span>With smaller subset of data</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Performance-comparison\" data-toc-modified-id=\"Performance-comparison-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Performance comparison</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    " \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    StratifiedShuffleSplit, cross_val_score, StratifiedKFold, \\\n",
    "    GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, \\\n",
    "    LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    precision_recall_curve, average_precision_score, f1_score, \\\n",
    "    roc_curve, auc, roc_auc_score, make_scorer,\\\n",
    "    accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "import missingno  # for visualizing missing data\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Set up pandas table display\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Set plotting options\n",
    "sns.set() # Use seaborn defaults for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# Adjust number of CPU cores to use\n",
    "n_jobs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training and test set, incl. feature names \n",
    "X_train = joblib.load('data_processed/X_train.joblib')\n",
    "X_test = joblib.load('data_processed/X_test.joblib')\n",
    "y_train = joblib.load('data_processed/y_train.joblib')\n",
    "y_test = joblib.load('data_processed/y_test.joblib')\n",
    "X_train_small = joblib.load('data_processed/X_train_small.joblib')\n",
    "X_test_small = joblib.load('data_processed/X_test_small.joblib')\n",
    "y_train_small = joblib.load('data_processed/y_train_small.joblib')\n",
    "y_test_small = joblib.load('data_processed/y_test_small.joblib')\n",
    "feature_names = joblib.load('data_processed/feature_names')\n",
    "feature_names_small = joblib.load('data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "with open('data_processed/all_data.pickle', 'rb') as pickled_file: \n",
    "    all_data = pickle.load(pickled_file)  \n",
    "\n",
    "    \n",
    "# Find categorical variables with more than 50 unique values and drop them\n",
    "unique_values_cat = all_data.select_dtypes(include='object') \\\n",
    "                        .nunique() \\\n",
    "                        .sort_values(ascending=False) \n",
    "# Drop categorical variables with more than 50 categories\n",
    "all_data = all_data.drop(unique_values_cat[unique_values_cat > 50].index,\n",
    "                 axis='columns')\n",
    "\n",
    "\n",
    "def split_preprocess(X=all_data.drop('default', axis='columns'),\n",
    "                     y=all_data.default,\n",
    "                     train_size=.8, test_size=.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test set of specified size, \n",
    "    then applies preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train-test split \n",
    "    # ================\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y,\n",
    "                         train_size=train_size, test_size=test_size,\n",
    "                         random_state=1, shuffle=True, stratify=y) \n",
    "\n",
    "    # Preprocessing\n",
    "    # =============\n",
    "    # Imputation and standardization for numeric features\n",
    "    numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "    numeric_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())]) \n",
    "\n",
    "    # Imputation and one-hot encoding for categorical features\n",
    "    categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "    categorical_transformer = Pipeline(steps =[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Combining preprocessing for both kinds of features\n",
    "    # (Features of other dtypes – in our case, boolean – will be\n",
    "    # appended at the end without transformation.)\n",
    "    # (Use only 1 core to avoid joblib error)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric_transformer', \n",
    "                 numeric_transformer, numeric_features),\n",
    "            ('categorical_transformer', \n",
    "                 categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough', n_jobs=1) \n",
    "    \n",
    "    # Print dtypes of untransformed data\n",
    "    print('data types of columns that were not transformed:\\n {}'\n",
    "            .format(X_train.select_dtypes(exclude=[np.number, object]) \\\n",
    "                    .dtypes.unique()))\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_p = preprocessor.fit_transform(X_train)\n",
    "    X_test_p = preprocessor.transform(X_test)\n",
    "   \n",
    "\n",
    "    # Get feature names\n",
    "    # =================\n",
    "    # Names of categorical variables after one-hot encoding\n",
    "    categorical_names = preprocessor \\\n",
    "        .named_transformers_['categorical_transformer'] \\\n",
    "        .named_steps['onehot'] \\\n",
    "        .get_feature_names()\n",
    "    # Names of columns with other dtype (should only be Boolean)\n",
    "    other_names = X_train \\\n",
    "        .select_dtypes(exclude=[np.number, object]) \\\n",
    "        .columns\n",
    "    # Concatenate feature names (Note that list with names of \n",
    "    # numeric features was already created above)\n",
    "    feature_names = list(numeric_features) + \\\n",
    "        list(categorical_names) + list(other_names) \n",
    "\n",
    "    \n",
    "    # Return results\n",
    "    # ==============\n",
    "    return(X_train_p, X_test_p, y_train, y_test, feature_names)\n",
    "  \n",
    "    \n",
    "# Create smaller training and test data to start out with\n",
    "X_train_small, X_test_small, y_train_small, y_test_small, feature_names_small= \\\n",
    "    split_preprocess(train_size=20000, test_size=10000)\n",
    "\n",
    "# Create full training and test set\n",
    "X_train, X_test, y_train, y_test, feature_names = \\\n",
    "    split_preprocess(train_size=.8, test_size=.2)\n",
    "\n",
    "\n",
    "# Save preprocessed training and test sets\n",
    "filenames_whole = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "filenames_small = [filename + '_small' for filename in filenames_whole]\n",
    "filenames = filenames_whole + filenames_small\n",
    "files = [X_train, X_test, y_train, y_test,\n",
    "         X_train_small, X_test_small, y_train_small, y_test_small]\n",
    "\n",
    "for file, filename in zip(files, filenames):\n",
    "    joblib.dump(file,\n",
    "                'data_processed/{}.joblib'.format(filename))\n",
    "# Delete temporary list to conserve memory\n",
    "del files\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(feature_names, 'data_processed/feature_names')\n",
    "joblib.dump(feature_names_small, 'data_processed/feature_names_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store results for SMALL data set\n",
    "# average_precision_1 = {}\n",
    "classification_reports_1 = {}\n",
    "most_important_features_1 = {} \n",
    "# Note that models with small data were estimated on a different subset\n",
    "# of the observations, though the size stayed constant.  So don't use future \n",
    "# importance on these data, unless re-estimating models!\n",
    "\n",
    "# Dictionaries to store results for WHOLE data set\n",
    "# average_precision_2 = {}\n",
    "classification_reports_2 = {}\n",
    "most_important_features_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average precision\n",
    "def print_save_ap(clf, model_name, X_test, y_test, \n",
    "                  X_train, y_train, validation_plot=False):\n",
    "    \"\"\"\n",
    "    Calculates and prints average precision score on train and test set; \n",
    "    saves score from test set. Optionally plot how average precision \n",
    "    changed over iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Score classifier with the test data\n",
    "    # Try if classifier supports probability\n",
    "    try:\n",
    "        y_score = clf.predict_proba(X_test)[:,1]\n",
    "    # If it doesn't, use its decision function\n",
    "    except AttributeError:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "   \n",
    "    # Calculate average precision\n",
    "    ap_score = average_precision_score(y_test, y_score)\n",
    "    ap_score_train = average_precision_score(y_test_train, y_score_train)\n",
    "    \n",
    "    # Save AP\n",
    "    try:\n",
    "        average_precision_hp[model_name] = ap_score\n",
    "    # If dictionary to save AP doesn't exist yet, create it first\n",
    "    except NameError:\n",
    "        average_precision = {}\n",
    "        average_precision[model_name] = ap_score\n",
    "    \n",
    "    # Print AP\n",
    "    print('Best average precision score on *test* set: {}'.format(ap_score))\n",
    "    print('Best average precision score on *training* set: {}'.format(ap_score))\n",
    "    \n",
    "    \n",
    "    # Plot AP, if specified\n",
    "    if validation_plot:\n",
    "        # Load progress file with validation performance\n",
    "        progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "        progress_file = pd.read_csv(progress_file_path)\n",
    "\n",
    "        # Extract AP for each iteration\n",
    "        ap = - progress_file.loss\n",
    "        ap.plot()\n",
    "        plt.title('Performance on *Validation* Set')\n",
    "        plt.ylabel('Average Precision')\n",
    "        plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to carry out hyperparameter optimization\n",
    "def find_best_hp(CLF, space, model_name,\n",
    "                 X_train, y_train, \n",
    "                 n_folds=5, n_jobs=-1, max_evals=20):\n",
    "    \"\"\"Find best hyperparameters for a given classifier and search space.\"\"\"\n",
    "    \n",
    "    # Trials object to track progress\n",
    "    trials = Trials()\n",
    "\n",
    "    # CSV file to track progress\n",
    "    progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "    with open(progress_file_path, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write header to the file\n",
    "        writer.writerow(['loss', 'params'])\n",
    "\n",
    "    # Objective function to minimize\n",
    "    def objective(params, CLF=CLF, progress_file_path=progress_file_path,\n",
    "                  n_folds=n_folds, n_jobs=n_jobs):\n",
    "        \"\"\"Objective function to minimize\"\"\"\n",
    "\n",
    "        # Instantiate CLF\n",
    "        clf = CLF(**params)\n",
    "        \n",
    "        ## Generate indices is for cross-validation\n",
    "        # If only one \"fold\" is desired, split into train and validation set\n",
    "        if n_folds == 1: \n",
    "            cv = StratifiedShuffleSplit(n_splits=1, test_size=.2, \n",
    "                                        random_state=1)\n",
    "        # Otherwise, generate indices for proper cross-validation split\n",
    "        else:  \n",
    "            cv = StratifiedKFold(n_folds, random_state=1)\n",
    "\n",
    "        # Compute average precision through CV / validation set\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=cv,\n",
    "                                scoring='average_precision', n_jobs=n_jobs)\n",
    "        # Compute loss as the negative mean of the average precision scores\n",
    "        # (since hyperopt can only minimize a function)\n",
    "        loss = -score.mean()\n",
    "        \n",
    "        # Save results to csv file\n",
    "        with open(progress_file_path, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([loss, params])\n",
    "        \n",
    "        # Return results\n",
    "        return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "    \n",
    "    # Minimize objective\n",
    "    best = fmin(objective, space, algo=tpe.suggest,\n",
    "                max_evals=max_evals, trials=trials)\n",
    "\n",
    "    # Get the values of the optimal parameters\n",
    "    best_params = space_eval(space, best)\n",
    "\n",
    "    # Fit the model with the optimal hyperparamters\n",
    "    clf = CLF(**best_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Save model to disk\n",
    "    joblib.dump(clf, 'saved_models/' + model_name + '.joblib')\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'n_estimators': hp.normal('n_estimators', 100),\n",
    "          'max_depth': np.arange(20, 100),\n",
    "          'max_features': np.arange(\n",
    "              int(0.25 * sqrt_n_ft), int(1.5 * sqrt_n_ft)),\n",
    "          'min_samples_leaf': np.arange(1, 200)}\n",
    "\n",
    "\n",
    "\n",
    "space = {'n_estimators': np.arange(50, 750),\n",
    "          'max_depth': np.arange(20, 100),\n",
    "          'max_features': np.arange(\n",
    "              int(0.25 * sqrt_n_ft), int(1.5 * sqrt_n_ft)),\n",
    "          'min_samples_leaf': np.arange(1, 200)}\n",
    "\n",
    "N_JOBS = 3\n",
    "# Find best hyperparameters\n",
    "find_best_hp(RandomForestClassifier, space, model_name='rf_hp_1',\n",
    "              X_train=X_train_small, y_train=y_train_small,\n",
    "              max_evals=2, n_jobs=2, n_folds=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fit random forest with default parameters\n",
    "rf_2 = RandomForestClassifier(n_estimators=100, \n",
    "        oob_score=False, n_jobs=N_JOBS, random_state=1,\n",
    "        class_weight='balanced_subsample')\n",
    "rf_2.fit(X_train, y_train)\n",
    "\n",
    "# Predictions of class and probability\n",
    "y_pred_rf_2 = rf_2.predict(X_test) \n",
    "y_pred_proba_rf_2 = rf_2.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf_2, 'rf_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 3\n",
    "# Compute sqrt of number of features for baseline max_features\n",
    "sqrt_n_ft = np.sqrt(X_train.shape[1])\n",
    "sqrt_n_ft\n",
    "\n",
    "# Parameters to search over (uniform distributions)\n",
    "param_distributions = {'n_estimators': np.arange(50, 750),\n",
    "                      'max_depth': np.arange(20, 100),\n",
    "                      'max_features': np.arange(\n",
    "                          int(0.25 * sqrt_n_ft), int(1.5 * sqrt_n_ft)),\n",
    "                      'min_samples_leaf': np.arange(1, 200)}\n",
    "# Randomized  search\n",
    "rf = RandomForestClassifier()\n",
    "rf_rs_2 = RandomizedSearchCV(rf, param_distributions=param_distributions, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=False, random_state=1,\n",
    "                       n_jobs=N_JOBS, cv=5, n_iter=100)\n",
    "rf_rs_2.fit(X_train, y_train) \n",
    "\n",
    "# Save model to disk\n",
    "joblib.dump(rf_rs_2, 'saved_models/rf_rs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "rf_rs_1 = joblib.load('saved_models/rf_rs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf_rs_2, 'rf_rs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(rf, 'rf', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of parameters to tune, we need a smart way of searching over the different parameters that avoids the combinatorial explosion that would result from a simultaneous grid search over all parameters.  \n",
    "\n",
    "In the following, I will follow the suggestions from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ for plausible ranges for the hyperparameters.  However, since I will use Bayesian optimization rather than brute force, I am able to avoid having to repeatedly optimize a small number of parameters at a time. Instead, I will optimize all tree-specific parameters at once, using a relatively higher learning rate to speed up training. Subsequently, I will reestimate the model on the training set with the parameters identified in the previous step, but use a smaller learning rate for increased accuracy. \n",
    "\n",
    "During both of the steps, I will use early stopping to determine the optimal number of trees.  To that end, I split off a quarter of the original training set to use as the validation set for early stopping. Since the original training set has about 200,000 observations, we will still have around 150,000 observations left as the new test set for the final XGBoost classifier. This is more than enough to measure performance with very high accuracy.\n",
    "\n",
    "I will be using XGBoost's native API rather than the Scikit-learn API. This has several benefits, such as being able to use SGBoost's native data format, which increases performance.  Thus, let's start by converting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"<\" from feature names, since this causes problems for xgboost\n",
    "feature_names_xgb = [x.replace('<', '_less_than_') for x in feature_names]\n",
    "\n",
    "\n",
    "# Split original test set into validation set (for early stopping) and new test set\n",
    "X_val_xgb, X_test_xgb, y_val_xgb, y_test_xgb = \\\n",
    "    train_test_split(X_test, y_test,\n",
    "                     train_size=0.25, test_size=0.75,\n",
    "                     random_state=1, shuffle=True, stratify=y_test) \n",
    "\n",
    "# Convert data to DMatrix \n",
    "data_xgb_train = xgb.DMatrix(data=X_train, label=y_train,\n",
    "                             feature_names=feature_names_xgb, nthread=-1)\n",
    "data_xgb_test = xgb.DMatrix(data=X_test_xgb, label=y_test_xgb,\n",
    "                            feature_names=feature_names_xgb)\n",
    "data_xgb_val = xgb.DMatrix(data=X_val_xgb, label=y_val_xgb,\n",
    "                            feature_names=feature_names_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not using the sklearn API, we won't be able to reuse the function defined above for Bayesian hyperparameters optimization. Instead, let's adapt the code for XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most parameters, we will use a normal distribution to define their prior distributions to sample from.  Thus, setting the mean and standard deviation for these distributions is pretty straightforward.  However, for the regularization term alpha, we will use a lognormal distribution (analogous to using a logarithmic grid for a brute force search). Since the relationship between its parameters and the scale of the distribution is less intuitive, let's draw a few samples first to inspect if it yields a plausible distribution for the regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics:\n",
      " count    100.000000\n",
      "mean       7.647200\n",
      "std       12.817076\n",
      "min        0.002542\n",
      "25%        0.068217\n",
      "50%        1.251402\n",
      "75%        9.318613\n",
      "max       54.344284\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Inspect prior distribution for reg_alpha\n",
    "from hyperopt import pyll\n",
    "reg_alpha_distr = hp.loguniform('n_estimators', -6, 4)\n",
    "samples = [pyll.stochastic.sample(reg_alpha_distr) for i in range(100)]\n",
    "\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist', bins=100)\n",
    "plt.xlabel('reg_alpha')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the minimum, maximum, and median, these values look good, so let's go with these parameters.\n",
    "\n",
    "How let's decide on an appropriate prior distribution for gamma, the minimum loss reduction that we require to further partition a node. I will use a lognormal distribution bounded between 0 and 0.5.  The challenge is to define this in hyperopt, because it bounds the distribution by the exponential function of the upper and lower bounds supplied as the parameters. Thus, in order to get a lower bound of 0, we would have to pass log(0) or -$\\infty$ as the parameter. I solved this problem by passing the log of a small number as the lower bound, and then subtract the small number from the final distribution when adjusting the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics:\n",
      " count    1000.000000\n",
      "mean        0.117692\n",
      "std         0.128395\n",
      "min         0.000022\n",
      "25%         0.016077\n",
      "50%         0.070008\n",
      "75%         0.175608\n",
      "max         0.494426\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Inspect prior distribution for gamma\n",
    "from hyperopt import pyll\n",
    "small_number = 0.01\n",
    "\n",
    "gamma_distr = hp.loguniform('n_estimators', \n",
    "                            np.log(small_number), \n",
    "                            np.log(0.5 + small_number))\n",
    "\n",
    "samples = [pyll.stochastic.sample(gamma_distr) - small_number\n",
    "               for i in range(1000)]\n",
    "\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist')\n",
    "plt.xlabel('gamma')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_number = 0.01 # To adjust lower bound for Gamma\n",
    "space = {\n",
    "    # Parameters that we are going to tune (Note that these may be modified\n",
    "    # in objective function to convert to integer or to set min or max.)\n",
    "    'eta':.3,  # Start with a higher learning rate for speed\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'map',\n",
    "    'scale_pos_weight': 5,  # Balance classes\n",
    "    'max_depth': hp.normal('max_depth', 6, 2),\n",
    "    'min_child_weight': hp.normal('min_child_weight', 4, 2), \n",
    "    'gamma': hp.loguniform('gamma', # small number will be subtracted later\n",
    "                            np.log(small_number), \n",
    "                            np.log(0.5 + small_number)),\n",
    "    'subsample': hp.normal('subsample', 0.75, 0.2), \n",
    "    'colsample_bytree':  hp.normal('colsample_bytree', 0.75, 0.2),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -6, 4),\n",
    "    'verbose_eval': False,\n",
    "    'nthread': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options\n",
    "N_JOBS=3\n",
    "MAX_EVALS = 1\n",
    "\n",
    "# CSV file to track progress\n",
    "progress_file_path = 'hp_progress/progress_xgb.csv'\n",
    "with open(progress_file_path, 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header to the file\n",
    "    writer.writerow(['loss', 'params', 'n_trees'])\n",
    "\n",
    "    \n",
    "# Function to convert sampled parameters to integer or make positive, etc., \n",
    "# where necessary\n",
    "def adjust_params_xgb(params):\n",
    "    \"\"\" \n",
    "    Adjust parameters where hyperopt did not allow sampling from optimal \n",
    "    distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert sampled parameters to integer, where  applicable\n",
    "    params['max_depth'] = round(params['max_depth'])\n",
    "    \n",
    "    # Make sure min_child_weight is positive\n",
    "    if params['min_child_weight'] <= 0:\n",
    "        params['min_child_weight'] = 0 # Set to lower bound\n",
    "   \n",
    "    # Subtract the small number from gamma to set 0 as lower bound\n",
    "    params['gamma'] = params['gamma'] - small_number\n",
    "\n",
    "    # Set min or max thresholds for parameters, where applicable\n",
    "    if params['max_depth'] <= 2:\n",
    "        params['max_depth'] = 2\n",
    "    if params['subsample'] < 0:\n",
    "        params['subsample'] = 0\n",
    "    if params['subsample'] > 1:\n",
    "        params['subsample'] = 1\n",
    "    if params['colsample_bytree'] < 0: \n",
    "        params['colsample_bytree'] = 0\n",
    "    if params['colsample_bytree'] > 1:\n",
    "        params['colsample_bytree'] = 0.75\n",
    "    \n",
    "    # Return modified parameters\n",
    "    return params\n",
    "\n",
    "\n",
    "# Objective function to minimize\n",
    "def objective(params, progress_file_path=progress_file_path,\n",
    "              n_jobs=N_JOBS):\n",
    "    \"\"\"Objective function to minimize\"\"\"\n",
    "    \n",
    "    # Adjust parameters\n",
    "    params = adjust_params_xgb(params)\n",
    "    \n",
    "    # Train model\n",
    "    xgb_ = xgb.train(params, dtrain=data_xgb_train, \n",
    "                num_boost_round=1000,\n",
    "                evals=[(data_xgb_val, \"val\")], \n",
    "                early_stopping_rounds=50)\n",
    "    \n",
    "    # Compute loss as the negative mean of the average precision scores\n",
    "    # (since hyperopt can only minimize a function)\n",
    "    loss = - xgb_.best_score\n",
    "    \n",
    "    # Save results to csv file\n",
    "    with open(progress_file_path, 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([loss, params, xgb_.best_ntree_limit])\n",
    "\n",
    "    # Return results\n",
    "    return {'loss': loss, 'params': params, 'n_trees': xgb_.best_ntree_limit, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to carry out the hyperparameters optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:35:14] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[0]\tval-map:0.334662\n",
      "Will train until val-map hasn't improved in 50 rounds.\n",
      "[10:35:16] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[1]\tval-map:0.349399\n",
      "[10:35:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[2]\tval-map:0.354619\n",
      "[10:35:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[3]\tval-map:0.359672\n",
      "[10:35:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[4]\tval-map:0.363973\n",
      "[10:35:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[5]\tval-map:0.369194\n",
      "[10:35:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[6]\tval-map:0.369983\n",
      "[10:35:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[7]\tval-map:0.373693\n",
      "[10:35:30] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[8]\tval-map:0.37597\n",
      "[10:35:32] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[9]\tval-map:0.377168\n",
      "[10:35:35] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[10]\tval-map:0.378\n",
      "[10:35:37] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[11]\tval-map:0.379258\n",
      "[10:35:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[12]\tval-map:0.379833\n",
      "[10:35:41] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[13]\tval-map:0.380228\n",
      "[10:35:43] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14]\tval-map:0.380948\n",
      "[10:35:45] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[15]\tval-map:0.381743\n",
      "[10:35:47] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[16]\tval-map:0.382609\n",
      "[10:35:49] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[17]\tval-map:0.383174\n",
      "[10:35:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[18]\tval-map:0.383586\n",
      "[10:35:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[19]\tval-map:0.385013\n",
      "[10:35:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[20]\tval-map:0.38578\n",
      "[10:35:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[21]\tval-map:0.386299\n",
      "[10:35:59] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[22]\tval-map:0.387015\n",
      "[10:36:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[23]\tval-map:0.38743\n",
      "[10:36:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[24]\tval-map:0.388135\n",
      "[10:36:05] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[25]\tval-map:0.388817\n",
      "[10:36:07] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[26]\tval-map:0.388905\n",
      "[10:36:09] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[27]\tval-map:0.38939\n",
      "[10:36:11] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[28]\tval-map:0.389889\n",
      "[10:36:13] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[29]\tval-map:0.390212\n",
      "[10:36:15] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[30]\tval-map:0.390447\n",
      "[10:36:17] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[31]\tval-map:0.390893\n",
      "[10:36:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[32]\tval-map:0.3911\n",
      "[10:36:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[33]\tval-map:0.391483\n",
      "[10:36:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[34]\tval-map:0.391627\n",
      "[10:36:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[35]\tval-map:0.392035\n",
      "[10:36:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[36]\tval-map:0.392265\n",
      "[10:36:29] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[37]\tval-map:0.392206\n",
      "[10:36:31] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[38]\tval-map:0.392491\n",
      "[10:36:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[39]\tval-map:0.392661\n",
      "[10:36:35] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[40]\tval-map:0.392765\n",
      "[10:36:37] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[41]\tval-map:0.392995\n",
      "[10:36:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[42]\tval-map:0.393323\n",
      "[10:36:41] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[43]\tval-map:0.393826\n",
      "[10:36:43] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[44]\tval-map:0.393881\n",
      "[10:36:46] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[45]\tval-map:0.393943\n",
      "[10:36:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[46]\tval-map:0.394356\n",
      "[10:36:50] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[47]\tval-map:0.394637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:36:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[48]\tval-map:0.394896\n",
      "[10:36:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[49]\tval-map:0.395113\n",
      "[10:36:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[50]\tval-map:0.395304\n",
      "[10:36:58] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[51]\tval-map:0.395375\n",
      "[10:37:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[52]\tval-map:0.395354\n",
      "[10:37:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[53]\tval-map:0.395417\n",
      "[10:37:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[54]\tval-map:0.395682\n",
      "[10:37:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[55]\tval-map:0.395913\n",
      "[10:37:08] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[56]\tval-map:0.396107\n",
      "[10:37:10] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[57]\tval-map:0.396207\n",
      "[10:37:12] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[58]\tval-map:0.396349\n",
      "[10:37:14] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[59]\tval-map:0.396342\n",
      "[10:37:16] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[60]\tval-map:0.396496\n",
      "[10:37:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[61]\tval-map:0.396782\n",
      "[10:37:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[62]\tval-map:0.397016\n",
      "[10:37:22] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[63]\tval-map:0.397156\n",
      "[10:37:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[64]\tval-map:0.397198\n",
      "[10:37:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[65]\tval-map:0.39719\n",
      "[10:37:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[66]\tval-map:0.397116\n",
      "[10:37:30] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[67]\tval-map:0.397127\n",
      "[10:37:32] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[68]\tval-map:0.397164\n",
      "[10:37:34] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[69]\tval-map:0.397513\n",
      "[10:37:36] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[70]\tval-map:0.397543\n",
      "[10:37:38] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[71]\tval-map:0.397785\n",
      "[10:37:40] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[72]\tval-map:0.397799\n",
      "[10:37:42] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[73]\tval-map:0.397934\n",
      "[10:37:44] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[74]\tval-map:0.397879\n",
      "[10:37:46] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[75]\tval-map:0.397843\n",
      "[10:37:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[76]\tval-map:0.397761\n",
      "[10:37:50] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[77]\tval-map:0.397678\n",
      "[10:37:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[78]\tval-map:0.397638\n",
      "[10:37:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[79]\tval-map:0.397755\n",
      "[10:37:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[80]\tval-map:0.397842\n",
      "[10:38:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[81]\tval-map:0.397725\n",
      "[10:38:05] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[82]\tval-map:0.397795\n",
      "[10:38:07] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[83]\tval-map:0.397802\n",
      "[10:38:09] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[84]\tval-map:0.397874\n",
      "[10:38:12] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[85]\tval-map:0.397896\n",
      "[10:38:14] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[86]\tval-map:0.398074\n",
      "[10:38:17] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[87]\tval-map:0.398279\n",
      "[10:38:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[88]\tval-map:0.398388\n",
      "[10:38:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[89]\tval-map:0.39837\n",
      "[10:38:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[90]\tval-map:0.398512\n",
      "[10:38:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[91]\tval-map:0.398496\n",
      "[10:38:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[92]\tval-map:0.398406\n",
      "[10:38:30] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[93]\tval-map:0.398376\n",
      "[10:38:32] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[94]\tval-map:0.398302\n",
      "[10:38:34] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[95]\tval-map:0.398493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:38:36] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[96]\tval-map:0.398392\n",
      "[10:38:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[97]\tval-map:0.398331\n",
      "[10:38:41] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[98]\tval-map:0.39843\n",
      "[10:38:43] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[99]\tval-map:0.39851\n",
      "[10:38:45] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[100]\tval-map:0.398823\n",
      "[10:38:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[101]\tval-map:0.399085\n",
      "[10:38:50] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[102]\tval-map:0.399097\n",
      "[10:38:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[103]\tval-map:0.399219\n",
      "[10:38:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[104]\tval-map:0.399258\n",
      "[10:38:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[105]\tval-map:0.399241\n",
      "[10:38:58] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[106]\tval-map:0.399387\n",
      "[10:39:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[107]\tval-map:0.399338\n",
      "[10:39:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[108]\tval-map:0.399394\n",
      "[10:39:05] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[109]\tval-map:0.399321\n",
      "[10:39:07] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[110]\tval-map:0.399551\n",
      "[10:39:09] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[111]\tval-map:0.399586\n",
      "[10:39:11] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[112]\tval-map:0.399666\n",
      "[10:39:13] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[113]\tval-map:0.399828\n",
      "[10:39:15] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[114]\tval-map:0.399746\n",
      "[10:39:17] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[115]\tval-map:0.399686\n",
      "[10:39:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[116]\tval-map:0.399742\n",
      "[10:39:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[117]\tval-map:0.399728\n",
      "[10:39:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[118]\tval-map:0.399691\n",
      "[10:39:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[119]\tval-map:0.399587\n",
      "[10:39:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[120]\tval-map:0.399544\n",
      "[10:39:29] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[121]\tval-map:0.399547\n",
      "[10:39:31] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[122]\tval-map:0.399705\n",
      "[10:39:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[123]\tval-map:0.39961\n",
      "[10:39:35] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[124]\tval-map:0.399589\n",
      "[10:39:37] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[125]\tval-map:0.399574\n",
      "[10:39:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[126]\tval-map:0.399469\n",
      "[10:39:41] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[127]\tval-map:0.399438\n",
      "[10:39:43] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[128]\tval-map:0.399268\n",
      "[10:39:46] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[129]\tval-map:0.399263\n",
      "[10:39:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[130]\tval-map:0.399345\n",
      "[10:39:50] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[131]\tval-map:0.399177\n",
      "[10:39:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[132]\tval-map:0.39928\n",
      "[10:39:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[133]\tval-map:0.399247\n",
      "[10:39:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[134]\tval-map:0.399237\n",
      "[10:39:58] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[135]\tval-map:0.399158\n",
      "[10:40:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[136]\tval-map:0.399328\n",
      "[10:40:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[137]\tval-map:0.399338\n",
      "[10:40:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[138]\tval-map:0.399355\n",
      "[10:40:07] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[139]\tval-map:0.399683\n",
      "[10:40:09] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[140]\tval-map:0.399558\n",
      "[10:40:11] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[141]\tval-map:0.399489\n",
      "[10:40:13] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[142]\tval-map:0.399412\n",
      "[10:40:15] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[143]\tval-map:0.399539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:40:17] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[144]\tval-map:0.399558\n",
      "[10:40:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[145]\tval-map:0.399593\n",
      "[10:40:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[146]\tval-map:0.399499\n",
      "[10:40:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[147]\tval-map:0.399322\n",
      "[10:40:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[148]\tval-map:0.399238\n",
      "[10:40:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[149]\tval-map:0.399242\n",
      "[10:40:29] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[150]\tval-map:0.399307\n",
      "[10:40:31] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[151]\tval-map:0.399232\n",
      "[10:40:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[152]\tval-map:0.39923\n",
      "[10:40:35] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[153]\tval-map:0.399386\n",
      "[10:40:38] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[154]\tval-map:0.399271\n",
      "[10:40:40] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[155]\tval-map:0.399191\n",
      "[10:40:42] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[156]\tval-map:0.399145\n",
      "[10:40:44] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[157]\tval-map:0.399132\n",
      "[10:40:46] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[158]\tval-map:0.399068\n",
      "[10:40:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[159]\tval-map:0.399066\n",
      "[10:40:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[160]\tval-map:0.399313\n",
      "[10:40:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[161]\tval-map:0.399482\n",
      "[10:40:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[162]\tval-map:0.399429\n",
      "[10:40:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[163]\tval-map:0.399512\n",
      "Stopping. Best iteration:\n",
      "[113]\tval-map:0.399828\n",
      "\n",
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "\n",
    "# Minimize objective\n",
    "best = fmin(objective, space, algo=tpe.suggest,\n",
    "            max_evals=MAX_EVALS)\n",
    "\n",
    "# Get the values of the optimal parameters\n",
    "best_params = space_eval(space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full results from progress file\n",
    "xgb_results = pd.read_csv('hp_progress/progress_xgb.csv')\n",
    "\n",
    "# Get validation score\n",
    "# Extract AP for each iteration\n",
    "ap_xgb = - xgb_results.loss\n",
    "\n",
    "print(f'Best average precision on validation set: {ap_xgb.max()}')\n",
    "\n",
    "# Plot AP per iteration\n",
    "ap_xgb.plot()\n",
    "plt.title('Performance on validation set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the best parameters, let's re-estimate the model with a lower learning rate to get another boost in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease learning rate\n",
    "best_params['eta'] = 0.005\n",
    "\n",
    "# Adjust parameters (e.g., convert to integer)\n",
    "best_params = adjust_params_xgb(best_params)\n",
    "\n",
    "# Fit the model with the optimal hyperparamters and lower learning rate\n",
    "xgb_best = xgb.train(best_params,\n",
    "                    dtrain=data_xgb_train, \n",
    "                    num_boost_round=10000,\n",
    "                    evals=[(data_xgb_val, \"val\")], \n",
    "                    early_stopping_rounds=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best.best_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute test score of final model\n",
    "# Make predicition\n",
    "y_xgb = xgb_best.predict(data_xgb_test)\n",
    "y_xgb\n",
    "\n",
    "# Save and print AP\n",
    "ap_xgb = average_precision_score(y_test_xgb, y_xgb)\n",
    "print(f'Average precision on test set: {ap_xgb}')\n",
    "# average_precision['xgb'] = ap_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add optimum number of trees to best parameters\n",
    "best_params['num_boost_round'] = xgb_best.best_ntree_limit\n",
    "# Remove early stopping, because now we don't need it anymore\n",
    "best_params['early_stopping_rounds'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature importances\n",
    "fi_xgb = pd.Series(xgb_best.get_fscore()) \\\n",
    "            .sort_values(ascending=False)\n",
    "feature_importances = {}\n",
    "feature_importances['xgb'] = fi_xgb\n",
    "fi_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "#### With smaller subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_1 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 1, 8)}\n",
    "# Grid search\n",
    "lr_gs_1 = GridSearchCV(lr_1, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=N_JOBS, cv=3)\n",
    "lr_gs_1.fit(X_train_small, y_train_small) \n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_gs_1, 'saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_1 = joblib.load('saved_models/lr_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_best_result(gridsearchcv, decimals=3):\n",
    "    \"\"\"Returns details for best results from grid search.\"\"\"\n",
    "\n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(gridsearchcv.cv_results_) \\\n",
    "                .drop('params', axis='columns')\n",
    "    \n",
    "    # Get values for hyperparameters \n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    \n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], axis=1)\n",
    "    # Set hyperparameters as index\n",
    "    scores_w_params = scores_w_params \\\n",
    "                        .set_index(params.columns.tolist())\n",
    "    \n",
    "    # Get tuple with best hyperparameters values, making sure it \n",
    "    # has the same order as the multi-index.\n",
    "    best_param_tuple = (\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[0]],\n",
    "        gridsearchcv.best_params_[scores_w_params.index.names[1]])\n",
    "    \n",
    "    # Filter results for best hyperparameters \n",
    "    best_result = pd.to_numeric(\n",
    "                    scores_w_params.loc[best_param_tuple, :])\n",
    "    \n",
    "    # Return rounded result (convert to dataframe for pretty  printing)\n",
    "    return(pd.DataFrame(best_result) \\\n",
    "               .round(decimals))\n",
    "\n",
    "gs_best_result(lr_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_lr_1= lr_gs_1.predict(X_test_small)    \n",
    "y_pred_proba_lr_1= lr_gs_1.predict_proba(X_test_small)[:, 1]\n",
    "\n",
    "# Save results\n",
    "average_precision_1['logistic regression'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_proba_lr_1)\n",
    "classification_reports_1['logistic regression'] = \\\n",
    "    classification_report(y_test_small, y_pred_lr_1)\n",
    "\n",
    "# Compute feature importance and sort\n",
    "most_important_features_1['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_1.best_estimator_.coef_[0], \n",
    "          index=feature_names_small) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "def gs_heatmap(gridsearchcv, x_digits=0, y_digits=0,\n",
    "               x_scientific_notation=True, y_scientific_notation=True):\n",
    "    \"\"\"Visualizes validation accuracy from grid search over two hyperparameters.\"\"\"\n",
    "    \n",
    "    # Print test score and  hyperparameters\n",
    "    print('Best score: {:.3f}, best hyperparameters: '\n",
    "                .format(gridsearchcv.best_score_), \n",
    "          gridsearchcv.best_params_)\n",
    "      \n",
    "    # Get mean validation scores\n",
    "    scores = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['mean_test_score'])\n",
    "    # Get values for hyperparameters\n",
    "    params = pd.DataFrame(\n",
    "        gridsearchcv.cv_results_['params'])\n",
    "    # Concatenate validation scores and hyperparameters \n",
    "    scores_w_params = pd.concat([params, scores], \n",
    "                                  axis=1)\n",
    "    # Set first two columns, which correspond to parameters, as index.\n",
    "    # Then unstack.\n",
    "    index_cols = list(scores_w_params.columns)[:2]\n",
    "    scores_2d = scores_w_params.set_index(index_cols) \\\n",
    "                    .squeeze() \\\n",
    "                    .unstack()\n",
    "    \n",
    "    # Create desired formatting string for axes (scientific notation and digits)\n",
    "    if x_scientific_notation == True:\n",
    "        x_notation = 'E' \n",
    "    else: \n",
    "        x_notation = 'F'\n",
    "    x_formatting = '{:.' + str(x_digits) + x_notation + '}'\n",
    "\n",
    "    if y_scientific_notation == True:\n",
    "        y_notation = 'E' \n",
    "    else: \n",
    "        y_notation = 'F'\n",
    "    y_formatting = '{:.' + str(y_digits) + y_notation + '}'\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(scores_2d, ax=ax,\n",
    "                xticklabels=[x_formatting.format(x) for  x in scores_2d.columns],\n",
    "                yticklabels=[y_formatting.format(y) for y in scores_2d.index])\n",
    "    ax.set_title('Validation accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(lr_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SGDClassifier, space, model_name='lr_hp_1',\n",
    "              X_train=X_train_small, y_train=y_train_small,\n",
    "              max_evals=8*11, n_jobs=3, n_folds=3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance: 0.37503654872776293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_hp_1 = joblib.load('saved_models/lr_hp_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_lr = pd.read_csv('hp_progress/progress_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best average precision score on validation set\n",
    "-progress_lr.loss.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best performance on the test set, 0.378, is slightly higher than what we found with a grid search, .375. Though this difference is only small, but note that this was achieved with the same number of iterations. Thus, let's take a look at how the performance changed with the number of iterations, to see if we already reached a plateau earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = - progress_lr.loss\n",
    "ap.plot()\n",
    "plt.title('Performance on Validation Set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows nicely how the Bayesian search algorithm has an intelligent approach towards the exploration-exploitation dilemma: For the first 20 or so iterations, it focuses on *exploration*: It searches the hyperparameter space seemingly randomly, resulting in both very high and very low performance. Later, it shifts to *exploitation*: Having identified values for the hyperparameters that work well, it shifts to predominantly searching around these values, resulting in more consistent high performance.  Nevertheless, it occasionally shifts back to exploring values further away, in order to avoid getting stuck in a local maximum.\n",
    "\n",
    "We also see that there does not seem to be much payoff from further optimization once reasonably good values have been found: The best values found during the first 10 iterations are not far off from the overall maximum. Thus, when we ran the hyperparameters optimization on the full data set, we will only let the algorithm run for 40 iteration, since the performance reaches a plateau starting at around 20 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now estimate the model on all data. Based on the results from the smaller data set, we will adjust the parameter grade for alpha, the constant that multiplies the regularization term: We will drop all values for alpha greater than 0.1, since these did not give us good performance. \n",
    "\n",
    "Because we are now using more data, the optimal regularization term will be even smaller; thus, we leave the minimum value for alpha to search over constant, even though it did not give us great performance either on the smaller data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (Elastic Net) \n",
    "# ---------------------------------\n",
    "n_jobs=2\n",
    "lr_2 = SGDClassifier(loss='log', penalty='elasticnet', \n",
    "                      class_weight='balanced', \n",
    "                      max_iter=1000, tol=1E-3, # those are defaults for sklearn 0.21+\n",
    "                      random_state=1, n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-6, 0, 13)}\n",
    "\n",
    "# Grid search\n",
    "lr_gs_2 = GridSearchCV(lr_2, param_grid=param_grid, \n",
    "                       scoring='average_precision',\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=N_JOBS, cv=5)\n",
    "lr_gs_2.fit(X_train, y_train) \n",
    "\n",
    "# Save model\n",
    "\n",
    "joblib.dump(lr_gs_2, 'saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_gs_2 = joblib.load('saved_models/lr_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_gs_2, 'lr_gs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predictions\n",
    "# y_pred_lr_2 = lr_gs_2.predict(X_test)\n",
    "# y_pred_proba_lr_2 = lr_gs_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Save results\n",
    "# average_precision_2['logistic regression'] = \\\n",
    "#     average_precision_score(y_test, y_pred_proba_lr_2)\n",
    "# classification_reports_2['logistic regression'] = \\\n",
    "#     classification_report(y_test, y_pred_lr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_gs_2, 'lr_gs_2', X_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute feature importance and sort\n",
    "most_important_features_2['logistic regression'] = \\\n",
    "    pd.Series(lr_gs_2.best_estimator_.coef_[0], \n",
    "          index=feature_names) \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .iloc[: 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results    \n",
    "gs_heatmap(lr_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_reports_2['logistic regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 0),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SGDClassifier, space, model_name='lr_hp_2',\n",
    "              X_train=X_train, y_train=y_train,\n",
    "              max_evals=40, n_jobs=3, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lr_hp_2 = joblib.load('saved_models/lr_hp_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(lr_hp_2, 'lr_hp_2', X_test, y_test, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_1 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 3),\n",
    "              'alpha': np.logspace(-5, 1, 7)}\n",
    "svm_lin_gs_1 = GridSearchCV(svm_lin_1, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=N_JOBS, cv=5)\n",
    "svm_lin_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_1, 'saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model\n",
    "svm_lin_gs_1 = joblib.load('saved_models/svm_lin_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_lin_1 = svm_lin_gs_1.predict(X_test_small)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_lin_1 = svm_lin_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_lin_1)\n",
    "classification_reports_1['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_lin_1)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_1, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -6, 1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(\n",
    "      SGDClassifier, space, model_name='svm_lin_hp_1',\n",
    "      X_train=X_train_small, y_train=y_train_small,\n",
    "      max_evals=8*11, n_jobs=3, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_lr = pd.read_csv('progress_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best average precision score on validation set\n",
    "-progress_lr.loss.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = - progress_lr.loss\n",
    "ap.plot()\n",
    "plt.title('Performance on Validation Set')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### With whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat this analysis on the whole data set. Again, since more data will require less regularization, we will look at lower our maximum value for alpha to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "# ----------\n",
    "# Elastic net, logistic regression (Loss='hinge')\n",
    "svm_lin_2 = SGDClassifier(loss='hinge', penalty='elasticnet', random_state=1,\n",
    "                          max_iter=1000, tol=1E-3,\n",
    "                          class_weight='balanced', n_jobs=N_JOBS) \n",
    "\n",
    "# Parameters to search over\n",
    "param_grid = {'l1_ratio': np.linspace(0, 1, 11),\n",
    "              'alpha': np.logspace(-5, -1, 9)}\n",
    "svm_lin_gs_2 = GridSearchCV(svm_lin_2, param_grid=param_grid,\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,       \n",
    "                          n_jobs=N_JOBS, cv=5)\n",
    "svm_lin_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_lin_gs_2, 'saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_lin_gs_2 = joblib.load('saved_models/svm_lin_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_2 = svm_lin_gs_2.predict(X_test)\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_2 = svm_lin_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (Linear Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_2)\n",
    "classification_reports_2['SVM (Linear Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_2)\n",
    "\n",
    "# Visualize grid search results\n",
    "gs_heatmap(svm_lin_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AP score\n",
    "print_save_ap(svm_lin_gs_2, 'svm_lin_gs_2', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "space = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'elasticnet',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'tol':1E-3,\n",
    "    'random_state': 1,\n",
    "    'alpha': hp.loguniform('alpha', -5, -1),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(\n",
    "      SGDClassifier, space, model_name='svm_lin_hp_2',\n",
    "      X_train=X_train, y_train=y_train,\n",
    "      max_evals=40, n_jobs=3, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_lin_hp_2 = joblib.load('saved_models/svm_lin_hp_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_save_ap(svm_lin_hp_2, 'svm_lin_hp_2', X_test, y_test, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with RBF-Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller subsets \n",
    "X_train_s, y_train_s = resample(\n",
    "    X_train, y_train, \n",
    "    replace=False, n_samples=500, random_state=1)\n",
    "    \n",
    "X_test_s, y_test_s = resample(\n",
    "    X_test, y_test, \n",
    "    replace=False, n_samples=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=30)\n",
    "X_train_pc = pca.fit_transform(X_train_s) \n",
    "X_test_pc = pca.transform(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to carry out hyperparameter optimization\n",
    "def find_best_hp(CLF, space, model_name,\n",
    "                 X_train, y_train, \n",
    "                 n_folds=5, n_jobs=-1, max_evals=20):\n",
    "    \"\"\"Find best hyperparameters for a given classifier and search space.\"\"\"\n",
    "    \n",
    "    # Trials object to track progress\n",
    "    trials = Trials()\n",
    "\n",
    "    # CSV file to track progress\n",
    "    progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "    with open(progress_file_path, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write header to the file\n",
    "        writer.writerow(['loss', 'params'])\n",
    "\n",
    "    # Objective function to minimize\n",
    "    def objective(params, adjust_params, CLF=CLF, progress_file_path=progress_file_path,\n",
    "                  n_folds=n_folds, n_jobs=n_jobs):\n",
    "        \"\"\"Objective function to minimize\"\"\"\n",
    "\n",
    "        # Instantiate CLF\n",
    "        clf = CLF(**params)\n",
    "        \n",
    "        ## Generate indices is for cross-validation\n",
    "        # If only one \"fold\" is desired, split into train and validation set\n",
    "        if n_folds == 1: \n",
    "            cv = StratifiedShuffleSplit(n_splits=1, test_size=.2, \n",
    "                                        random_state=1)\n",
    "        # Otherwise, generate indices for proper cross-validation split\n",
    "        else:  \n",
    "            cv = StratifiedKFold(n_folds, random_state=1)\n",
    "\n",
    "        # Compute average precision through CV / validation set\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=cv,\n",
    "                                scoring='average_precision', n_jobs=n_jobs)\n",
    "        # Compute loss as the negative mean of the average precision scores\n",
    "        # (since hyperopt can only minimize a function)\n",
    "        loss = -score.mean()\n",
    "        \n",
    "        # Save results to csv file\n",
    "        with open(progress_file_path, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([loss, params])\n",
    "        \n",
    "        # Return results\n",
    "        return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "    \n",
    "    # Minimize objective\n",
    "    best = fmin(objective, space, algo=tpe.suggest,\n",
    "                max_evals=max_evals, trials=trials)\n",
    "\n",
    "    # Get the values of the optimal parameters\n",
    "    best_params = space_eval(space, best)\n",
    "\n",
    "    # Fit the model with the optimal hyperparamters\n",
    "    clf = CLF(**best_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Save model to disk\n",
    "    joblib.dump(clf, 'saved_models/' + model_name + '.joblib')\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(best_params)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics:\n",
      " count    8.180000e+02\n",
      "mean     7.496773e+00\n",
      "std      1.674293e+01\n",
      "min      1.034089e-07\n",
      "25%      1.828256e-02\n",
      "50%      3.657970e-01\n",
      "75%      5.266221e+00\n",
      "max      9.586310e+01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Inspect prior distribution for reg_alpha\n",
    "from hyperopt import pyll\n",
    "c_distr = hp.lognormal('C', 0, 5)\n",
    "samples = [pyll.stochastic.sample(c_distr) for i in range(1000)]\n",
    "# \n",
    "samples = list(filter(lambda x: x<100, samples))\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist', bins=50)\n",
    "# plt.xlim([0,1000])\n",
    "plt.xlabel('c_distr')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics:\n",
      " count    9.130000e+02\n",
      "mean     4.201590e+00\n",
      "std      1.313622e+01\n",
      "min      2.372654e-10\n",
      "25%      4.967344e-04\n",
      "50%      2.613030e-02\n",
      "75%      8.495362e-01\n",
      "max      9.986400e+01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Inspect prior distribution for reg_alpha\n",
    "from hyperopt import pyll\n",
    "gamma_distrdistr = hp.lognormal('C', np.log(1/30), 6)\n",
    "samples = [pyll.stochastic.sample(gamma_distrdistr) for i in range(1000)]\n",
    "# \n",
    "samples = list(filter(lambda x: x<100, samples))\n",
    "# Plot\n",
    "# sns.distplot(pd.Series(samples))\n",
    "pd.Series(samples).plot(kind='hist', bins=50)\n",
    "# plt.xlim([0,1000])\n",
    "plt.xlabel('gamma_distrdistr')\n",
    "plt.title('Histogram for prior distribution of regularization strength')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print('Descriptive statistics:\\n', \n",
    "      pd.Series(samples).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_params_svm_rbf(params):\n",
    "    \"\"\" \n",
    "    Adjust parameters where hyperopt did not allow sampling from optimal \n",
    "    distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set min or max thresholds for parameters, where applicable\n",
    "    if params['C'] >= 10:\n",
    "        params['C'] = 10\n",
    "        \n",
    "    # Return modified parameters\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "# from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to carry out hyperparameter optimization\n",
    "def find_best_hp(CLF, space, model_name, \n",
    "                 X_train, y_train, \n",
    "                 adjust_params=None,n_folds=5, n_jobs=-1, max_evals=20):\n",
    "    \"\"\"Find best hyperparameters for a given classifier and search space.\"\"\"\n",
    "    \n",
    "    # Trials object to track progress\n",
    "    trials = Trials()\n",
    "\n",
    "    # CSV file to track progress\n",
    "    progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "    with open(progress_file_path, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write header to the file\n",
    "        writer.writerow(['loss', 'params'])\n",
    "\n",
    "    # Objective function to minimize\n",
    "    def objective(params, CLF=CLF, \n",
    "                  progress_file_path=progress_file_path,\n",
    "                  n_folds=n_folds, n_jobs=n_jobs):\n",
    "        \"\"\"Objective function to minimize\"\"\"\n",
    "#         pdb.set_trace()\n",
    "        # Adjust parameters, if specified\n",
    "        if adjust_params is not None:\n",
    "            params = adjust_params(params)\n",
    "    \n",
    "        # Instantiate CLF\n",
    "        clf = CLF(**params)\n",
    "        \n",
    "        ## Generate indices for cross-validation\n",
    "        # If only one \"fold\" is desired, split into train and validation set\n",
    "        if n_folds == 1: \n",
    "            cv = StratifiedShuffleSplit(n_splits=1, test_size=.2, \n",
    "                                        random_state=1)\n",
    "        # Otherwise, generate indices for proper cross-validation split\n",
    "        else:  \n",
    "            cv = StratifiedKFold(n_folds, random_state=1)\n",
    "\n",
    "        # Compute average precision through CV / validation set\n",
    "        score = cross_val_score(clf, X_train_pc, y_train, cv=cv,\n",
    "                                scoring='average_precision', n_jobs=n_jobs)\n",
    "        # Compute loss as the negative mean of the average precision scores\n",
    "        # (since hyperopt can only minimize a function)\n",
    "        loss = -score.mean()\n",
    "        \n",
    "        # Save results to csv file\n",
    "        with open(progress_file_path, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([loss, params])\n",
    "        \n",
    "        # Return results\n",
    "        return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "    \n",
    "    # Minimize objective\n",
    "    best = fmin(objective, space, algo=tpe.suggest,\n",
    "                max_evals=max_evals, trials=trials)\n",
    "\n",
    "    # Get the values of the optimal parameters\n",
    "    best_params = space_eval(space, best)\n",
    "\n",
    "    # Fit the model with the optimal hyperparamters\n",
    "    clf = CLF(**best_params)\n",
    "    clf.fit(X_train_pc, y_train)\n",
    "    \n",
    "    # Save model to disk\n",
    "    joblib.dump(clf, 'saved_models/' + model_name + '.joblib')\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4.3366552888303245, 'cache_size': 1500000, 'class_weight': 'balanced', 'gamma': 0.00029495971510450585, 'kernel': 'rbf', 'random_state': 1}\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAX_EVALS=40\n",
    "N_JOBS=3\n",
    "\n",
    "# Define search space\n",
    "space = {\n",
    "    'kernel': 'rbf',\n",
    "    'cache_size': 1500000,\n",
    "    'class_weight': 'balanced',\n",
    "    'random_state': 1,\n",
    "    'C': hp.lognormal('C', -3, 3),\n",
    "    'gamma': hp.lognormal('gamma', -3, 3)\n",
    "}\n",
    "\n",
    "# Find best hyperparameters\n",
    "find_best_hp(SVC, space, model_name='svm_rbf_hp',\n",
    "              X_train=X_train_pc, y_train=y_train_s, \n",
    "              adjust_params=adjust_params_svm_rbf,\n",
    "              max_evals=MAX_EVALS,n_folds=1, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best average precision score on *test* set: 0.3035966425438776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "svm_rbf_hp = joblib.load('saved_models/svm_rbf_hp.joblib')\n",
    "\n",
    "# Calculate average precision\n",
    "def print_save_ap(clf, model_name, X_test_pc, y_test, validation_plot=False):\n",
    "    \"\"\"\n",
    "    Calculates, saves, and prints average precision score on test set; \n",
    "    optionally plot how average precision changed over iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Score classifier with the test data\n",
    "    # Try if classifier supports probability\n",
    "    try:\n",
    "        y_score = clf.predict_proba(X_test_pc)[:,1]\n",
    "    # If it doesn't, use its decision function\n",
    "    except AttributeError:\n",
    "        y_score = clf.decision_function(X_test_pc)\n",
    "   \n",
    "    # Calculate average precision\n",
    "    ap_score = average_precision_score(y_test, y_score)\n",
    "    \n",
    "    # Save AP\n",
    "    try:\n",
    "        average_precision_hp[model_name] = ap_score\n",
    "    # If dictionary to save AP doesn't exist yet, create it first\n",
    "    except NameError:\n",
    "        average_precision = {}\n",
    "        average_precision[model_name] = ap_score\n",
    "    \n",
    "    # Print AP\n",
    "    print('Best average precision score on *test* set: {}'.format(ap_score))\n",
    "    \n",
    "    \n",
    "    # Plot AP, if specified\n",
    "    if validation_plot:\n",
    "        # Load progress file with validation performance\n",
    "        progress_file_path = 'hp_progress/progress_' + model_name + '.csv'\n",
    "        progress_file = pd.read_csv(progress_file_path)\n",
    "\n",
    "        # Extract AP for each iteration\n",
    "        ap = - progress_file.loss\n",
    "        ap.plot()\n",
    "        plt.title('Performance on *Validation* Set')\n",
    "        plt.ylabel('Average Precision')\n",
    "        plt.xlabel('Iteration');\n",
    "\n",
    "print_save_ap(svm_rbf_hp, 'svm_rbf_hp', X_test_pc, y_test_s, validation_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_1 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'gamma': np.logspace(-5, 1, 8)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_rbf_gs_1 = GridSearchCV(svm_rbf_1, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_1.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_1, 'saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_1 = joblib.load('saved_models/svm_rbf_gs_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_1 = svm_rbf_gs_1.predict(X_test_small)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_1 = svm_rbf_gs_1.decision_function(X_test_small)\n",
    "\n",
    "# Save results\n",
    "average_precision_1['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test_small, y_pred_distance_svm_rbf_1)\n",
    "\n",
    "classification_reports_1['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test_small, y_pred_svm_rbf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_best_result(svm_rbf_gs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs_1) #, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs_1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_2 = SVC(kernel='rbf', probability=False, \n",
    "              cache_size=10000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-2, 3, 6),\n",
    "              'gamma': np.logspace(-5, -1, 4)}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, random_state=1,\n",
    "                             train_size=50000, test_size=1000)\n",
    "\n",
    "svm_rbf_gs_2 = GridSearchCV(svm_rbf_2, param_grid=param_grid,\n",
    "                          return_train_score=True, n_jobs=3,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_rbf_gs_2.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(svm_rbf_gs_2, 'saved_models/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "svm_rbf_gs_2 = joblib.load('saved_model/svm_rbf_gs_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_rbf_2 = svm_rbf_gs_2.predict(X_test)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_rbf_2 = svm_rbf_gs_2.decision_function(X_test)\n",
    "\n",
    "# Save results\n",
    "average_precision_2['SVM (RBF Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_rbf_2)\n",
    "\n",
    "classification_reports_2['SVM (RBF Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_rbf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_best_result(svm_rbf_gs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_rbf_gs_2, x_digits=1, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_rbf_gs_2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with polynomial kernel \n",
    "\n",
    "##### With smaller subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel='poly', probability=False, gamma='auto',\n",
    "              cache_size=5000, class_weight='balanced')\n",
    "# Parameters to search over\n",
    "param_grid = {'C': np.logspace(-3, 3, 8),\n",
    "              'degree': [2,3,4]}\n",
    "# Define indices for validation split (instead of proper cross-validation)\n",
    "split_indices = ShuffleSplit(n_splits=1, test_size=.2, random_state=1)\n",
    "\n",
    "svm_poly_gs = GridSearchCV(svm_poly, param_grid=param_grid,\n",
    "                          return_train_score=True,\n",
    "                          scoring='average_precision', cv=split_indices)\n",
    "svm_poly_gs.fit(X_train_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of class\n",
    "y_pred_svm_poly = svm_poly_gs.predict(X_test_p)\n",
    "\n",
    "# Distance from separating hyperplane\n",
    "y_pred_distance_svm_poly = svm_poly_gs.decision_function(X_test_p)\n",
    "\n",
    "# Save results\n",
    "average_precision['SVM (Polynomial Kernel)'] = \\\n",
    "    average_precision_score(y_test, y_pred_distance_svm_poly)\n",
    "\n",
    "classification_reports['SVM (Polynomial Kernel)'] = \\\n",
    "    classification_report(y_test, y_pred_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_heatmap(svm_poly_gs, x_scientific_notation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(svm_poly_gs, 'svm_poly_gs.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = \n",
    "plt.title('Impact of Dropping Columns on Classifier Performance')\n",
    "plt.ylabel('Average Precision');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "47.2px",
    "left": "591.8px",
    "top": "95.6px",
    "width": "211.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
