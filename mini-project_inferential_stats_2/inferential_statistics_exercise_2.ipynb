{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "   4. Write a story describing the statistical significance in the context or the original problem.\n",
    "   5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "+ Formulas for the Bernoulli distribution: https://en.wikipedia.org/wiki/Bernoulli_distribution\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of callbacks for black-sounding names\n",
    "sum(data[data.race=='b'].call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad</th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>honors</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>military</th>\n",
       "      <th>empholes</th>\n",
       "      <th>occupspecific</th>\n",
       "      <th>...</th>\n",
       "      <th>compreq</th>\n",
       "      <th>orgreq</th>\n",
       "      <th>manuf</th>\n",
       "      <th>transcom</th>\n",
       "      <th>bankreal</th>\n",
       "      <th>trade</th>\n",
       "      <th>busservice</th>\n",
       "      <th>othservice</th>\n",
       "      <th>missind</th>\n",
       "      <th>ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nonprofit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ad  education  ofjobs  yearsexp  honors  volunteer  military  empholes  \\\n",
       "0  b  1          4       2         6       0          0         0         1   \n",
       "1  b  1          3       3         6       0          1         1         0   \n",
       "2  b  1          4       1         6       0          0         0         0   \n",
       "3  b  1          3       4         6       0          1         0         1   \n",
       "4  b  1          3       3        22       0          0         0         0   \n",
       "\n",
       "   occupspecific    ...      compreq  orgreq  manuf  transcom  bankreal trade  \\\n",
       "0             17    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "1            316    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "2             19    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "3            313    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "4            313    ...          1.0     1.0    0.0       0.0       0.0   0.0   \n",
       "\n",
       "  busservice othservice  missind  ownership  \n",
       "0        0.0        0.0      0.0             \n",
       "1        0.0        0.0      0.0             \n",
       "2        0.0        0.0      0.0             \n",
       "3        0.0        0.0      0.0             \n",
       "4        0.0        1.0      0.0  Nonprofit  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p>Your answers to Q1 and Q2 here</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What test is appropriate for this problem? Does CLT apply?\n",
    "  The most appropriate test for whether race has a significant impact on callback is either a classical t-test for the mean, or a bootstrap test for the mean. In either case, we need to conduct a two-sample test, because we are comparing the mean in the sample of resumes with white-sounding names to the mean in the sample with black-sounding names.\n",
    "\n",
    "The assumptions of the CLT are satisfied: The samples are *independent*, because race is randomly assigned to the resumes. The samples are also * identically distributed*, because the resumes are randomly drawn from the same distribution of resumes. \n",
    "\n",
    "Now let's look at how many observations of each group we have, so we can determine whether we can rely on asymptotics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    2435\n",
       "w    2435\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.race.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have about 2500 observations per group, we can rely on the CLT to yield a normally distributed test-statistic.  This is helpful, since our dependent variable – whether the employer called back or not – is dichotomous, and thus follows a Bernoulli rather than a normal distribution.\n",
    "\n",
    "### What are the null and alternate hypotheses?\n",
    "The null hypothesis is that the probability that an applicant receives a callback is equally likely for resumes with black- and white-sounding names. I chose a two-sided alternative hypothesis: The chance that an applicant receives a callback is *different* for black- and white-sounding names. Due to our large sample size – about 5000 – our test will have enough power to reach statistical significance even for insubstantial effect sizes anyway; therefore there is no reason to choose a  one-sided alternative hypothesis. In addition, this strategy would also enable us to detect the opposite pattern, namely if many employers actively tried to recruit black candidates to increase the diversity of their workforce.\n",
    "\n",
    "### Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "Let's start by looking at the descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       call\n",
       "race       \n",
       "b     0.064\n",
       "w     0.097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine mean callback rate\n",
    "round(data.loc[:, ['race', 'call']].groupby('race').mean(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does indeed reveal that white applicants were about 50% more likely to receive a callback (9.7% versus 6.4%).  Let's start by conducting a classical t-test to determine whether this difference could plausibly be due to chance, or whether it likely represents a real relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.11471e+00,  4.00000e-05])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct a parametric hypothesis test\n",
    "np.round_(  \n",
    "    stats.ttest_ind(data.loc[data.race=='b', 'call'],\n",
    "                    data.loc[data.race=='w', 'call']), \n",
    "    5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test yields a p-value of very close to zero (namely 0.004%). This means that race does indeed have a significant impact on whether an applicant receives a callback (because if race did not have an effect, there was virtually a zero chance that we would observe as big of a difference in callbacks as we did).\n",
    "\n",
    "Now let's conduct a bootstrap hypothesis test to see whether we get a similar result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:  0.0002\n"
     ]
    }
   ],
   "source": [
    "# Define function to permute data and compute test statistic\n",
    "def permutation_stat(dataframe, v, group, statistic, rng):\n",
    "    \"\"\"\n",
    "    Create a single permutation of the data, randomly assign groups, \n",
    "    and compute test statistic.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The data frame where the relevant variables are located.\n",
    "    v : str\n",
    "        Name of the variable in the data frame that contains the\n",
    "        data for which to compute means.\n",
    "    group : str\n",
    "        Name of the variable in the data frame that contains a\n",
    "        categorical variable that identifies the two groups for\n",
    "        which to compute the test statistic.\n",
    "    statistic : function\n",
    "        Function that returns the test statistic of interest.\n",
    "    rng : np.RandomState instance\n",
    "        Random number generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numeric\n",
    "        Value of the test statistic for the permutation sample.\n",
    "    \"\"\"\n",
    "\n",
    "    # Permute values\n",
    "    v_permuted = rng.permutation(dataframe.loc[:, v])\n",
    "    \n",
    "    # Randomly assign groups\n",
    "    group_1 = v_permuted[: group_value_counts[0]]\n",
    "    group_2 = v_permuted[group_value_counts[1]:]\n",
    "    \n",
    "    # Return test statistic\n",
    "    stat = statistic(group_1, group_2)\n",
    "    return(stat)\n",
    "\n",
    "\n",
    "# Define function to calculate p-value\n",
    "def p_value(replicates, observed_stat, two_sided=True):\n",
    "    \"\"\"\n",
    "    Computes the p-value of a test statistic using bootstrap replicates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    replicates : pd.Series\n",
    "        bootstrap replicates (i.e., the value of the test statistic for\n",
    "        each bootstrap sample.\n",
    "    observed_stat : numeric\n",
    "        Value of the test statistic in the actual sample.\n",
    "    two_sided : bool, optional\n",
    "        Whether to conduct a one-sided or two-sided hypothesis test.\n",
    "        Default: True (two-sided).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numeric\n",
    "        p-value\n",
    "    \"\"\"\n",
    "    \n",
    "    # First compute what percentage of bootstrap replicates are LOWER\n",
    "    p = (replicates < observed_stat).mean() \n",
    "    # If more than half are LOWER, compute what percentage is HIGHER \n",
    "    # (since we are interested in what proportion is more extreme).\n",
    "    if p > 0.5:\n",
    "        p = (replicates > observed_stat).mean()\n",
    "    \n",
    "    # If conducting a 2-sided test, adjust the p-value accordingly\n",
    "    if two_sided == True:\n",
    "        p = 2 * p\n",
    "    return(p)\n",
    "\n",
    "\n",
    "def btest_2samp(df, v, group, statistic, n_permutations=10000):\n",
    "    \"\"\"\n",
    "    Performs a two-sided two-sample hypothesis test using the bootstrap.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The data frame where the relevant variables are located.\n",
    "    v : str\n",
    "        Name of the variable in the data frame that contains the\n",
    "        data for which to compute means.\n",
    "    group : str\n",
    "        Name of the variable in the data frame that contains a\n",
    "        categorical variable that identifies the two groups for\n",
    "        which to compute the test statistic.\n",
    "    n_permutations : numeric, optional\n",
    "        Number of bootstrap replicates.  Default: 10000\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numeric\n",
    "        p-value \n",
    "    \"\"\"\n",
    "\n",
    "    # Count number of observations in each group\n",
    "    global group_value_counts # For some reason doesn't work otherwise\n",
    "    group_value_counts = df.loc[:, group].value_counts()\n",
    "    \n",
    "    # Compute actual test statistic\n",
    "    data_1 = df.loc[df[group]==group_value_counts.index[0], v]\n",
    "    data_2 = df.loc[df[group]==group_value_counts.index[1], v]\n",
    "    actual_stat = statistic(data_1, data_2)\n",
    "    \n",
    "    # Create random number generator\n",
    "    rng = np.random.RandomState(3)\n",
    "    \n",
    "    # Compute test statistic for each permutation replicate\n",
    "    permutation_stats = np.empty(shape=n_permutations)\n",
    "    for replicate in range(n_permutations):\n",
    "        permutation_stats[replicate] = permutation_stat(df, v, group, \n",
    "                                                        statistic, rng)\n",
    "\n",
    "    # Compute p-value\n",
    "    return(p_value(permutation_stats, actual_stat))\n",
    "\n",
    "\n",
    "# Define function to compute difference in means\n",
    "def diff_in_means(s1, s2):\n",
    "    \"\"\" Returns the difference in means between two pd.Series.\"\"\"\n",
    "    return (s1.mean() - s2.mean())\n",
    "\n",
    "\n",
    "# Conduct 2-sample hypothesis test\n",
    "print('p-value: ', btest_2samp(df=data, v='call', group='race', \n",
    "                    statistic=diff_in_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap likewise returns a p-value of close to zero (0.02%, to be exact). Thus, it likewise rejects the null hypothesis of no difference in callback rates at any reasonable significance level.\n",
    "\n",
    "Having establish that there is a significant difference between resumes with white and black names, let's now compute a 95% confidence interval for the effect size. This will also give us the margin of error.  Since we are dealing with proportions – which are naturally bounded between zero and one – the margin of error might not be symmetrical around the observed difference (which corresponds to the maximum likelihood estimate).  To simplify things, though, I will only compute the average margin of error, rather than calculating a separate margin of error for the low and the high. \n",
    "\n",
    "Like before, I will first computed it in the classical parametric way and then calculate it using the bootstrap. The first step is to investigate whether the variance in callback rates for whites and blacks are equal, because this will influence which assumptions we will be able to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06 0.087\n"
     ]
    }
   ],
   "source": [
    "# Parametric confidence interval\n",
    "# Sample variance of callback for black names \n",
    "# (ddof adjusts degrees of freedoms)\n",
    "var_b = np.var(data.loc[data.race=='b', 'call'], ddof=1)\n",
    "# Sample variance of callback for white names\n",
    "var_w = np.var(data.loc[data.race=='w', 'call'], ddof=1)\n",
    "print(np.round_(var_b, 3), np.round_(var_w, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the variances are not equal, so we will have to work with these separate variances rather than computing an overall variance of all callbacks. Unfortunately, this means that we would have to make a correction in the degrees of freedom for the t-distribution. To simplify this, I will use the normal distribution to approximate the t-distribution.  Since our sample size is so large (about 5000), the difference should be inconsequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical confidence interval:\n",
      "0   -0.047\n",
      "1   -0.017\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Number of observations by race\n",
    "n_race = data.race.value_counts()\n",
    "\n",
    "# Standard deviation for difference in mean callback\n",
    "sd_diff = np.sqrt(var_b / n_race.loc['b'] +\n",
    "                  var_w / n_race.loc['w'])\n",
    "# Mean difference in callback\n",
    "mean_diff = diff_in_means_df(data.loc[:, ['call', 'race']])\n",
    "# Compute test statistic\n",
    "z = mean_diff / sd_diff\n",
    "\n",
    "# 2.5th and 97.5th percentile of standard normal distribution\n",
    "# (convert to pd.Series to allow broadcasting)\n",
    "ci = pd.Series(scipy.stats.norm.interval(0.95)) \n",
    "\n",
    "# Confidence interval\n",
    "ci_classical = (mean_diff + ci*sd_diff)\n",
    "print('Classical confidence interval:\\n{}'\n",
    "        .format(np.round_(ci_classical, \n",
    "                       decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Margin of error\n",
    "np.round_(\n",
    "    (callback_ci_classical[1] - callback_ci_classical[0]) / 2,\n",
    "     decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0805"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For comparison, get average callback rate\n",
    "round(data.call.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we can be 95% confident that the true effect is between 1.7 and 4.7 percentage points. (To be precise, in repeated samples from the same data generating process, 95% of intervals created this way will contain the true effect.) The margin of error is 1.5 percentage points. \n",
    "\n",
    "This effect size is huge, given that the mean callback rate is only about 8%.\n",
    "\n",
    "Now let's calculate the confidence interval using the bootstrap, and see if we get similar results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed test statistic:  -0.032\n",
      "Confidence Interval: [-0.048 -0.017]\n",
      "Margin of Error: 0.015\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_ci(df, statistic, n_samples=10000, \n",
    "                 q=[2.5, 97.5], decimals=3, seed=1):\n",
    "    \"\"\"…\"\"\"\n",
    "\n",
    "    # Print observed value for test statistic\n",
    "    observed_stat = statistic(df)\n",
    "    print('Observed test statistic: ', \n",
    "          np.round_(observed_stat, decimals))\n",
    "    \n",
    "    # Create random number generator\n",
    "    rng = np.random.RandomState(seed)\n",
    "    # Draw random samples from the data frame's index\n",
    "    # (each column contains one bootstrap sample)\n",
    "    global sample\n",
    "    sample = rng.choice(df.index, (len(df.index), n_samples))\n",
    "    # pdb.set_trace ()\n",
    "    # For each sample of the index, compute test statistic\n",
    "    replicates = np.zeros(n_samples)\n",
    "    \n",
    "    for sample_number in range(n_samples):\n",
    "        # Get the sample index\n",
    "        sample_index = sample[:, sample_number]\n",
    "        # Get the corresponding data \n",
    "        data = df.loc[sample_index, :]\n",
    "        # Compute test statistic\n",
    "        replicates[sample_number] = statistic(data)\n",
    "        \n",
    "    # Compute confidence interval\n",
    "    ci = np.percentile(replicates, q)\n",
    "    # Compute margin of error \n",
    "    me = (ci[1] - ci[0]) / 2\n",
    "     \n",
    "    #  confidence interval\n",
    "    print('Confidence Interval: {}\\nMargin of Error: {}'\n",
    "            .format(np.round_(ci, decimals=decimals),\n",
    "                    np.round_(me, decimals=decimals)))\n",
    "    return(ci, me)\n",
    "           \n",
    "        \n",
    "# Define a function that computes the difference in means from a data frame\n",
    "def diff_in_means_df(df):\n",
    "    \"\"\"\n",
    "    Computes the difference in means between two groups in a data frame.\n",
    "    \n",
    "    The variable for which to compute the mean must be in the first column,\n",
    "    The variable that contains the group name must be in the second column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group by the 2nd column and compute mean of the 1st column \n",
    "    means = df.groupby(df.columns[1]).mean()\n",
    "    return(means.iloc[0, 0] - means.iloc[1, 0])\n",
    "\n",
    "# Compute bootstrap confidence intervals margin of error \n",
    "bootstrap_ci(data.loc[:, ['call', 'race']], diff_in_means_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us virtually identical results. The reason is that the only advantage of the bootstrap is that it is able to model a potential deviation of the distribution from normality; however, due to the Central Limit Theorem in conjunction with the huge sample size (around 5000), the distribution of our test statistic is very close to normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"span5 alert alert-success\">\n",
    "<p> Your answers to Q4 and Q5 here </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a story describing the statistical significance in the context or the original problem.\n",
    "It is long been suspected that many employers tend to discriminate against black applicants. In order to prove this, however, it is not enough to rely on anecdotal evidence or even observational data such as unequal representation. Instead, we need to conduct randomized experiments, where the difference between treatment and control group is the race of the applicant. This is commonly done by sending out resumes that have either white- or black-sounding names. \n",
    "\n",
    "The data set analyzed here can give us unique insight into this question because it is very comprehensive. It contains data from 5000 observations from such an experiment, split equally between treatment and control group.  This large sample size allows a precise estimation of the effect of race. Conducting a hypothesis test for whether it is plausible that race has no effect yields a p-value of virtually zero. Our best estimate is that having a black-sounding name reduces callback by about 3%; we can be 95% confident that the true effect lies between 1.7% and 4.8%.  Given that the mean callback rate is only 8%, this effect sizes very large.\n",
    "\n",
    "### Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "Since this analysis did not control for any other variables, we cannot say how important race is compared to other factors. Because this question is definitely of interest, the next step would be to conduct a regression analysis, where we include the other variables available to us as predictors. This could tell us how important race is relative to other attributes of the applicant and various attributes of the job and employer. In addition, this would also allow us to investigate whether there are any variables that mediate the effect of race. (This could be done by including interaction terms.) For example, it might show that the negative impact of race is particularly high on some kinds of jobs and for some kinds of employers, while this negative effect is ameliorated or even turned positive for workplaces that value a diverse workforce. \n",
    "\n",
    "That said, we still can be confident the effect of race observed here is not caused by any confounding variables (i.e., that the effect would decrease if we controlled for other important factors). We know this because race was randomly assigned to the resumes. As a result, it is not possible that the real causal factor is merely another variable correlated with race (e.g., having a high school diploma from a lower-achieving school), because randomization broke up the correlation between race and all other potential factors in our sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
